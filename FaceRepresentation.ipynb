{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version is 2.0.0 , device name /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "cmd_line_run = False\n",
    "if not cmd_line_run:\n",
    "    %matplotlib inline\n",
    "collab_mode = False\n",
    "\n",
    "if collab_mode and not cmd_line_run:\n",
    "    # set up tensorflow in collab\n",
    "    %tensorflow_version 2.x\n",
    "# imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import warnings # This ignore all the warning messages\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from random import randint\n",
    "from os import path\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(\"Tensorflow version is\", tf.__version__, \", device name\", tf.test.gpu_device_name())\n",
    "\n",
    "batch_size = 2048\n",
    "image_size = (64, 64)\n",
    "if not os.path.exists('./embedding'):\n",
    "    os.makedirs('./embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function load_dataset.<locals>.<lambda> at 0x0000024C0A3588B8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: expected exactly one node node, found []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function load_dataset.<locals>.<lambda> at 0x0000024C0A3588B8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: expected exactly one node node, found []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function load_dataset.<locals>.<lambda> at 0x0000024C0A3588B8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: expected exactly one node node, found []\n",
      "WARNING:tensorflow:Entity <function load_dataset.<locals>.<lambda> at 0x0000024C0A358C18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: expected exactly one node node, found []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function load_dataset.<locals>.<lambda> at 0x0000024C0A358C18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: expected exactly one node node, found []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function load_dataset.<locals>.<lambda> at 0x0000024C0A358C18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: expected exactly one node node, found []\n",
      "(64, 64, 3) 0.0 0.99964094\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "attributes_subset = [\n",
    "        'Attractive', 'Bald', 'Bangs',\n",
    "        'Big_Nose', 'Heavy_Makeup', 'Blond_Hair',\n",
    "        'Male', 'Smiling', 'Young', 'Straight_Hair'\n",
    "]\n",
    "\n",
    "def prepare_embeddings_from_batch(batch, output_type=tf.float32, attributes_subset = None):\n",
    "    imgs, attributes = batch\n",
    "    \n",
    "    if attributes_subset is not None:\n",
    "        attributes = {key: attributes[key] for key in attributes if key in attributes_subset}\n",
    "    embeddings = tf.stack(list(attributes.values()))\n",
    "    embeddings = tf.transpose(embeddings)\n",
    "    embeddings = tf.cast(embeddings, dtype=output_type)\n",
    "    return imgs, embeddings\n",
    "\n",
    "def process_image(img, image_shape):\n",
    "    img = tf.cast(img, tf.float32)/127.5-1 # IMPORTANT, image's pixels are in the range <-1, 1>\n",
    "    img = img[50:(218-50), 40:(178-40)] # crop\n",
    "    img = tf.image.resize(img, image_shape)\n",
    "    return img\n",
    "\n",
    "def load_image(filename):\n",
    "    img = tf.io.read_file(filename)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    return img\n",
    "\n",
    "def convert_from_output_to_image(images):\n",
    "    return tf.clip_by_value((images+1)/2, 0, 1)\n",
    "\n",
    "def display_image_from_dataset(data):\n",
    "    for batch in data.take(1):\n",
    "        image, attributes = batch\n",
    "        img_ = convert_from_output_to_image(image[0])\n",
    "        plt.imshow(img_)\n",
    "        print(img_.shape, np.min(img_), np.max(img_))\n",
    "\n",
    "def save_generated_image(settings, epoch):\n",
    "    save_dir = settings.generated_images_path\n",
    "    if not path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    name = path.join(save_dir,\n",
    "                     'img_{}_{}.png'.format(epoch, get_time()))\n",
    "    plt.savefig(name)\n",
    "\n",
    "\n",
    "def show_images(images, epoch, settings, save_images=False, display_images=False):\n",
    "    print(\"image pixels range\", np.min(images), np.max(images), \"std\", np.std(images))\n",
    "    num_of_images = min(10, images.shape[0])\n",
    "    # (x, y=1)\n",
    "    plt.figure(figsize=(num_of_images, 1))\n",
    "    for i in range(num_of_images):\n",
    "        plt.subplot(1, num_of_images, i + 1)\n",
    "        img = images[i, :, :, :].numpy() #\n",
    "        # img = convert_from_output_to_image(img) # images are already converted in gen_step\n",
    "        # img = (img * 127.5 + 127.5).astype(np.uint8)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    \n",
    "\n",
    "    if save_images:\n",
    "        save_generated_image(settings, epoch)\n",
    "    if display_images and not cmd_line_run:\n",
    "        plt.show()\n",
    "\n",
    "def load_dataset(image_shape, preprocess_images=True, shuffle_size=500, seed=101, split=tfds.Split.TRAIN):\n",
    "    dataset_name = 'celeb_a'\n",
    "    data = tfds.load(dataset_name, split=split)\\\n",
    "               .shuffle(shuffle_size)\n",
    "    # for each image return a tuple (image, attributes), ignore 'landmarks'\n",
    "    if preprocess_images:\n",
    "        data = data\\\n",
    "            .map(lambda x: (process_image(x['image'], image_shape), x['attributes']))\n",
    "    else:\n",
    "        data = data\\\n",
    "            .map(lambda x: (x['image'], x['attributes']))\n",
    "    return data.batch(batch_size)\n",
    "train_data = load_dataset(image_size)\n",
    "test_data = load_dataset(image_size, split=tfds.Split.TEST)\n",
    "\n",
    "train_count = 162770\n",
    "test_count = 19962\n",
    "\n",
    "display_image_from_dataset(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"embedding\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 16)        208       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 32)        2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 64)          8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 128)         32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               65664     \n",
      "=================================================================\n",
      "Total params: 110,064\n",
      "Trainable params: 109,584\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n",
      "Model: \"all\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,290\n",
      "Trainable params: 1,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "kernel_size = 2\n",
    "strides = 2\n",
    "initial_filters = 16\n",
    "input_shape= (*image_size, 3)\n",
    "outputs = len(attributes_subset) if attributes_subset is not None else 40\n",
    "embedding_size = 128\n",
    "epochs = 10\n",
    "\n",
    "model_embedding = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=initial_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides,\n",
    "        input_shape=input_shape),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=initial_filters*2,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=initial_filters*4,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=initial_filters*8,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides*2),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(embedding_size)\n",
    "], name='embedding')\n",
    "\n",
    "model_all = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(outputs, activation='sigmoid', input_shape=(embedding_size, ))\n",
    "], name='all')\n",
    "\n",
    "model_embedding.summary()\n",
    "model_all.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_weights(model, name):\n",
    "    # save model and its weights\n",
    "    model_json = model.to_json()\n",
    "    with open(\"./embedding/{}_structure.json\".format(name), \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights('./embedding/{}_weights.h5'.format(name))\n",
    "    \n",
    "    print('saved model: {}'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 progress:  6  %, time  1.3551134586334228\n",
      "epoch  1 progress:  12  %, time  0.739394998550415\n",
      "epoch  1 progress:  18  %, time  0.6147096157073975\n",
      "epoch  1 progress:  25  %, time  0.6313878536224365\n",
      "epoch  1 progress:  31  %, time  0.6275001525878906\n",
      "epoch  1 progress:  37  %, time  0.7936123847961426\n",
      "epoch  1 progress:  44  %, time  0.7564778804779053\n",
      "epoch  1 progress:  50  %, time  0.6802363395690918\n",
      "epoch  1 progress:  56  %, time  0.6926822662353516\n",
      "epoch  1 progress:  62  %, time  0.6935555934906006\n",
      "epoch  1 progress:  69  %, time  0.6633721828460694\n",
      "epoch  1 progress:  75  %, time  0.6259775161743164\n",
      "epoch  1 progress:  81  %, time  0.6556247234344482\n",
      "epoch  1 progress:  88  %, time  0.6318241119384765\n",
      "epoch  1 progress:  94  %, time  0.6863379001617431\n",
      "epoch  1 progress:  100  %, time  0.6421751499176025\n",
      "saved model: embedding_10attr_changed_net\n",
      "epoch 1/10, loss 4.1574320793151855, test_loss 4.227690696716309\n",
      "epoch  2 progress:  6  %, time  0.6813719272613525\n",
      "epoch  2 progress:  12  %, time  0.7090989112854004\n",
      "epoch  2 progress:  18  %, time  0.6586773872375489\n",
      "epoch  2 progress:  25  %, time  0.6560522556304932\n",
      "epoch  2 progress:  31  %, time  0.6339264869689941\n",
      "epoch  2 progress:  37  %, time  0.6267659664154053\n",
      "epoch  2 progress:  44  %, time  0.6490350246429444\n",
      "epoch  2 progress:  50  %, time  0.6968817234039306\n",
      "epoch  2 progress:  56  %, time  0.7458713054656982\n",
      "epoch  2 progress:  62  %, time  0.687335729598999\n",
      "epoch  2 progress:  69  %, time  0.6614026069641114\n",
      "epoch  2 progress:  75  %, time  0.6631266593933105\n",
      "epoch  2 progress:  81  %, time  0.6826387405395508\n",
      "epoch  2 progress:  88  %, time  0.6347397327423095\n",
      "epoch  2 progress:  94  %, time  0.661966609954834\n",
      "epoch  2 progress:  100  %, time  0.6019079208374023\n",
      "saved model: embedding_10attr_changed_net\n",
      "epoch 2/10, loss 3.9347236156463623, test_loss 3.9786109924316406\n",
      "epoch  3 progress:  6  %, time  0.9585380554199219\n",
      "epoch  3 progress:  12  %, time  0.980372142791748\n",
      "epoch  3 progress:  18  %, time  0.8411922931671143\n",
      "epoch  3 progress:  25  %, time  0.7565640926361084\n",
      "epoch  3 progress:  31  %, time  0.7506007671356201\n",
      "epoch  3 progress:  37  %, time  0.6813466548919678\n",
      "epoch  3 progress:  44  %, time  0.6624445915222168\n",
      "epoch  3 progress:  50  %, time  0.6802336215972901\n",
      "epoch  3 progress:  56  %, time  0.674933385848999\n",
      "epoch  3 progress:  62  %, time  0.6865843772888184\n",
      "epoch  3 progress:  69  %, time  0.6868891239166259\n",
      "epoch  3 progress:  75  %, time  0.66880784034729\n",
      "epoch  3 progress:  81  %, time  0.6769872188568116\n",
      "epoch  3 progress:  88  %, time  0.6935293674468994\n",
      "epoch  3 progress:  94  %, time  0.7210091114044189\n",
      "epoch  3 progress:  100  %, time  0.6129762172698975\n",
      "saved model: embedding_10attr_changed_net\n",
      "epoch 3/10, loss 3.684929132461548, test_loss 3.766392707824707\n",
      "epoch  4 progress:  6  %, time  1.043576431274414\n",
      "epoch  4 progress:  12  %, time  0.9645735263824463\n",
      "epoch  4 progress:  18  %, time  0.7683664798736572\n",
      "epoch  4 progress:  25  %, time  0.69434494972229\n",
      "epoch  4 progress:  31  %, time  0.6869888305664062\n",
      "epoch  4 progress:  37  %, time  0.7017783641815185\n",
      "epoch  4 progress:  44  %, time  0.6491117954254151\n",
      "epoch  4 progress:  50  %, time  0.6539246082305908\n",
      "epoch  4 progress:  56  %, time  0.6531539916992187\n",
      "epoch  4 progress:  62  %, time  0.6744349002838135\n",
      "epoch  4 progress:  69  %, time  0.6873575210571289\n",
      "epoch  4 progress:  75  %, time  0.7006853103637696\n",
      "epoch  4 progress:  81  %, time  0.6450227737426758\n",
      "epoch  4 progress:  88  %, time  0.6834271430969239\n",
      "epoch  4 progress:  94  %, time  0.6778069496154785\n",
      "epoch  4 progress:  100  %, time  0.6071830749511719\n",
      "saved model: embedding_10attr_changed_net\n",
      "epoch 4/10, loss 3.5172746181488037, test_loss 3.5585906505584717\n",
      "epoch  5 progress:  6  %, time  0.7507226467132568\n",
      "epoch  5 progress:  12  %, time  0.6676380157470703\n",
      "epoch  5 progress:  18  %, time  0.6437094688415528\n",
      "epoch  5 progress:  25  %, time  0.6582858562469482\n",
      "epoch  5 progress:  31  %, time  0.6626091957092285\n",
      "epoch  5 progress:  37  %, time  0.6861018180847168\n",
      "epoch  5 progress:  44  %, time  0.6525971412658691\n",
      "epoch  5 progress:  50  %, time  0.647133207321167\n",
      "epoch  5 progress:  56  %, time  0.6867348194122315\n",
      "epoch  5 progress:  62  %, time  0.6384509086608887\n",
      "epoch  5 progress:  69  %, time  0.6777751445770264\n",
      "epoch  5 progress:  75  %, time  0.6811262130737304\n",
      "epoch  5 progress:  81  %, time  0.6589193344116211\n",
      "epoch  5 progress:  88  %, time  0.8519493579864502\n",
      "epoch  5 progress:  94  %, time  0.7864115238189697\n",
      "epoch  5 progress:  100  %, time  0.6484909534454346\n",
      "saved model: embedding_10attr_changed_net\n",
      "epoch 5/10, loss 3.394974946975708, test_loss 3.4589242935180664\n",
      "epoch  6 progress:  6  %, time  0.8202200412750245\n",
      "epoch  6 progress:  12  %, time  0.7287834167480469\n",
      "epoch  6 progress:  18  %, time  0.6985500812530517\n",
      "epoch  6 progress:  25  %, time  0.6940356731414795\n",
      "epoch  6 progress:  31  %, time  0.6974865913391113\n",
      "epoch  6 progress:  37  %, time  0.6542072296142578\n",
      "epoch  6 progress:  44  %, time  0.6543388366699219\n",
      "epoch  6 progress:  50  %, time  0.681432056427002\n",
      "epoch  6 progress:  56  %, time  0.6417190551757812\n",
      "epoch  6 progress:  62  %, time  0.6681039810180665\n",
      "epoch  6 progress:  69  %, time  0.6574552536010743\n",
      "epoch  6 progress:  75  %, time  0.6512778282165528\n",
      "epoch  6 progress:  81  %, time  0.6487521648406982\n",
      "epoch  6 progress:  88  %, time  0.670874547958374\n",
      "epoch  6 progress:  94  %, time  0.6649549961090088\n",
      "epoch  6 progress:  100  %, time  0.5832100868225097\n",
      "saved model: embedding_10attr_changed_net\n",
      "epoch 6/10, loss 3.3494584560394287, test_loss 3.398547887802124\n",
      "epoch  7 progress:  6  %, time  0.9051762104034424\n",
      "epoch  7 progress:  12  %, time  0.7359960556030274\n",
      "epoch  7 progress:  18  %, time  0.6844916820526123\n",
      "epoch  7 progress:  25  %, time  0.6583192348480225\n",
      "epoch  7 progress:  31  %, time  0.6706122398376465\n",
      "epoch  7 progress:  37  %, time  0.6814873218536377\n",
      "epoch  7 progress:  44  %, time  0.7272260665893555\n",
      "epoch  7 progress:  50  %, time  0.8021928787231445\n",
      "epoch  7 progress:  56  %, time  0.7197895050048828\n",
      "epoch  7 progress:  62  %, time  0.6871223449707031\n",
      "epoch  7 progress:  69  %, time  0.8297791957855225\n",
      "epoch  7 progress:  75  %, time  0.6841384410858155\n",
      "epoch  7 progress:  81  %, time  1.0093549251556397\n",
      "epoch  7 progress:  88  %, time  1.1015244960784911\n",
      "epoch  7 progress:  94  %, time  1.310066318511963\n",
      "epoch  7 progress:  100  %, time  1.1099996089935302\n",
      "saved model: embedding_10attr_changed_net\n",
      "epoch 7/10, loss 3.3190741539001465, test_loss 3.3419928550720215\n",
      "epoch  8 progress:  6  %, time  1.2714256286621093\n",
      "epoch  8 progress:  12  %, time  1.1003756046295166\n",
      "epoch  8 progress:  18  %, time  1.0880122661590577\n",
      "epoch  8 progress:  25  %, time  1.1641838550567627\n",
      "epoch  8 progress:  31  %, time  1.1543768405914308\n",
      "epoch  8 progress:  37  %, time  0.9638762474060059\n",
      "epoch  8 progress:  44  %, time  0.9732157230377197\n",
      "epoch  8 progress:  50  %, time  0.9910478591918945\n",
      "epoch  8 progress:  56  %, time  0.9718321800231934\n",
      "epoch  8 progress:  62  %, time  0.9652907848358154\n",
      "epoch  8 progress:  69  %, time  1.0593499660491943\n",
      "epoch  8 progress:  75  %, time  1.1557979106903076\n",
      "epoch  8 progress:  81  %, time  1.1509341716766357\n",
      "epoch  8 progress:  88  %, time  1.1183130741119385\n",
      "epoch  8 progress:  94  %, time  1.1114799976348877\n",
      "epoch  8 progress:  100  %, time  1.0912675380706787\n",
      "saved model: embedding_10attr_changed_net\n",
      "epoch 8/10, loss 3.2631893157958984, test_loss 3.2873682975769043\n",
      "epoch  9 progress:  6  %, time  0.9447698593139648\n",
      "epoch  9 progress:  12  %, time  0.9186561584472657\n",
      "epoch  9 progress:  18  %, time  0.913857889175415\n",
      "epoch  9 progress:  25  %, time  0.9066763877868652\n",
      "epoch  9 progress:  31  %, time  0.9207248210906982\n",
      "epoch  9 progress:  37  %, time  0.9216293811798095\n",
      "epoch  9 progress:  44  %, time  0.8955203056335449\n",
      "epoch  9 progress:  50  %, time  0.919824743270874\n",
      "epoch  9 progress:  56  %, time  0.9172928333282471\n",
      "epoch  9 progress:  62  %, time  0.9073419094085693\n",
      "epoch  9 progress:  69  %, time  0.9197152137756348\n",
      "epoch  9 progress:  75  %, time  0.8627718925476074\n",
      "epoch  9 progress:  81  %, time  0.9304535865783692\n",
      "epoch  9 progress:  88  %, time  1.2413830757141113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  9 progress:  94  %, time  1.0318858623504639\n",
      "epoch  9 progress:  100  %, time  0.8826215744018555\n",
      "saved model: embedding_10attr_changed_net\n",
      "epoch 9/10, loss 3.1760714054107666, test_loss 3.236891984939575\n",
      "epoch  10 progress:  6  %, time  0.9448145389556885\n",
      "epoch  10 progress:  12  %, time  0.9222382545471192\n",
      "epoch  10 progress:  18  %, time  0.9725105285644531\n",
      "epoch  10 progress:  25  %, time  0.8596037864685059\n",
      "epoch  10 progress:  31  %, time  0.877708101272583\n",
      "epoch  10 progress:  37  %, time  1.029103660583496\n",
      "epoch  10 progress:  44  %, time  0.9160688400268555\n",
      "epoch  10 progress:  50  %, time  0.9403282165527344\n",
      "epoch  10 progress:  56  %, time  0.856281042098999\n",
      "epoch  10 progress:  62  %, time  0.8481643199920654\n",
      "epoch  10 progress:  69  %, time  0.8449550628662109\n",
      "epoch  10 progress:  75  %, time  1.0220286846160889\n",
      "epoch  10 progress:  81  %, time  1.5583725452423096\n",
      "epoch  10 progress:  88  %, time  1.2729849815368652\n",
      "epoch  10 progress:  94  %, time  1.2659714221954346\n",
      "epoch  10 progress:  100  %, time  1.2499197483062745\n",
      "saved model: embedding_10attr_changed_net\n",
      "epoch 10/10, loss 3.100933790206909, test_loss 3.191437244415283\n"
     ]
    }
   ],
   "source": [
    "def train_step(embedding_model, sigmoids_model):\n",
    "    loss_f = tf.keras.losses.BinaryCrossentropy()\n",
    "    optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "    \n",
    "    def test(test_x, test_y):\n",
    "        test_output = sigmoids_model(embedding_model(test_x))\n",
    "        return loss_f(test_output, test_y)\n",
    "    \n",
    "    def train(data, test_data):\n",
    "        val = []\n",
    "        print_every_iter = 5\n",
    "        time_sum = 0.0\n",
    "        test_x, test_y = prepare_embeddings_from_batch(next(iter(test_data)), attributes_subset=attributes_subset)\n",
    "        for epoch in range(epochs):\n",
    "            iteration = 0\n",
    "            for batch in data:\n",
    "                s = time.time()\n",
    "                x, y = prepare_embeddings_from_batch(batch, attributes_subset=attributes_subset)\n",
    "                \n",
    "                @tf.function\n",
    "                def _train():\n",
    "                    with tf.GradientTape() as tape:\n",
    "                        embedding = embedding_model(x)\n",
    "                        output = sigmoids_model(embedding)\n",
    "                        train_loss = loss_f(output, y)\n",
    "\n",
    "                    grads = tape.gradient(train_loss, \n",
    "                                          embedding_model.trainable_variables + sigmoids_model.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(grads, \n",
    "                                                 embedding_model.trainable_variables + sigmoids_model.trainable_variables))\n",
    "                    return train_loss\n",
    "                train_loss = _train()\n",
    "                e = time.time()\n",
    "                time_sum += e-s\n",
    "                if (iteration+1)%print_every_iter == 0:\n",
    "                    progress = (int((iteration+1)*batch_size*100 / train_count))\n",
    "                    iter_time = (time_sum/print_every_iter)\n",
    "                    print('epoch ', epoch+1,'progress: ',progress,' %, time ',iter_time)\n",
    "                    time_sum = 0.0\n",
    "                iteration+=1\n",
    "                \n",
    "            \n",
    "            test_loss = test(test_x, test_y)\n",
    "            \n",
    "            save_model_and_weights(embedding_model, 'embedding_10attr_changed_net')\n",
    "            epoch_res = 'epoch {}/{}, loss {}, test_loss {}'.format(epoch+1, epochs, train_loss, test_loss)\n",
    "            print(epoch_res)\n",
    "            val.append(epoch_res)\n",
    "        return val\n",
    "            \n",
    "    return train\n",
    "        \n",
    "train_f = train_step(model_embedding, model_all)\n",
    "res = train_f(train_data, test_data)\n",
    "\n",
    "with open('representation', 'w') as f:\n",
    "    f.writelines(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.63691133, shape=(), dtype=float32) tf.Tensor(0.75467527, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_iter = iter(test_data)\n",
    "x, y = prepare_embeddings_from_batch(next(test_iter), attributes_subset=attributes_subset)\n",
    "output = model_all(model_embedding(x)).numpy()\n",
    "o = np.array([1 if x > .5 else 0 for x in output[0]], dtype=np.int8)\n",
    "print(f1_m(output, y), recall_m(output, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.640122, shape=(), dtype=float32) tf.Tensor(0.7580257, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6452612, shape=(), dtype=float32) tf.Tensor(0.7538214, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6428267, shape=(), dtype=float32) tf.Tensor(0.75711995, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6461119, shape=(), dtype=float32) tf.Tensor(0.7525794, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64460814, shape=(), dtype=float32) tf.Tensor(0.7521504, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64496326, shape=(), dtype=float32) tf.Tensor(0.765527, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6430703, shape=(), dtype=float32) tf.Tensor(0.75657237, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6395409, shape=(), dtype=float32) tf.Tensor(0.74938875, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6471447, shape=(), dtype=float32) tf.Tensor(0.76352584, shape=(), dtype=float32)\n",
      "tf.Tensor(0.63906133, shape=(), dtype=float32) tf.Tensor(0.7485853, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for batch in test_data:\n",
    "    x, y = prepare_embeddings_from_batch(batch, attributes_subset=attributes_subset)\n",
    "    output = model_all(model_embedding(x)).numpy()\n",
    "    o = np.array([1 if x > .5 else 0 for x in output[0]], dtype=np.int8)\n",
    "    print(f1_m(output, y), recall_m(output, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.65194494, shape=(), dtype=float32) tf.Tensor(0.77441484, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64811194, shape=(), dtype=float32) tf.Tensor(0.782582, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64643544, shape=(), dtype=float32) tf.Tensor(0.7726444, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6515806, shape=(), dtype=float32) tf.Tensor(0.7753126, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6499065, shape=(), dtype=float32) tf.Tensor(0.7749646, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6570112, shape=(), dtype=float32) tf.Tensor(0.782921, shape=(), dtype=float32)\n",
      "tf.Tensor(0.640918, shape=(), dtype=float32) tf.Tensor(0.76916754, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64877635, shape=(), dtype=float32) tf.Tensor(0.77798015, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6494262, shape=(), dtype=float32) tf.Tensor(0.77245873, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6495493, shape=(), dtype=float32) tf.Tensor(0.7770545, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6418312, shape=(), dtype=float32) tf.Tensor(0.7589543, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64996195, shape=(), dtype=float32) tf.Tensor(0.7800729, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6525207, shape=(), dtype=float32) tf.Tensor(0.7843297, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6432698, shape=(), dtype=float32) tf.Tensor(0.76481444, shape=(), dtype=float32)\n",
      "tf.Tensor(0.647197, shape=(), dtype=float32) tf.Tensor(0.7767929, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6460989, shape=(), dtype=float32) tf.Tensor(0.7750816, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6389365, shape=(), dtype=float32) tf.Tensor(0.7603592, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6516029, shape=(), dtype=float32) tf.Tensor(0.7748935, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6537872, shape=(), dtype=float32) tf.Tensor(0.7835577, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64418, shape=(), dtype=float32) tf.Tensor(0.7747803, shape=(), dtype=float32)\n",
      "tf.Tensor(0.648667, shape=(), dtype=float32) tf.Tensor(0.7804481, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6452208, shape=(), dtype=float32) tf.Tensor(0.7772157, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64453447, shape=(), dtype=float32) tf.Tensor(0.77304965, shape=(), dtype=float32)\n",
      "tf.Tensor(0.63652587, shape=(), dtype=float32) tf.Tensor(0.7587115, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6508341, shape=(), dtype=float32) tf.Tensor(0.7757711, shape=(), dtype=float32)\n",
      "tf.Tensor(0.65051603, shape=(), dtype=float32) tf.Tensor(0.7724878, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64978254, shape=(), dtype=float32) tf.Tensor(0.7704752, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6466779, shape=(), dtype=float32) tf.Tensor(0.7702922, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64494604, shape=(), dtype=float32) tf.Tensor(0.76802444, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6488503, shape=(), dtype=float32) tf.Tensor(0.77112323, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64559317, shape=(), dtype=float32) tf.Tensor(0.7713649, shape=(), dtype=float32)\n",
      "tf.Tensor(0.65757364, shape=(), dtype=float32) tf.Tensor(0.7861049, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6458756, shape=(), dtype=float32) tf.Tensor(0.77395177, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6502806, shape=(), dtype=float32) tf.Tensor(0.7716996, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6463, shape=(), dtype=float32) tf.Tensor(0.77921015, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64626426, shape=(), dtype=float32) tf.Tensor(0.7653371, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6560341, shape=(), dtype=float32) tf.Tensor(0.78586024, shape=(), dtype=float32)\n",
      "tf.Tensor(0.65261906, shape=(), dtype=float32) tf.Tensor(0.78088295, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64618766, shape=(), dtype=float32) tf.Tensor(0.77100164, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64356005, shape=(), dtype=float32) tf.Tensor(0.7664085, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6502732, shape=(), dtype=float32) tf.Tensor(0.7754021, shape=(), dtype=float32)\n",
      "tf.Tensor(0.65507036, shape=(), dtype=float32) tf.Tensor(0.78142625, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6429117, shape=(), dtype=float32) tf.Tensor(0.7690278, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6485755, shape=(), dtype=float32) tf.Tensor(0.7749495, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6440764, shape=(), dtype=float32) tf.Tensor(0.7689016, shape=(), dtype=float32)\n",
      "tf.Tensor(0.65299195, shape=(), dtype=float32) tf.Tensor(0.78038895, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6436255, shape=(), dtype=float32) tf.Tensor(0.77262557, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6499957, shape=(), dtype=float32) tf.Tensor(0.77532864, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64803606, shape=(), dtype=float32) tf.Tensor(0.77093047, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6481325, shape=(), dtype=float32) tf.Tensor(0.7752173, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6556274, shape=(), dtype=float32) tf.Tensor(0.78486615, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64616686, shape=(), dtype=float32) tf.Tensor(0.7719085, shape=(), dtype=float32)\n",
      "tf.Tensor(0.646872, shape=(), dtype=float32) tf.Tensor(0.77138764, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6488588, shape=(), dtype=float32) tf.Tensor(0.7722334, shape=(), dtype=float32)\n",
      "tf.Tensor(0.65222514, shape=(), dtype=float32) tf.Tensor(0.7787842, shape=(), dtype=float32)\n",
      "tf.Tensor(0.65983915, shape=(), dtype=float32) tf.Tensor(0.7822597, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6574247, shape=(), dtype=float32) tf.Tensor(0.78159755, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6466863, shape=(), dtype=float32) tf.Tensor(0.7704687, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6520016, shape=(), dtype=float32) tf.Tensor(0.781888, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64669645, shape=(), dtype=float32) tf.Tensor(0.78267974, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6477794, shape=(), dtype=float32) tf.Tensor(0.7715849, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6492778, shape=(), dtype=float32) tf.Tensor(0.77631044, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6396643, shape=(), dtype=float32) tf.Tensor(0.7653689, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6421443, shape=(), dtype=float32) tf.Tensor(0.77127767, shape=(), dtype=float32)\n",
      "tf.Tensor(0.650822, shape=(), dtype=float32) tf.Tensor(0.77879715, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64724857, shape=(), dtype=float32) tf.Tensor(0.77333605, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64500165, shape=(), dtype=float32) tf.Tensor(0.76771575, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6459511, shape=(), dtype=float32) tf.Tensor(0.77965754, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6438367, shape=(), dtype=float32) tf.Tensor(0.7648249, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6563921, shape=(), dtype=float32) tf.Tensor(0.7834741, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6441826, shape=(), dtype=float32) tf.Tensor(0.7623345, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6471434, shape=(), dtype=float32) tf.Tensor(0.77545637, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64667904, shape=(), dtype=float32) tf.Tensor(0.7763051, shape=(), dtype=float32)\n",
      "tf.Tensor(0.65250736, shape=(), dtype=float32) tf.Tensor(0.7843972, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6464526, shape=(), dtype=float32) tf.Tensor(0.7701751, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6523749, shape=(), dtype=float32) tf.Tensor(0.77911645, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6470338, shape=(), dtype=float32) tf.Tensor(0.77637476, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6451114, shape=(), dtype=float32) tf.Tensor(0.76520854, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6538362, shape=(), dtype=float32) tf.Tensor(0.7771452, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64325583, shape=(), dtype=float32) tf.Tensor(0.7655379, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_data:\n",
    "    x, y = prepare_embeddings_from_batch(batch, attributes_subset=attributes_subset)\n",
    "    output = model_all(model_embedding(x)).numpy()\n",
    "    o = np.array([1 if x > .5 else 0 for x in output[0]], dtype=np.int8)\n",
    "    print(f1_m(output, y), recall_m(output, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
