{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_line_run = False\n",
    "if not cmd_line_run:\n",
    "    %matplotlib inline\n",
    "collab_mode = False\n",
    "\n",
    "if collab_mode and not cmd_line_run:\n",
    "    # set up tensorflow in collab\n",
    "    %tensorflow_version 2.x\n",
    "# imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import warnings # This ignore all the warning messages\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from random import randint\n",
    "from os import path\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "print(\"Tensorflow version is\", tf.__version__, \", device name\", tf.test.gpu_device_name())\n",
    "\n",
    "batch_size = 2048\n",
    "image_size = (64, 64)\n",
    "if not os.path.exists('./embedding'):\n",
    "    os.makedirs('./embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attributes_subset = [\n",
    "        'Attractive', 'Bald', 'Bangs',\n",
    "        'Big_Nose', 'Heavy_Makeup', 'Blond_Hair',\n",
    "        'Male', 'Smiling', 'Young', 'Straight_Hair'\n",
    "]\n",
    "\n",
    "def prepare_embeddings_for_training(batch, output_type=tf.float32, attributes_subset = None, use_embedding_net=True):\n",
    "    imgs, attributes = batch\n",
    "    if not use_embedding_net:\n",
    "        return imgs, embeddings\n",
    "    \n",
    "    if attributes_subset is not None:\n",
    "        attributes = {key: attributes[key] for key in attributes if key in attributes_subset}\n",
    "        embeddings = tf.stack(list(attributes.values()))\n",
    "        embeddings = tf.transpose(embeddings)\n",
    "        embeddings = tf.cast(embeddings, dtype=output_type)\n",
    "        return imgs, embeddings\n",
    "    else:\n",
    "        return imgs, tf.image.resize(imgs, (64, 64))\n",
    "    \n",
    "def prepare_embeddings_from_batch(batch, output_type=tf.int8, attributes_subset = None, use_embedding_net=True):\n",
    "    return prepare_embeddings_for_training(batch, output_type, attributes_subset, use_embedding_net)\n",
    "    imgs, attributes = batch\n",
    "    if not use_embedding_net:\n",
    "        return imgs, embeddings\n",
    "    \n",
    "    if attributes_subset is not None:\n",
    "        attributes = {key: attributes[key] for key in attributes if key in attributes_subset}\n",
    "        embeddings = tf.stack(list(attributes.values()))\n",
    "        embeddings = tf.transpose(embeddings)\n",
    "        embeddings = tf.cast(embeddings, dtype=output_type)\n",
    "        print('using net', embedding_net)\n",
    "        return imgs, embedding_net.predict(embeddings)\n",
    "    else:\n",
    "        imgs, _ = batch\n",
    "        return imgs, embedding_net.predict(tf.image.resize(imgs, (64, 64)))\n",
    "\n",
    "def process_image(img, image_shape):\n",
    "    img = tf.cast(img, tf.float32)/127.5-1 # IMPORTANT, image's pixels are in the range <-1, 1>\n",
    "#     img = img[50:(218-50), 40:(178-40)] # crop\n",
    "    # crop 150x150\n",
    "    y_offset, x_offset = (img.shape[0] - 150) // 2, (img.shape[1] - 150) // 2\n",
    "    img = img[y_offset:y_offset+150, x_offset:x_offset+150, :]\n",
    "    img = tf.image.resize(img, image_shape)\n",
    "    return img\n",
    "\n",
    "def load_image(filename):\n",
    "    img = tf.io.read_file(filename)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    return img\n",
    "\n",
    "def convert_from_output_to_image(images):\n",
    "    return tf.clip_by_value((images+1)/2, 0, 1)\n",
    "\n",
    "def display_image_from_dataset(data):\n",
    "    for batch in data.take(1):\n",
    "        image, attributes = batch\n",
    "        img_ = convert_from_output_to_image(image[0])\n",
    "        plt.imshow(img_)\n",
    "        print(img_.shape, np.min(img_), np.max(img_))\n",
    "\n",
    "def save_generated_image(settings, epoch):\n",
    "    save_dir = settings.generated_images_path\n",
    "    if not path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    name = path.join(save_dir,\n",
    "                     'img_{}_{}.png'.format(epoch, get_time()))\n",
    "    plt.savefig(name)\n",
    "\n",
    "\n",
    "def show_images(images, epoch, settings, save_images=False, display_images=False):\n",
    "    print(\"image pixels range\", np.min(images), np.max(images), \"std\", np.std(images))\n",
    "    num_of_images = min(10, images.shape[0])\n",
    "    # (x, y=1)\n",
    "    plt.figure(figsize=(num_of_images, 1))\n",
    "    for i in range(num_of_images):\n",
    "        plt.subplot(1, num_of_images, i + 1)\n",
    "        img = images[i, :, :, :].numpy() #\n",
    "        # img = convert_from_output_to_image(img) # images are already converted in gen_step\n",
    "        # img = (img * 127.5 + 127.5).astype(np.uint8)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    \n",
    "\n",
    "    if save_images:\n",
    "        save_generated_image(settings, epoch)\n",
    "    if display_images and not cmd_line_run:\n",
    "        plt.show()\n",
    "\n",
    "def load_dataset(image_shape, preprocess_images=True, shuffle_size=500, seed=101, split=tfds.Split.TRAIN):\n",
    "    dataset_name = 'celeb_a'\n",
    "    data = tfds.load(dataset_name, split=split)\\\n",
    "               .shuffle(shuffle_size)\n",
    "    # for each image return a tuple (image, attributes), ignore 'landmarks'\n",
    "    if preprocess_images:\n",
    "        data = data\\\n",
    "            .map(lambda x: (process_image(x['image'], image_shape), x['attributes']))\n",
    "    else:\n",
    "        data = data\\\n",
    "            .map(lambda x: (x['image'], x['attributes']))\n",
    "    return data.batch(batch_size)\n",
    "train_data = load_dataset(image_size)\n",
    "test_data = load_dataset(image_size, split=tfds.Split.TEST)\n",
    "\n",
    "train_count = 162770\n",
    "test_count = 19962\n",
    "\n",
    "display_image_from_dataset(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_from_dataset(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 2\n",
    "strides = 2\n",
    "initial_filters = 16\n",
    "input_shape= (*image_size, 3)\n",
    "outputs = len(attributes_subset) if attributes_subset is not None else 40\n",
    "embedding_size = 128\n",
    "epochs = 10\n",
    "\n",
    "model_embedding = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=initial_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides,\n",
    "        input_shape=input_shape),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=initial_filters*2,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=initial_filters*4,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=initial_filters*8,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides*2),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(embedding_size)\n",
    "], name='embedding')\n",
    "\n",
    "model_all = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(outputs, activation='sigmoid', input_shape=(embedding_size, ))\n",
    "], name='all')\n",
    "\n",
    "model_embedding.summary()\n",
    "model_all.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoding_dim = 128  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "attr_encoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(16, input_shape=(outputs,)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    \n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    \n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    \n",
    "    tf.keras.layers.Dense(128),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "])\n",
    "\n",
    "attr_encoder_out = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, input_shape=(128, )),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    \n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    \n",
    "    tf.keras.layers.Dense(16),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dense(outputs, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# attr_encoder.summary()\n",
    "# attr_encoder_out.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 128  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "small_attr_encoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, input_shape=(outputs,)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "])\n",
    "\n",
    "small_attr_encoder_out = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(outputs, activation='sigmoid' , input_shape=(128, ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_weights(model, name):\n",
    "    # save model and its weights\n",
    "    model_json = model.to_json()\n",
    "    with open(\"./embedding/{}_structure.json\".format(name), \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights('./embedding/{}_weights.h5'.format(name))\n",
    "    \n",
    "    print('saved model: {}'.format(name))\n",
    "    \n",
    "def load_model(model, filename):\n",
    "    model.load_weights('./embedding/{}_weights.h5'.format(filename))\n",
    "    print('loaded weights for', filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "def train_step(embedding_model, sigmoids_model):    \n",
    "    def test(test_x, test_y):\n",
    "        test_output = sigmoids_model(embedding_model(test_y))\n",
    "        return loss_f(test_output, test_y)\n",
    "    \n",
    "    def train(data, test_data):\n",
    "        val = []\n",
    "        print_every_iter = 5\n",
    "        time_sum = 0.0\n",
    "        test_x, test_y = prepare_embeddings_for_training(next(iter(test_data)), attributes_subset=attributes_subset)\n",
    "        for epoch in range(epochs):\n",
    "            iteration = 0\n",
    "            for batch in data:\n",
    "                s = time()\n",
    "                x, y = prepare_embeddings_for_training(batch, attributes_subset=attributes_subset)\n",
    "                \n",
    "                @tf.function\n",
    "                def _train():\n",
    "                    with tf.GradientTape() as tape:\n",
    "                        embedding = embedding_model(y)\n",
    "                        output = sigmoids_model(embedding)\n",
    "                        train_loss = loss_f(output, y)\n",
    "\n",
    "                    grads = tape.gradient(train_loss, \n",
    "                                          embedding_model.trainable_variables + sigmoids_model.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(grads, \n",
    "                                                 embedding_model.trainable_variables + sigmoids_model.trainable_variables))\n",
    "                    return train_loss\n",
    "                train_loss = _train()\n",
    "                e = time()\n",
    "                time_sum += e-s\n",
    "                if (iteration+1)%print_every_iter == 0:\n",
    "                    progress = (int((iteration+1)*batch_size*100 / train_count))\n",
    "                    iter_time = (time_sum/print_every_iter)\n",
    "                    print('epoch ', epoch+1,'progress: ',progress,' %, time ',iter_time)\n",
    "                    time_sum = 0.0\n",
    "                iteration+=1\n",
    "                \n",
    "            \n",
    "            test_loss = test(test_x, test_y)\n",
    "            \n",
    "            save_model_and_weights(embedding_model, 'small_embedding_10attr_encoder')\n",
    "            save_model_and_weights(sigmoids_model, 'small_embedding_10attr_encoder_out')\n",
    "            epoch_res = 'epoch {}/{}, loss {}, test_loss {}'.format(epoch+1, epochs, train_loss, test_loss)\n",
    "            print(epoch_res)\n",
    "            val.append(epoch_res)\n",
    "        return val\n",
    "            \n",
    "    return train\n",
    "\n",
    "# previous\n",
    "# train_f = train_step(model_embedding, model_all)\n",
    "# res = train_f(train_data, test_data)\n",
    "\n",
    "# checkpoint = tf.train.Checkpoint(opt=optimizer,\n",
    "#                                 attributes_model=attr_encoder,\n",
    "#                                 attributes_output_model=attr_encoder_out)\n",
    "\n",
    "# checkpointManager = tf.train.CheckpointManager(checkpoint=checkpoint,\n",
    "#                                                    directory='embedding/embedding_10attr_encoder',\n",
    "#                                                    max_to_keep=3\n",
    "#                                                   )\n",
    "# if checkpointManager.latest_checkpoint:\n",
    "#     print(\"restoring state from\", checkpointManager.latest_checkpoint)\n",
    "#     checkpoint\\\n",
    "#         .restore(checkpointManager.latest_checkpoint)\n",
    "# else:\n",
    "#     print('not restored')\n",
    "\n",
    "load_model(small_attr_encoder, 'small_embedding_10attr_encoder')\n",
    "load_model(small_attr_encoder_out, 'small_embedding_10attr_encoder_out')\n",
    "embedding_net = small_attr_encoder\n",
    "train_f = train_step(small_attr_encoder, small_attr_encoder_out)\n",
    "res = train_f(train_data, test_data)\n",
    "\n",
    "with open('representation_autoencoder', 'w') as f:\n",
    "    f.writelines(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(small_attr_encoder, 'small_embedding_10attr_encoder')\n",
    "load_model(small_attr_encoder_out, 'small_embedding_10attr_encoder_out')\n",
    "\n",
    "test_iter = iter(test_data)\n",
    "x, y = prepare_embeddings_from_batch(next(test_iter), attributes_subset=attributes_subset)\n",
    "\n",
    "output = small_attr_encoder_out.predict(small_attr_encoder.predict(y))\n",
    "o = np.array([1 if x > .5 else 0 for x in output[0]], dtype=np.int8)\n",
    "print(f1_m(o, y), recall_m(o, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_data:\n",
    "    x, y = prepare_embeddings_from_batch(batch, attributes_subset=attributes_subset)\n",
    "    output = attr_encoder_out.predict(attr_encoder.predict(y))\n",
    "    o = np.array([1 if x > .5 else 0 for x in output[0]], dtype=np.int8)\n",
    "    print(f1_m(output, y), recall_m(output, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_data:\n",
    "    x, y = prepare_embeddings_from_batch(batch, attributes_subset=attributes_subset)\n",
    "    output = model_all.predict(model_embedding.predict(x))\n",
    "    o = np.array([1 if x > .5 else 0 for x in output[0]], dtype=np.int8)\n",
    "    print(f1_m(output, y), recall_m(output, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_data:\n",
    "    x, y = prepare_embeddings_from_batch(batch, attributes_subset=attributes_subset)\n",
    "    embedding = small_attr_encoder.predict(y)\n",
    "    output = small_attr_encoder_out.predict(embedding)\n",
    "    for y_, output_, emb_ in zip(y, output, embedding):\n",
    "        one_hot_out = [1 if x > .5 else 0 for x in output_]\n",
    "        print(y_, '\\n', one_hot_out, '\\n', emb_)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.convert_to_tensor([[0, 1, 0, 1, 0, 0, 0, 0, 0, 0]], dtype=tf.int8)\n",
    "\n",
    "# embedding_net is used in prepare_embeddings_from_batch\n",
    "embedding_net = model_embedding\n",
    "\n",
    "for batch in test_data:\n",
    "    x, y = prepare_embeddings_from_batch(batch, attributes_subset=None)\n",
    "    x_, y_ = prepare_embeddings_from_batch(batch, attributes_subset=attributes_subset)\n",
    "    break\n",
    "\n",
    "print(y.shape)\n",
    "s = time()\n",
    "# emb = [small_attr_encoder.predict(data) for i in range(batch_size)]\n",
    "emb = small_attr_encoder.predict(y_)\n",
    "e = time()\n",
    "print(e-s)\n",
    "\n",
    "s = time()\n",
    "model_embedding.predict(x)\n",
    "e = time()\n",
    "print(e-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
