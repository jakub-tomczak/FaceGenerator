{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "collab_mode = False\n",
    "\n",
    "if collab_mode:\n",
    "    # set up tensorflow\n",
    "    %tensorflow_version 2.x\n",
    "# imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import warnings # This ignore all the warning messages\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from os import path\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "root_local_path = os.getcwd()\n",
    "root_gdrive_path = '/content/drive'\n",
    "gdrive_project_path = 'My Drive/pp/GSN/FaceGenerator'\n",
    "checkpoints_path = 'checkpoints'\n",
    "dataset_path = 'datasets'\n",
    "dataset_name = \"celeb_a\"\n",
    "tensorboard_logs_dir='tensorboard'\n",
    "download_path = '' # output path for the dataset\n",
    "generated_images_path = 'generated_images'\n",
    "dataset_image_size = (28, 28)\n",
    "run_name = ''\n",
    "gdrive_mounted = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Getting device name\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def allow_memory_growth():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            # Memory growth must be set before GPUs have been initialized\n",
    "            print(e)\n",
    "\n",
    "# run the line below if you're using local runtime and have GTX > 1660 (this is known bug with tensorflow memory allocation)\n",
    "# allow_memory_growth()\n",
    "\n",
    "allow_memory_growth()\n",
    "print(\"Getting device name\")\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OitotiNIkMdu",
    "pycharm": {}
   },
   "source": [
    "Misc helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_time():\n",
    "    return time.strftime(\"%d-%m-%Y-_%H-%M-%S\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n9nTYth-ib_Y",
    "pycharm": {}
   },
   "source": [
    "# Mount gdrive disk if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "if collab_mode:\n",
    "    from google.colab import drive\n",
    "    project_path = path.join(root_gdrive_path, gdrive_project_path )\n",
    "    gdrive_project_path = path.join(root_gdrive_path, gdrive_project_path)\n",
    "    drive.mount(root_gdrive_path)\n",
    "    gdrive_mounted = True\n",
    "\n",
    "def get_base_path():\n",
    "    if collab_mode:\n",
    "        return path.join(root_gdrive_path, gdrive_project_path)\n",
    "    else:\n",
    "        return root_local_path "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if collab_mode:\n",
    "    path_with_imports = path.join(root_gdrive_path, gdrive_project_path)\n",
    "    print(\"Files in path\", path_with_imports)\n",
    "    !ls /content/drive/My\\ Drive/pp/GSN/FaceGenerator\n",
    "    if path_with_imports not in os.sys.path:\n",
    "        os.sys.path.append(path_with_imports)\n",
    "\n",
    "import dataset_helpers as ds_helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D5XPXT_060P8",
    "pycharm": {}
   },
   "source": [
    "### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset download path is D:\\iswd_2\\gsn\\laby\\FaceGenerator\\datasets\\celeb_a\n",
      "Found celeba Data\n"
     ]
    }
   ],
   "source": [
    "def download_dataset():\n",
    "    '''Downloads data to dataset_path/dataset_name directory'''\n",
    "    if collab_mode:\n",
    "        download_path = path.join(root_gdrive_path, gdrive_project_path, dataset_path, dataset_name)\n",
    "    else:\n",
    "        download_path = path.join(root_local_path, dataset_path, dataset_name)\n",
    "    \n",
    "    print('dataset download path is {}'.format(download_path))\n",
    "    ds_helpers.download_extract('celeba', download_path)\n",
    "\n",
    "download_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "download_path = path.join(root_local_path, dataset_path, 'celeb_a')\n",
    "img_path = path.join(download_path, '1k\\\\*.jpg')\n",
    "IMAGE_SIZES = (64, 64)\n",
    "IMAGE_CHANNELS=3\n",
    "IMAGES_SHAPE = (*IMAGE_SIZES, IMAGE_CHANNELS)\n",
    "print(IMAGES_SHAPE)\n",
    "def process_image(img):\n",
    "    img = tf.cast(img, tf.float32)/127.5-1 # IMPORTANT, image's pixels are in the range <-1, 1>\n",
    "    img = tf.image.resize(img, IMAGE_SIZES)\n",
    "    return img\n",
    "\n",
    "def load_image(filename):\n",
    "    img = tf.io.read_file(filename)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    return img\n",
    "\n",
    "def load_dataset(batch_size, preprocess_images=True, shuffle_size=500, seed=101):\n",
    "    data = tf.data.Dataset.list_files(img_path, seed=seed)\\\n",
    "        .shuffle(shuffle_size)\\\n",
    "        .map(load_image)\n",
    "    if preprocess_images:\n",
    "        data = data.map(process_image)\n",
    "    return data.batch(batch_size)\n",
    "    \n",
    "data = load_dataset(batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3) 0.0017558932 0.9879902\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO19aYxk13Xed2rt6r17unt2zojUSKI2LqKphY5Mi5bBKIaZAJZhAQ7kQAaDwAlkxIElJUAABwigIIHh/EiCELYsBZbtKJZlCfImhrYgW7FkDSVK4r4OOfve02ttr25+dHXd75yq97pmpqd6qDofMNP31b3vvlv3vVvvnHvO+Y6EEOBwOH70kdvpATgcjsHAF7vDMSTwxe5wDAl8sTscQwJf7A7HkMAXu8MxJLiuxS4iD4rIcyLyooh8crsG5XA4th9yrXZ2EckDeB7ABwGcAPAdAB8JITy9fcNzOBzbhcJ1nHsvgBdDCC8DgIj8IYCHAKQu9rGx0TAzPQUAyOfNpUV6lwGAf5BCiz5umWYJNUugEftoteg882PX4j7N7yD/MOqyvRTVIQNd/adVmvlAn/1fxbVTYS+d0kdWs77RdyfpDbehi2vvfzv6tM9+f1UdLK1WsV6t92x5PYt9P4DjdHwCwLuzTpiZnsLH//kvAQDGpnepunxphA6MdtFqdIqhsd4pN2urqlmjGY9r1Uu6jxD7qK1XYx/1umpWr9ZiXUP/YDQazZ7lEPTcJo3YR6tlV5VQna5pNvgD/nHS/af96NjzspAk8Vq5nH024nHmA0aX2o7Nn1yu3170oESkZ7nrrIx2+jCr//767O6fj/OpdTwHdjokFyfcjmPz5fn5P/0W0nA996jXrHY9aSLysIgcFZGjq6tr13E5h8NxPbieN/sJAAfp+ACAU7ZRCOERAI8AwMH9e0M+v/GrZn/5tASbLt/qt5p+NYrEY8nZty2J+KBylyqQ9da8+dHvmPltnnVO1pvS8frC9bzZvwPgiIi8QURKAH4BwFe2Z1gOh2O7cc1v9hBCU0T+JYC/xIYS8pkQwlPbNjKHw7GtuB4xHiGEPwPwZ9s0FofDcQNxXYv9qiHS2W2UDHOS3ftjnbKVobPrPtLrWi3eSdf6qrqW2S63x2mfZ6nNvDvfvTXBH2SZ3tJxLTp21/4JWzqzvkzoWex1hb7G8frYI+lvF99+lRu99bF5D7Puv7vLOhxDAl/sDseQYLBifJ/IEq11nRGfkaTWtUK9Z13oEvevH+wYkeX0kiSvB7H1+sHzkSXOvh7E+O5nk8tk+s1QjazSMyjzpr/ZHY4hgS92h2NI4Ivd4RgS7IDO3sfvS5deRLo46UWtkJh2HBFno964nVK0th7PVYJNcVbHS7He/UgjzWRp0R2QczMiXWfXundWu6xn7tpMrv3A3+wOx5DAF7vDMSQYqBgvEORyG5e0MeASyDxjRPACmagSqhM0VbscecbljBjVasbz8iQeNTLMX/2agq7OZNSf6U1rGlZd6S+ePcsTriA6pppxFf5613RWGmzcvuYz6R3zvRW6vSx7o1/zVyujGWshXSpJhogPFYVJfAemWY7q7Hg3VaWsZ9Hf7A7HkMAXu8MxJBhwIAyQz2867NvKdG45FnMyd7pVwEy/pBT9i+Bpfdjd5tfDnvJg0R/N1evAgW7AsJYcpqXS7+l+VEl/szscQwJf7A7HkMAXu8MxJBiw6S16D+VyRh8Bk0Ua/UOZqNhMkU5MmSTaXMWmCq7r9nDL8n5L6z/d/JVFgd8vuvtI73+7dwy2J1org2Of0K9JjWmw7TjsmNK98tI93DKR+ZX7+54WLXU/6btkzHfWc5sGf7M7HEMCX+wOx5Bg8IEwm0EAYsQOMiV0pW5K4Z3LMr29HogQHBr93zM3blpszp170DkcDl/sDsewwBe7wzEkGLDOLpBcGQAQgv6d0fH81tU1kkXmAkW2iY56S1qxneUHUFsELbp2l/Uu3SyXrg+ZaC3K0mk5NIT2I3K2/5RUzI2rMDX1SxTBw7KWzjR0cy6Qy7CpTCgCUeidYnPwqfHbe8ZElXzVYHX2eGIeNpovncRE9aDIJWxdv4QSffLjWzfYlGi5LpdYKtuASRvl2QtbvtlF5DMick5EnqTPZkXkURF5of13ZssrORyOHUU/YvxnATxoPvskgMdCCEcAPNY+djgcNzG2FONDCN8QkcPm44cA3N8ufw7A1wF8YuvLCdAR340Yj3TvICZuE45muwpSh7S0S1eT/ikNVuwTUhOunZc+3UtOe/np/lO90GwfKSqDRS5DguVrFwpafC6XRjpl9ja0agfX2UjFAn2XXI76Nypgo0EqQz79vmeBp607dVO6eK60kND7GbP9Z0E9f13XylJ5tlYhrnWDbncI4XR7cKcBLFxjPw6HY0C44bvxIvKwiBwVkaMrqys3+nIOhyMF17obf1ZE9oYQTovIXgDn0hqGEB4B8AgAHDp4sC+Zqt/0T9nt0sXn/vtID3AZJOw4dDolLT63rPdhCpIcq0ZZ145lKygKicg5uwvOqgYHDRmReGJsLPZhZN21tbVOuVknS4v5zkVSIZoNbaHJoNoz2G6vvGsLtMn2IuS6q39PX+ub/SsAPtoufxTAl6+xH4fDMSD0Y3r7AwB/B+DNInJCRD4G4NMAPigiLwD4YPvY4XDcxOhnN/4jKVUPbPNYHA7HDcRNk7K5X3MYw5rGgjpO9yzL0ouyiCHSPNeseSfrWv1em/voNv1k7Tn07tuatbjLnPUAVHyc6abIkUJ8fMYqZTOOeF6VTKSTk5Op7cbHR1XdxFil1zDQbOp9idWVqNsHU8eeZnpP4GqIOHgOdI3mtu9NQrE10vaarOCdzj3fz16N+8Y7HEMCX+wOx5Bg4GL8pnjTHVMRxZeki4edTTzXhmsz39lR9hnokMFLn8Ujth0okGit+s8IyMkb7ysWd1tkNsvb4SbRzFUZKamqOpnK3njbG/jKqt0q+V4U8vpxXFtd6pSbFAxUyBdVu4mJ8U55fEwP8sraes8x2SCTftFt0uV++uPHv4qrmWtntb1xHnQOh+N1Bl/sDseQwBe7wzEkGHCut4BWbkMHzNlopMC6oXZ5bJFrZz1pdMqJUUQTSuEcLLGFxPOUC2XT6NSkGOVz2teyUaf+k3R308ABWl3kGMRfHyw5QbwdTJ7ZKNZUu2Y1fpeC0T2nx6Jpa21puVOeKFdUu9CqdsqT09ocNjFJOvB0LNcbZhyNOP+ry+uq7k1vjHp6sRjNcouLS6rd3MREp1wyE7lvT4yvYtPh6pq+Vq0ex3X81ElVVyrEvYQKReKtmT44ZXhXsGOeyTf0M6Fdd/n+WVNYPC6Y76mIJ5QNWvfA+wx541oc9xKccNLhGHr4Ync4hgSD96DriOTWaysr7VJvsoYus1mrX5Na78+3CzzGLu+60LsdACRJNA0Fmp+cSWU1NRE9zRrrVVVXJFXm0P7dsXzooGo3Px9FdyuaLi2vxjHRgOtNPd48e+Et6O9ZLEbzGJu8FmanVLtKJaoXRTOONTLLjY5HdQLGVNgkE+Chw7eouvPnLnXKi4uLND776Mf33uLlRVWjvBlz+jxhnS0zKjIjfLDviDtJKfNxel/+Znc4hgS+2B2OIcEOBsKYIBbFuWa3Q4neGRkBLSTBZPHHZQfFcIBLenBBliecCHuxaasAi+7GYQx58n6rVKKo3qwtq3aNahSzD+3drepuPRTF2P379sZzalrcP3c+7lrnctojLUniOF4+Ftu9/PJx1W59PY5jdER/mdtvf1OnfOHihU65UNDvl/HxSF5ht8HvvvvuTvnYqy91ysURHXQzNT0dx1TV33P33GynvHdhrlM+c0bzrSwvxzmurWtGJR7WaqOh6nL0HOgNcvP88e68saC0WkxGkiHS8zNnPQA36zI0CX+zOxxDAl/sDseQwBe7wzEkGLDOHqI+HuzvDOnRXdE+rP9kRKXRYZbOnhWVlt6ufzAXencfpLPn08kil1cudsr7d02rdodveXOnPDejTVkTo9FLrLEa+7hw4YJqtzC/r1N+5dgJVffk0y90ymfPRNPV6pr2oKtU4rVGp8ZVXbMeddvbjxyha72g2k2MRQ+31WW9N/HNv/mrTvlO0t9Pnz2j2kkuzhub/ADgxMlXOuXZ2aizL+yeVe047VexuFfVnT5zulPOWY9Lfm4T3p8xZsoCRcR1PbZpJrU081qvuq3f2/5mdziGBL7YHY4hwc6Z3rrMa2wOM2md2PSmsqxa8x2nhuqXqLu/Zt1I5wPLcXBE189pPK9ozFAsgh44eFunvH96QrWbIHPVaFnfwrOnonmsTP3fsl+Lpt99IorTx0+cUnWtWvR4q5Tjd8lBE1RUiHfOPkijhfhdpsaiuH/QmAr5fk4s6MRCx09E9eLVY1Ec3zU/p9qxyra+vqbq5uejuH6K+tuzW8/HgX17OuVz57TKExbimOWSVjU4KIe9JbtMaCS7J8ar0po+6aSMY/tg5Xq06d3C4XD8iMMXu8MxJPDF7nAMCQZPONlW0XI5E/EVyA3RuJiyqUJa5J4ohryi1aQ6fV3mGhcVeabbqYi4lonMIxdFPs3qYEqbt3naaIwLC1r3PHQg6o2jlagfT02NqHblUtSjz5w8puvovF2Tsf8nvvdD1e7Myainjxq/3XIlfoP5iWjayxkXTf5mTWNqqpSj26ok0Xy3d07r/SdPRHfcYlnr87fsjebB105G89fkuDZF5spxXJNTmnu+0Yz7DzMLM53yq2beDtJDcfjQfj3GU2c75dU1Q4ZKj+ByNervXY7WNHeSNw+net6zzGsRXa7cbb3fmq1Vk9SazcuJHBSRvxaRZ0TkKRH5ePvzWRF5VEReaP+d2aovh8Oxc+hHjG8C+LUQwu0A3gPgV0TkrQA+CeCxEMIRAI+1jx0Ox02KfnK9nQZwul1eFpFnAOwH8BCA+9vNPgfg6wA+sR2D6jKppXC5Wy855ilrZRBgtJSFLsP2ZqUtTlFMppVCFx9YFLHKRe0lN0ZeZ7e9QRNKkJUL87uioFQylpmL56MHWckQPuyejaamHz4RRffGqo7kmiWT3YRJyVSm6DvmOmuaiK8m8emhpMdRKMS21fXLnfL+fbeqdqsrkSiibMyIa1USb0nUXV7W5BJ7p6O4n7OEIKS+Vcpx7ufndulrLV/plE+bFFJzu+Kchpx+Xk6fieOqXYhifE1PFUIrfjexD5bhS7wmZOXdbuOqNuhE5DCAuwB8G8Du9g/B5g/CQvqZDodjp9H3YheRcQBfBPCrIYSlrdrTeQ+LyFERObqysrr1CQ6H44agr8UuIkVsLPTPhxD+uP3xWRHZ267fC+Bcr3NDCI+EEO4JIdyjiAocDsdAsaXOLht+f78D4JkQwm9S1VcAfBTAp9t/v7z15aTjRpiZbtmoH2nMMpmEkxlRb+zJGIz6lGQQA7I7ZCDyxVJBK9XNBnGyT+gfuHe+4/ZOuazVXMxOx7YjZE5aPHdRtSsTj/muGR29dfKVY51ynnTP2XEdlTY+H/cExkY1pzx1jyLZMBuGN16K0YxWM6SY683ottpqEdd/QzPJjBN5Zo3cdAFASJc9dEt0b11a1X2sLkV9e3ZBG4WmyvF7LxFnvVG9kaOotNDS33NlOc7/zJSdq3i9JdL7dXICoJlwvgCkgp/pnNkLymKxiaa49M77sbPfB+CfAvihiDzR/uzfYmORf0FEPgbgNQAf7qMvh8OxQ+hnN/5vkW7df2B7h+NwOG4UdpBw8uZAy4g9SQY5BpsEy5TSqG6426cmo4nnvvf9mKrj1D8TFT39I6Uotq2txOiqvI2SInFOEm22aVLU157ZaF4arWgxvkgmwaLx6MqTjFvIscnSpOUiHWi9rusqIao2q7W4MWvTRM1Oz3fKlxe1ujI1GUXklbXYf8OYxmYofVWlpMkoc8WoGl1JoglwekLPx3kyZza7yFOI276k79kskYe87fZI0vHd7z8NDdYdLVmk0ec617UieQbRStuDMcsA577xDseQwBe7wzEkGDgHHUL6LvkmpCuwhHfZWYQzfamImfSdy0BilN21Z7HexMGgWI4iIovSUyN6x/3eu9/SKe+a1IEZgbLQ7jKpkEokWr927FinfMuCJlpgEfS5J59Sdbt3xWAaTq0UzO96pRx30sXcE2ExnrbmbWbSBmWTLQf9KBVJNG0qLzY9H5w1d9Zkk11ajeI/e7FV61ptmiNvw/KI3i0fGY1BM1cuRTWhZNwSC4U4Xibl2KjjPAD62axXo9rEqa2O3HZYtXvupVc7ZftoclCLqCVp+OWVimkCYTrPvmdxdTiGHr7YHY4hgS92h2NIMHjTW0fnsbmw+NjokK00wklLEUCEf13XJT2d9S67P8AeeqaXJlES1ImoYL9Jh3zbGw7EPhId/rRrNsYLlQra5LJ4KRIdzs1Fk1TFeLitr0Q9sVTQZBC752P/TZrTpjHRlYizPhhTEOuo7MWVGC85Ib03D/09a7ThMT0WdVkxXPnVWvwuTLwBABJYl43jn53RBJzrq9FMOT6u64pEGjE/E3X7Wk2bAPfujsQZr7zysqqbI4LLUkmPsUAK+AjtuRwkAksAWFqJ+wwvHXtV1Y3QPgbvIZnpVhY7MS6AOU/Z7HA4NuGL3eEYEgzc9LbJAd9NUJEunmviifR0y4rYIsP7TWd/MuIQeYWJqUuIz2xyLIrWe3ZrIgQ+b26X5pljU9bEmBbPX3nh+U55gcT4QkOL4BcpNdSUEVvVmGmuKsYklcvgOC+TiZHntGFEdY7TaDV18AgoTdIYmQAvrVxRzSaIE3959bKqm6QxL10hwoqC5uRLkvg9V6/o/lujsW56MposX3vtkmpXLkeVpJjTy2KMvA/zxtutTB51yxQIU65oM+KbjsQ8ACtrmtt+aSke8xNn04MlnFvBqJ8qeikF/mZ3OIYEvtgdjiGBL3aHY0iwA1Fv7eicYEn22OSVngeOibqzdHZbx3op6+9iuNC1uUejQEQOHPxUKFjzXey/aAgIxkgPrVe1njs6EnVR4fxlRsdrkfvpRFnr4mxKLDAZZVcEVS61iuckR985MawLeYrSK04Y91Miuqg2o9mpWNL69spqNIFNT2n34ctXol49QgQhy2Y+ypWo99cMsSZjbCzq3i1jimQP3N3z2j15bTlW7p3SZCF5ylkYCvTsGALIMs3V+Jh2x718mSIcc9G0Z/MRMKGqeWwRNveaMsLe/M3ucAwJfLE7HEOCwYrxIXQifGwEFVLSMgM2ZXN/pjdbl2q+63LkI+HduDDxtVeWoiloakJHco2NxuOulEk0rrVlI3LSkM+cjmQKE0XttTU5EcXWEWMmYhE/Rx5ulmuvQJ53rURPAo+ZRce8SROVL5K4XzbvjYTE+gbx0Le0GH/uYvQavGLMZrumovlqaaXW83MAWGRCDDMfazSpZfJ+mxjTkYotuu9vfOMRVffNb36rU06aeq6YBKQyEsXzlaqOzKuMxzHfdpvmzj95KqorzWZUL4JZnjkyr1lVt8sU1wP+Znc4hgS+2B2OIcGAd+MF+baIKCb4gkVrsYEwtHPPtMTdgTBRFLNJLgN7xrFIa+m/QvzAZokV2o2eJs+vWw4eUO0K5IG2YvjpeHd78ZL2GDt7/ESnXCGRs2h41RrNOAetnB7jKKkQQpaAklEFCiAa6JqhiKYgi1KeVAGTm7RBOY6C8fYqF+KYhfoQk0Jq11Q8b31Npx5YJM8yDhaxASK7KcBlfV1/lyvUx2ojfi8rjgcSkRcvnld1Y2NxrtbXdH6U8jQRZzDPX1W3K9DlZipa7dtFKsXiUlRJmpZzmpZMYtQysWmLe8Df7A7HkMAXu8MxJPDF7nAMCXbAg07o/2tBVmRb6NUssw9rk8rqo0heXPv37+/5uT1xaUmnF64R0UK36TCWS8RLb9MisXmmKyUQmc2KRRqXUfLYjFYx+jzr8Pw2qNXtOKLyzN50ALBMKZmW16Ieann62QQ4Oqq53Fut6B2YI5NaIZ/+9IyP6XvBZBDLPPc2oqwR+7x0Se8dzM5Es9mlJa2LL9HxJO2RWBINvtclk956z54Y4Xjp8kudcrGkdftqg+bfkFfYVNK9sOWbXURGROTvReT7IvKUiPxG+/NZEXlURF5o/53Zqi+Hw7Fz6EeMrwH4QAjhDgB3AnhQRN4D4JMAHgshHAHwWPvY4XDcpOgn11sAsOnqVWz/CwAeAnB/+/PPAfg6gE/00V/K53ywVS+9Tsr2oMvoJP2wKxNsrJyZjEEbiTEnLS5FcbFhRN9nn322U37nW96q6nZNR6ILFvRqxpy0vh6v12zqa1+6GK89Riad2WkdwAHKWjo9M62qmGtundJJWRPdOh0vrWjRl0V8tiA1jLdemYN/RJsYi8VYVyRvQEvEwerKmPGMq65GNeqHTz/ZKV9a1GZPEO9e09htpymNlu2fTX1VCmyanLLtoirTMEE4C5R59pVX43dZ78pqS6blrsxQ2+RBJyL5dgbXcwAeDSF8G8DuEMLpjeuE0wAWsvpwOBw7i74WewghCSHcCeAAgHtF5O39XkBEHhaRoyJydGV1besTHA7HDcFVmd5CCIvYENcfBHBWRPYCQPvvuZRzHgkh3BNCuGd8bLRXE4fDMQBsqbOLyDyARghhUUQqAH4KwH8C8BUAHwXw6fbfL/dzwU1d2hpPQkaq5CySydTr9DGGjQM9EsnYO2Cdad9C5AUXe7Ek6lonj7+iqvYRP/nKko56K+WivrZypbfuDQDV9dh/sPrlVNS/G7SXsLyyqtphLH6XotHFE/qeRSKLXG1oHbLeiNcuFrW+HUK8Nrum1uv6WpOUltlsfSg34VYr7mKsreuGk6Tb15taH2ayyNvfFPdIvvrnf67arVKU2sHDOipt6VI0I46Y/Y0JikBcWIgmtFrd5BBkMpKalnALxTjfc3Nxf+D4qQuqndCqSV8/6U9+P3b2vQA+JyJ5bEgCXwghfFVE/g7AF0TkYwBeA/DhPvpyOBw7hH52438A4K4en18E8MCNGJTD4dh+7IAHXRtdpgMqZojx/ZgYrmoYpr88CUjWy2qMUvmO0v7DkiFdKFB02GhFkzWw91u+qPcw6iSer69weiK9tXKYxMzlFa0KvPjiC/FaxDc/PaN9niokfq4Y82A+xUNtvaFVhvOXI+nC2rIRTcmUtbBnX6d8593vUu2eevqZTvnb33lc1e2ai+bCI8S7Pj6u522JVJT8uh57Qt6Bo+X4nd9113tUuy9+6Uudci5/RtXNMIe/MXXOzUUj1Ardi9U1ra6wKbJqxPjR8ahqTFE0pRXj+VlNrFm4HfWWtTrcN97hGBL4Ync4hgQDFeMFAcW264/l0GJOulYXzXRsm6Ot75whr2DPr5wRaBp8OaFgiZYWt/jaYmig6y3aBafPi0bcX12MIvj501rEP0AibbmoPcG+c/T7nfIo7UTfultnBG1SCqKjT3xf1Z09Gy2gMyS6H3nr21S7CeLNK5rMpMrrj3bmS4a2ukiBK/ZBWqZMs9PkD7i8ru/tyhrd25IOhLm8FO/Nd48+0Snffaf+LjMT0VphEuNiNUepoZbijvvkmA5UObjvcKd86txFVffmt8Utq1dO6Ayv4+Nxji+fONkpz8/Pq3Z1IjFRFN8AEkqVlZM4k6Fl10gKAQv6czr1N7vDMSTwxe5wDAl8sTscQ4KBm942SQtbLcvJTqQURlfR6ZyvlTc+9Cx36zrxk7oxSd16SzR5KTLHvPYee+rEc53ya8dPqbrRUYqWM1sT73r3ezvlCfL8WjdeYQduOdQpv/POu1XdmTPRbMSRVnv2aVJMjgarGw86nn9OG5w3exgl2lfYd8thVTc7GyP4mkT0yKYqACgQkeQthw6qukY96v0TY9GEmdS16Yro69Fs6nvG+vHIKO05VLTSe++7oknwv//276i6hDwH9+zR+yeFIi0huvbioiYtadF+0swubQZdWo36fJU8+WzK5haRtAbz5G7eMcmghfE3u8MxJPDF7nAMCQYsxgdEgcOK8XRsIkvSgmS6+NdUfzaLa+86245THzUamvP9APHDcwqm+oomQqhQVtG1qhYr3/GOO+K1m3oO5iZjkAX/CktR36ZSOYq0t912m6pjk8/aavQse+3VY6rd/t0kZte1VxibfDgYJWlodWKGgm6aRuVZIu865o+7dF5/50sXo5kr19LjGCVeuzxx+JfK2lRYKhPXf06bBxPKA1Ajr8RRw91+4EAUz4+88RZVd2Ux8sjvOXRY90/PFc991aR/YjF+fW1d1RXJy69CgUdNQ5CfcK4ym8bVeeMdDscmfLE7HEMCX+wOx5BgoDp7CFE3b5lcyTotc9Ocl/Rsd7XX3kQWGQbzqSvedeiItYZlWiDsno+67Ad+4n2qbmqCTEhGnz9/NuZ6a1IetboxJ/HU2XGsV6M+OElpgm89sF+1YxIJS77BaZ9LxIm/a0aTVrJp6ML5s6ruylLcx6gTEWPe+LOWKS/e+IR2l+WtiiLp70w+Cej8efm8cXGmqctXyPxqotdGx6KufOcd71B1TzwViSr3HD6s6tjENkJuu3Y/iV2Xz57XpE4tIvdYW2Ozotl3onezzZkQm6Y7zvqb3eEYEvhidziGBAM3vW2K4TbdcpqXnD0OXYTZaZdKT62kYEwWdRKLrSh29kwUVRu3RrG4YMZ77FiMjHrfj71b1Y2SbGpNK61KNME0SNot17Raw+etGO+3sUL8/a4QtxlHhgHAympsVzOmoDkS10sUEWdNhQmpAoVEqxpV4mWfmoriec7MaYlFdWM9KrBKReJ/sWjzbEeIURMKRFqfkIgfjFfiCqVxOnRYe/L99Tf/JvZh7nWV1KZqI5YtWUijFk1x01NTqm5pLc5dU43LPMOkb9mMBptVTl7hcDh8sTscw4Id4KBrU0mL3Y3vHahijwMF8CdJRjBNlwed9CxbLi/eqRfT/yh5rrHHWJJobynepeZgEQAo0Q5/2XoAUsDFikRxLlT1OJokPudMNE2DeOIO77u9U16/orOPLl+OVNUr5O0GAKuX4g7z2Ch5mpnxFomrbn5ql6pbukCBNitxfqamNGnESD7Oh1UTCiPkQUdeeKWCnlNWxRo2wApVKse5SowaycyKJ1wAABpqSURBVCmfpiY1XTSnm1q0c7VMWVyJP27UWAzOnY8BSjMzOhhofDRaTU6d/m6n3Grpe9uiV3MQra7IdqV/cjgcr3/4Ync4hgS+2B2OIcHO8cZnoF9SCktywciKiDMtU2tyhjxgnPi9FbmlGccc6WSS6D5yFIWVmEgxkFNXrknnNcweRjXqcvUVTeSQJ9Pet7/xjU75pZc0UeKhQ29AGmZno+ntAnmI/eAHP1DtWJ8/eECTY3D0Vq0eTVJXLmhShzxdKz+q3z1VIt9g26kl+CxQFFwusfs98d4kZNbKGSKOUSK2qJm00tPTUYe/ckmTUfJzMDUVzW1BjJcfEZxcWdZc/5w5a4RSWK+s6X2WTHKWrbM/9f9mb6dt/p6IfLV9PCsij4rIC+2/M1v14XA4dg5XI8Z/HMAzdPxJAI+FEI4AeKx97HA4blL0JcaLyAEA/wjAfwTwr9sfPwTg/nb5c9hI5fyJ7I6ieN2V+DRhD7p0WSTNhLZxXhY/XSwr81qGtG9Ne3w99gSzwSi1tSimra9oUWydozuMGL+2GtuyCFs1WUsXF2O7RlN70O2bj6QUU5NkChrXaajyiLLj8pIxyy1Frns2I/7E+9+v2hXIjLi6ptUJntdCOba7bExXFy7F4+mcDrQpg7KzIn5Pa1bNV+Oc2kAbDrhiM6sE/Z7jVFldmWApi2511aRuIv75cimqAgWT1XZ8Mn63paVlVcdpo3i+c4ZfPuvZlz48S/t9s/8WgF+H9tLbHUI4DQDtvwu9TnQ4HDcHtlzsIvIzAM6FEB7fqm3K+Q+LyFERObqysr71CQ6H44agHzH+PgA/KyIfAjACYFJEfg/AWRHZG0I4LSJ7AZzrdXII4REAjwDAoYO7tzcFq8Ph6Bv95Gf/FIBPAYCI3A/g34QQflFE/jOAjwL4dPvvl7fqS0A6uzFXsQ7Sr+mtOzou3TTBh9p8l/77UzI50CYno1vj0nLUu/LQOvXSYky1e+GM1pUn83EfoLmqJR0mlEhojGsmsu38lWi+OnLkjaquTKmkm0k8b7qo9eFQj/M9NqUj4nivggk8usyZFH02Oq1dTDmXX3U96rm7KntVuzNnIq9+uKyJO9nkNULXbtkdH5qfUlnrysKklWyya+nvwrp+wzw7o2xGXNb69iqReqo8e/OaX36UyDkTs1/ApJt6n6j/d2Pn3mTsQV2PU82nAXxQRF4A8MH2scPhuElxVU41IYSvY2PXHSGEiwAe2P4hORyOG4GBc9BtRvLYlM1B8cKlp2xOQhSZG0YUU8H9RlRi0guhyLm8NWGQOLdqPJ3OnD/dKR9ciCL9+rI2J4Eikp5//hVVdXA+pmyuVbV4zqmLamRSu3T+gmq3f28UhUtFrSYwtVq+GM1C1jxYZgtgTZsAE4q2atWJ8MGIiCzWlyp6HAnN9+RUVC0uEwc7AOzaHaPllq7oeVyqRpNgcSyqE3ljkmpS5F/S0vc9aRJ3HZ9nvPACyb/sxQYAhynd1qm/P6rq2AyY0BSPFDQvPShtdcHkAaiMkGlvPYrxjZbxvmR+PZs7bDPV83Z40Dkcjtc3fLE7HEOCwXPQtcWeLJ65Lm5jOmZRPWvnse8RmZ3XBnlSjYxpUWx1Le68QiKP2JrhcGN5t2REQuYwK5jdfs7oUydOt4kpTbE8NRVVCJvps067uefOxN3hK5f1LvIoieBN4zFWKMTHQhF9GNFRqF3e0G4XyxWqi19sdEy3y9N8MJ0zoINVyiNxl91+ZxZvbYBLi608uXQPNGWBMOQYtxyInHQvvviSqnv++Xi8ay5+t9PHj6t28/ycGTG+2ohz0Mp4plllsFyMmxpK1pLwN7vDMSTwxe5wDAl8sTscQ4KBk1dEnT3dSy7tnK37vvrxJIaogMO16iZF8dJK1Nmr9VhXLGu9vNCKult1WUdJrZO319yk1sWFTIylUSJkEK1vLxLJ4dmzmpRifmF3p1wZi7r9zIwmhKyQ/loz6YWbRPzIOrDVc1mHFMO/nyvE8a9X4xxcuKBNb2u1+F3mF7QX3thoNB1yWmOrs7MXpCU0ydEzkWeN1jwrHGHWMvd9cizep7ve8U5Vd+ls/D5V8qYbqWivxGX2DhzRewLlybj/w/tEl1f1fckp26fllNd/e8Hf7A7HkMAXu8MxJBisBx2imGVFbha/rCgWUkwOWTxzfasFYkw1TIBh6i4RacQ6eZ3ljOx04Vw0eZ0/eUbV7aW0QLsmb1N1LJ6WyWQ3OW28Aa9EcfGOu+5UdeMkElZrFHRjRFOsxz7yJp2S5HubqKxZi010NmgoYY+0UcoEu6B548+ej5lrKxUt3o4Sxx1nas1SAbueHT4gmd6aflkVsKrdOBFU7D+ks+H+45/7J53yd47GKPDjZ7TXo7Ti/ayuas/JJbo3DXaBNPPN/PgtY2Tr8Ma7B53D4fDF7nAMCXyxOxxDgsGa3gJS3WVbmWSRaeQVuvtWqz/CSV1n9H7KKdYwhJCBzDNN0uvWr1xR7U6djamdays6co7dZa1rJJMycO6xnCFRnFBEktp8p/PicYpfyzMe+09sAmB+BdAYpWB1yFi0LrccVTZCungr6DmdmY17GEmiI/N4j0Dx9Oes6S39vhum0VhsWpdsIvOoaDfpJ5/8YTwY00smJ/H47nff2yk/+3++qLtP4n0Ked0Hk1esVOP8BHvPkL43kctlKOubbbZs4XA4fiTgi93hGBIMVIwXCcjl2+JGYuvItGKC9hH4mMVUk9KW+rTccoH6UGWTLohNPFZqbTWiR1OVvMKaRiTcMxu91Q697e2qbmSURFojzgUSfeskzklTD2RiPIrxBdF9cMrmQCYde6Pr9OVsFq2iiWDr9GdMnU0+zOkbyk5udeZuN6K65KLJLjT0QOp1S2KygUIhPV9AlzVW4vV4vqs2aqwYPd7WWnq2vvC1v+2Un37uhKrbvy96/d1919s65eNntMl1F0VrTs7tU3XLZIlrUqqvnFEx+fmWnL5HIct1rtOfw+EYCvhidziGBAP3oNsUubo9mFgMTM/Oes3XTqWZNjueTdqxNWNcXY9i/LPPvdgpH7lFZzDNES/cydNnVd03/+b/dcr/4pd/WdVVGxRIUYpi2lojnSNOmka0piAWHTBiUiaRalAwu9sgETeLSlrPohbjC+R9qDb3jVcYU2ZrAV/v8FvvPdWHSdPFyNH4G3xvE5P+CfFazzz/vKq7eDlaVEamtAfgmUsxSGl0JqbeKo9r6u6Ffbd2ykvr2oOuTlYfZU0xknlWoFc/QWD+Znc4hgS+2B2OIYEvdodjSDBw8opNTa+VwQ0PsZFLbFrJiHBS0WxIryNYPZRVw3wwZi0igVwi/f1d7/5x1e7//knMhFVd0h50r56MEXEnz2p9/tC+GFHVUqmY7R4GkVyUtQmmQBFsTTLD1WpaI85zRJ8xAfK8svnH8rXzjOYMoUTaeGvrmpBB6dtZZIs0JsuBnxUxmSTUaT6a+aomCrA4Gk1vv/8Hf6Tq6jSwQ0e0KTVpRBPsydORyEIKmtDkxJnoJRcsKaa1fW62S3fy6/Ku64d9td/87McALGPDOt4MIdwjIrMA/jeAwwCOAfj5EMLltD4cDsfO4mrE+J8MIdwZQrinffxJAI+FEI4AeKx97HA4blJcjxj/EID72+XPYSMH3CeyTwkd8T2ExNSQ51cXp3yzZ112wEz2SNKQzvKlUwSt1+N4/+dnPqvaTZZiIMX05Iyqu+N97+2UH3/6GVW3e19M65SwaNfSIuc6ZUW1Im2Fgjg402zDiPGhyXOaPo9robcZDgDyijdevzd0EAul7DKpplgcbdl8Aan9mWcn474n+TjmOs1VuTKp2l1ejOrW4pLOAzC3O2ZkXVm+qOr2zM9SXQyIWjXZXncRH+Bq1cxB2sPaJZlfX6KEft/sAcDXRORxEXm4/dnuEMJpAGj/XbiukTgcjhuKft/s94UQTonIAoBHReTZfi/Q/nF4GABmpse2aO1wOG4U+nqzhxBOtf+eA/AlAPcCOCsiewGg/fdcyrmPhBDuCSHcMz420quJw+EYALZ8s4vIGIBcCGG5Xf5pAP8BwFcAfBTAp9t/v5zeC6O3u2y2Lt5vO25o9ZsU01tfrTbA0W1F0gWt4eQ0kRFIURMxThBneGLcYJ96Mbrg7luIrpeTxjTGpIT1una9rNWivrlObpk2/TSa6S6mDGUWMvPN+d0KJW16S3PVtfedTZ/5kjEBqmg53tNJv0vWlFqj/Y4C8fuXDNf/2ZdjNNv0jN5nGafcenNzmtv+PJlPC6UctZtT7XgPJjFmv7SANUt4er2pDfsR43cD+FJ7EgsAfj+E8Bci8h0AXxCRjwF4DcCHr3MsDofjBmLLxR5CeBnAHT0+vwjggRsxKIfDsf0YbNRbCB0zjI5ys+3sB1GcCUzcFqy5J5abTasmcDle24rgigQg0YJTQaLYmlD/dWMKqoxGse/MxUVVd5rEuYmyFvEvXPhep/z+9/xYp3xgRkdQCXnXhfqqqkuaUTVYXYsmuivGFFRfi55sYiaczXl5miDLDZ8n77288eTjtln8/lxXyOs+Rog7Xygtc2JUAVYZbIrsMUodXR6PG8SNplZ/zpyPW05NQwhSb8RrL13SfINXiMP/wG0xD0DLeBsur0U1Ksnp/kV6b511fXqd2crdN97hGBL4Ync4hgS+2B2OIcGAo95CXymbM3N5ZbRT/OFdhJNp10Jf7Xodb6LL3JNEfbBhovuEpvziuk7nPEIuw3/17W91yj/3wE/pcdTieUsXdORcnvRZzhdn2Wjq5Jpar2n9lVEqR1PhuOGor4xH19yCSUPM94KZWKyrq4pYM9GO7CLL38WaqtiNt1ypqLpSKR4npBuHvN5/eO7ZmPq6XNSutONj851yra7dSUbGY1tO6Z2YFNaK893sNWUGDPaJzrrKMB77m93hGBL4Ync4hgQDFuMl1QzDn9smWaYbhiYlTI+MMiNSx0kmEQL3ySQaRtxHekQZW/MKBS1K1oiXfpk41JsmGmxuPnpnTY1p8bm2Ek1sRYpKm5rSnl+Lly/FMdV1RByb3kok/o+P69iGCh2XRrX4zNCEiumiek60PFsmFaLIZkojIhdU9J0237GJN5fvHYkHAGuUwnpiYkrVLa3GOa2a86Zm4rzWW+QRKfaZSB1+Krof2WsM5dy87nWd7XA4Xjfwxe5wDAkGvhu/KcZl7rh37aSnZXHNamd941hNoFRTRjRisTJL5NSZQ007cJ0ehQoP6TIFxP4bddrNNkQf4zNRzEzMHZwai+J0oEyzdUMa0SSVobamyRoajbg7z/fCir5Zblw8V7xbnjdbz1kedOq8Yvyi7E1nYQXdPPXZVC5ohscuRAtHMO9AJiqZ2rNf11Xj3HF22WB9MyU9oCgrsGc74W92h2NI4Ivd4RgS+GJ3OIYEg9XZQ4wqaxk9pUmeZi2T/pezKock/fdJmcZChlsS9wcbHZee/lfp+hl6Vp105aIhr+DtiJaJzEvI2a5Qih5jK1VrHozfrWwi50KN5oD01YqJWEtaUS+3adQarajPsllOSrphcST2XzTEE0L2paKkP2Y5zglnTJEFNqPR3Cet9Ki30LXPEidcOHoy0fsUzWY0RdYT7fU4t/CGTvnyuo4eLJAnnkppbZ4PCbxHoJ/NlspPwOO/CmqVzT2BjCb+Znc4hgS+2B2OIcHAPeg6YjwyTG/W64yOmypSxfxWsZhmxfM0y0caAZhth3TR3Yr7LLozmQQAFCgtUK6gxblKmQJLSKRtNPR3ESLREPt7TYNpkRjYMoMskppQMurEyEgUY2u5OP5gPNwarK6YcbBnYo7IGrrSbbFqZPSJ0KfnZFbK5jqpIZWxGMhTC5r04+c/8qFO+dg5naLqsW883SmXJjQ/HafILuQ4vbUeB98na+4VsWbidrtuFpee7bau24C/2R2OIYEvdodjSOCL3eEYEgyWcHIbyCuu+dqphBX9990veQWnQx4Z0ZFiJdLLx43+d/bshU75yaeinvgP7niLardWjTplMW/1XNINaQ+jZcw4Qvp3zhAg5mm/oEh7GjYtM+e+E6Nv8zGfl7PteO4y6rKeAdbZbf/5QoycE3I7zkPr5WdOvdQp3/fAQ6ruM1/4Wqc8k+g5mJvZ3SnX63Gvo1SwS4vHleFKmwmPenM4HH3AF7vDMSQYuAfdpsjVzRFHnk5dJpeUuj5NM5lDugp1QhEtWLczwvxcTGg7ZnjbVlaj59q3Hn9C1V24dLlT5mizqZl51Q4UXZWI5bgjcxuNsYubnERrMeJ5jkTQUgZBmpD4b3nSmUSCTWrWvKbEf5NLgMVzJqiw0YiFLpE5gu9hQqmyGjXN/zdKeQhffPmYqmvQc3bmok7ZXG/GugPz+2jwJsVTYJXH2uV6R3za75n1uLdaW6+Fvt7sIjItIn8kIs+KyDMi8l4RmRWRR0Xkhfbfma17cjgcO4V+xfj/CuAvQghvwUYqqGcAfBLAYyGEIwAeax87HI6bFP1kcZ0E8H4AvwQAIYQ6gLqIPATg/nazzwH4OoBPbNVfP7vx/aJlSCM0oUR//WV5yeUsHTCJWKOjcVd9z549qt3aWmz3raNPqbqTZyMVcWJ+a6uIouR6PQZqXLp8WbVr7I68Z8VRfQubTRanqX/j/caie86IwQUKmmF1pdnUoil7QSbGCy+f6z2PXR5/LN4aOZXvBV/bjiNTvZKeRYyYoJu73n53p/xf/tefqbpGQm2Luv9LizEdVG0tjuuW3fqZGCnQeV3Pfu/gqyx11qIfnsZ+3uy3AjgP4HdF5Hsi8tvt1M27QwinNwYbTgNYyOrE4XDsLPpZ7AUAdwP4HyGEuwCs4ipEdhF5WESOisjR1bX0ZAQOh+PGop/FfgLAiRDCt9vHf4SNxX9WRPYCQPvvuV4nhxAeCSHcE0K4Z2y03KuJw+EYAPrJz35GRI6LyJtDCM9hIyf70+1/HwXw6fbfL2/ZF1oI7SD+YExGyHHqJmO2YI52KocMs1DBmCKYGj0h3bvZsjoekT6aYKr1tdjJifMxFfNjf6v18jrpx3mjQzKpoiWq5LROFdJ5z124oNpJPaZwrtl0SimRV9ZjrEZ6dN3sTTQpGo91wZYhoeB5LBlSzCaRU3IEYsgwkxWN2pmn6yVEuJ83xCQ5Ns1a7zSKOmzl45ia5tG/sBr7ePyp06ouoQjBppnvAnspVqPk+uLJU6rdwb17O+VyxXgz0tcRzltgUocVOZLQeERaD8le6NfO/q8AfF5ESgBeBvDPsCEVfEFEPgbgNQAf7rMvh8OxA+hrsYcQngBwT4+qB7Z3OA6H40ZhwOQV0ZwiLWtGyCKliEU+r9nQYo4iMUi0WMPmpTyJ+JeXVlS7k2fOd8qLi5pv7MpyFLPzxSjaWe+0kUrv4AtAm41arfQUVay6HDv2impXvO9tsY+m5j9vUp+iUhClZ09lfvmNyt7jaBkRlr81p4yy/Y9wBtYMk2vDzEc+H/tImpy6yZj5aLySM15n+cijz7zuTdEc9U8992ynvGb6D2SmyxsTJog/jrkB6w39TLzw8vFOeW5OZ4mdnY1eliOkMoSWmVN1P9PTS6XBfeMdjiGBL3aHY0jgi93hGBIMOOotRLOaMTsJu00anT1PdQ3S03OGf7tJ+vHSsta3Xz0WTSHnSBdf1XyQaIaoyyWGjDKXj/pUg/TEfEGPt8w2L7s3oajFrf7KzeLB8rLeV3jmmWc65bce2qvqUOid+rpp9L8a2SI5pTLQHW21CUvsKKwDN9P3T9Ki1wCdzy1nTa6kDwfSh+342ERVKOh7lvAeBhFZHDuno9d+9/f/tFNuktsyAAgd52x0GY+LzXCWnJO+24VLmuxycTHe37nZmMdvZlITn0iRTZE2754xZfeAv9kdjiGBL3aHY0ggg0oXCwAich7AqwDmAFzYovkg4OPQ8HFo3AzjuNoxHAohzPeqGOhi71xU5GgIoZeTjo/Dx+HjuEFjcDHe4RgS+GJ3OIYEO7XYH9mh61r4ODR8HBo3wzi2bQw7orM7HI7Bw8V4h2NIMNDFLiIPishzIvKiiAyMjVZEPiMi50TkSfps4FTYInJQRP66Tcf9lIh8fCfGIiIjIvL3IvL99jh+YyfGQePJt/kNv7pT4xCRYyLyQxF5QkSO7uA4bhht+8AWu2wkF/tvAP4hgLcC+IiIvHVAl/8sgAfNZztBhd0E8GshhNsBvAfAr7TnYNBjqQH4QAjhDgB3AnhQRN6zA+PYxMexQU++iZ0ax0+GEO4kU9dOjOPG0baHEAbyD8B7AfwlHX8KwKcGeP3DAJ6k4+cA7G2X9wJ4blBjoTF8GcAHd3IsAEYBfBfAu3diHAAOtB/gDwD46k7dGwDHAMyZzwY6DgCTAF5Bey9tu8cxSDF+P4DjdHyi/dlOYUepsEXkMIC7AHx7J8bSFp2fwAZR6KNhg1B0J+bktwD8OnRq050YRwDwNRF5XEQe3qFx3FDa9kEu9l6MeENpChCRcQBfBPCrIYSlnRhDCCEJIdyJjTfrvSLy9kGPQUR+BsC5EMLjg752D9wXQrgbG2rmr4jI+3dgDNdF274VBrnYTwA4SMcHAJxKaTsI9EWFvd0QkSI2FvrnQwh/vJNjAYAQwiI2svk8uAPjuA/Az4rIMQB/COADIvJ7OzAOhBBOtf+eA/AlAPfuwDiui7Z9KwxysX8HwBEReUObpfYXAHxlgNe3+Ao2KLCBPqmwrxeywcv8OwCeCSH85k6NRUTmRWS6Xa4A+CkAzw56HCGET4UQDoQQDmPjefirEMIvDnocIjImIhObZQA/DeDJQY8jhHAGwHEReXP7o03a9u0Zx43e+DAbDR8C8DyAlwD8uwFe9w8AnAbQwMav58cA7MLGxtAL7b+zAxjHj2NDdfkBgCfa/z406LEAeCeA77XH8SSAf9/+fOBzQmO6H3GDbtDzcSuA77f/PbX5bO7QM3IngKPte/MnAGa2axzuQedwDAncg87hGBL4Ync4hgS+2B2OIYEvdodjSOCL3eEYEvhidziGBL7YHY4hgS92h2NI8P8BybMp4nwOiNMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_image_from_dataset():\n",
    "    # Check image\n",
    "    for batch in data.take(1):\n",
    "        for img in iter(batch):\n",
    "            img_ = (img+1)/2\n",
    "            plt.imshow(img_)\n",
    "            print(img_.shape, np.min(img_), np.max(img_))\n",
    "            break\n",
    "            \n",
    "display_image_from_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SKcjsmJF6yxz",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def save_generated_image(epoch):\n",
    "    save_dir = path.join(get_base_path(), generated_images_path)\n",
    "    if not path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    name = path.join(save_dir,\n",
    "                     run_name,\n",
    "                     'img_{}_{}.png'.format(epoch, get_time()))\n",
    "    plt.savefig(name)\n",
    "\n",
    "def show_images(images, epoch, img_size=12, save_images=False, display_images=False):\n",
    "    print(\"saving images with shape\", images.shape, \"image size\", img_size)\n",
    "    print(\"image pixels range\", np.min(images[0]), np.max(images[0]))\n",
    "    fig = plt.figure(figsize=(img_size, img_size * 10))\n",
    "\n",
    "    for i in range(images.shape[0]):\n",
    "        plt.subplot(1, images.shape[0], i+1)\n",
    "        plt.imshow(images[i, :, :, :] * 127.5 + 127.5)\n",
    "        plt.axis('off')\n",
    "\n",
    "    if save_images:\n",
    "        save_generated_image(epoch)\n",
    "    if display_images:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "07vs6jG7ZUqP",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def save_models(generator, discriminator):\n",
    "    def save(epoch_number):\n",
    "        path = get_path()\n",
    "    return save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "id": "7qc4AKp0RFYv",
    "outputId": "5a3b3ae9-9489-4419-b71a-63810acf2ef8",
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open tensorboard with command\n",
      "tensorboard --logdir D:\\iswd_2\\gsn\\laby\\FaceGenerator\\tensorboard\n"
     ]
    }
   ],
   "source": [
    "log_dir_path = path.join(get_base_path(), tensorboard_logs_dir)\n",
    "if collab_mode:\n",
    "    %reload_ext tensorboard\n",
    "\n",
    "    print('tensorboard log dir {}'.format(log_dir_path))\n",
    "    %tensorboard --logdir logs\n",
    "    from tensorboard import notebook\n",
    "    notebook.list() # View open TensorBoard instances\n",
    "else:\n",
    "    print('open tensorboard with command')\n",
    "    print('tensorboard --logdir {}'.format(log_dir_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log_dir = 'logs/gradient_tape/' + get_time() + '/train'\n",
    "test_log_dir = 'logs/gradient_tape/' + get_time() + '/test'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1xwRLPZYmJtL",
    "pycharm": {}
   },
   "source": [
    "Loss functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TnfRHsNBmLsd",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def min_max_discriminator_loss(real_out, gen_out):\n",
    "    real_loss = bce(tf.ones_like(real_out), real_out)\n",
    "    gen_loss = bce(tf.zeros_like(gen_out), gen_out)\n",
    "    return real_loss + gen_loss\n",
    "\n",
    "\n",
    "def min_max_generator_loss(gen_out):\n",
    "    return - min_max_discriminator_loss(tf.ones_like(gen_out), gen_out)\n",
    "\n",
    "\n",
    "def w_discriminator_loss(real_out, gen_out):\n",
    "    res = - (tf.reduce_mean(real_out) - tf.reduce_mean(gen_out))\n",
    "    return res\n",
    "\n",
    "\n",
    "def w_generator_loss(gen_out):\n",
    "    return - tf.reduce_mean(gen_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_layers(model):\n",
    "    for layer in model.layers:\n",
    "            print(layer.name, \":\", layer.input_shape, \"->\", layer.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwrjmA4t6Oxn",
    "pycharm": {}
   },
   "source": [
    "Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QFu3fHge6K86",
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_9 : (None, 64, 3) -> (None, 64, 1024)\n",
      "batch_normalization_63 : (None, 64, 1024) -> (None, 64, 1024)\n",
      "re_lu_71 : (None, 64, 1024) -> (None, 64, 1024)\n",
      "reshape_10 : (None, 64, 1024) -> (None, 16, 16, 256)\n",
      "conv2d_44 : (None, 16, 16, 256) -> (None, 16, 16, 256)\n",
      "batch_normalization_64 : (None, 16, 16, 256) -> (None, 16, 16, 256)\n",
      "re_lu_72 : (None, 16, 16, 256) -> (None, 16, 16, 256)\n",
      "conv2d_transpose_20 : (None, 16, 16, 256) -> (None, 32, 32, 128)\n",
      "batch_normalization_65 : (None, 32, 32, 128) -> (None, 32, 32, 128)\n",
      "re_lu_73 : (None, 32, 32, 128) -> (None, 32, 32, 128)\n",
      "conv2d_45 : (None, 32, 32, 128) -> (None, 32, 32, 64)\n",
      "batch_normalization_66 : (None, 32, 32, 64) -> (None, 32, 32, 64)\n",
      "re_lu_74 : (None, 32, 32, 64) -> (None, 32, 32, 64)\n",
      "conv2d_transpose_21 : (None, 32, 32, 64) -> (None, 64, 64, 32)\n",
      "batch_normalization_67 : (None, 64, 64, 32) -> (None, 64, 64, 32)\n",
      "re_lu_75 : (None, 64, 64, 32) -> (None, 64, 64, 32)\n",
      "conv2d_46 : (None, 64, 64, 32) -> (None, 64, 64, 3)\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 64, 1024)          4096      \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 64, 1024)          4096      \n",
      "_________________________________________________________________\n",
      "re_lu_71 (ReLU)              (None, 64, 1024)          0         \n",
      "_________________________________________________________________\n",
      "reshape_10 (Reshape)         (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 16, 16, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "re_lu_72 (ReLU)              (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_20 (Conv2DT (None, 32, 32, 128)       819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_73 (ReLU)              (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 32, 32, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_74 (ReLU)              (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_21 (Conv2DT (None, 64, 64, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu_75 (ReLU)              (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 64, 64, 3)         99        \n",
      "=================================================================\n",
      "Total params: 2,724,291\n",
      "Trainable params: 2,721,283\n",
      "Non-trainable params: 3,008\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, input_shape, model_name=\"Generator\", **kwargs):\n",
    "        super(Generator, self).__init__(name=model_name, **kwargs)\n",
    "#         print(\"input \", input_shape)\n",
    "        self.noise_decoder = tf.keras.Sequential([\n",
    "            # flat\n",
    "            tf.keras.layers.Dense(1024, input_shape=input_shape),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Reshape([16, 16, 256]),\n",
    "            # conv without stride (16x16)\n",
    "            tf.keras.layers.Conv2D(256, 5, 1, 'same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            # t_conv with stride (32x32)\n",
    "            tf.keras.layers.Conv2DTranspose(128, 5, 2, 'same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            # conv without stride (32x32)\n",
    "            tf.keras.layers.Conv2D(64, 5, 1, 'same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            # t_conv with stride (64x64)\n",
    "            tf.keras.layers.Conv2DTranspose(32, 5, 2, 'same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            # conv without stride\n",
    "            tf.keras.layers.Conv2D(3, (1, 1), 1, 'same')\n",
    "        ])\n",
    "        print_layers(self.noise_decoder)\n",
    "\n",
    "    def call(self, noise, training):\n",
    "        return self.noise_decoder(noise)\n",
    "    \n",
    "    def summary(self):\n",
    "        self.noise_decoder.summary()\n",
    "\n",
    "generator_input_shape = (64, 3)\n",
    "generator = Generator(input_shape=generator_input_shape)\n",
    "# generator.build((None, *generator_input_shape))\n",
    "generator.summary()\n",
    "\n",
    "# generator = Generator(input_shape=IMAGES_SHAPE)\n",
    "# generator.build((None, *IMAGES_SHAPE))\n",
    "# generator.summary()\n",
    "# tf.keras.utils.plot_model(generator, \"gen.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8N1JmZB06SKO",
    "pycharm": {}
   },
   "source": [
    "Discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "16ATdVrY6UId",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, input_shape, model_name=\"Discriminator\", **kwargs):\n",
    "        super(Discriminator, self).__init__(name=model_name, **kwargs)\n",
    "\n",
    "        # since discriminator is for classification it should be robust, thus, add\n",
    "        # additional regularization like dropout to prevent from pixel attacks\n",
    "        self.image_encoder = tf.keras.Sequential([\n",
    "            # conv with stride (32x32)\n",
    "            tf.keras.layers.Conv2D(64, 5, 2, 'same', input_shape=input_shape),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            # conv with stride (16x16x128)\n",
    "            tf.keras.layers.Conv2D(128, 3, 2, 'same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            # flatten + hidden layer\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(64),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            # prediction (LOGITS!)\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        print_layers(self.image_encoder)\n",
    "\n",
    "    def call(self, images, training):\n",
    "        return self.image_encoder(images)\n",
    "    \n",
    "    def summary(self):\n",
    "        self.image_encoder.summary()\n",
    "\n",
    "# discriminator = Discriminator(input_shape=IMAGES_SHAPE)\n",
    "# discriminator.build(input_shape=(None, *IMAGES_SHAPE))\n",
    "# discriminator.summary()\n",
    "# start_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uX4rm1S_6Yfj",
    "pycharm": {}
   },
   "source": [
    "Noise generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S6YpknpB6a0C",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "class NoiseGenerator(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, num_classes, distribution_size):\n",
    "        super().__init__()\n",
    "        self.distribution_size = distribution_size\n",
    "        # self.data_distributions = self.add_weight(shape=(num_classes, distribution_size), trainable=True)\n",
    "        # self.data_distributions = tf.tile(tf.range(0, num_classes, dtype=tf.float32)[:, tf.newaxis], [1, distribution_size])\n",
    "        # TODO:\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # dists = tf.nn.embedding_lookup(self.data_distributions, inputs)\n",
    "        # dists += tf.random.uniform(tf.shape(dists), -0.35, 0.35)\n",
    "        # return dists\n",
    "        # TODO\n",
    "        return tf.random.uniform([tf.shape(inputs)[0], self.distribution_size, 3])\n",
    "        \n",
    "    def diverse_distributions_loss(self):\n",
    "        # TODO\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "enYw9PQ_6h_o",
    "pycharm": {}
   },
   "source": [
    "Training step\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OqIPgp5B6jqe",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def train_step_template(generator, discriminator, noise, d_optim, g_optim, d_loss_f, g_loss_f):\n",
    "\n",
    "    @tf.function\n",
    "    def _train_step_template(images):\n",
    "        with tf.GradientTape() as d_tape, tf.GradientTape() as g_tape:\n",
    "            real_out = discriminator(images, True)\n",
    "            gen_out = discriminator(generator(noise(images), True), True)\n",
    "\n",
    "            d_loss = d_loss_f(real_out, gen_out)\n",
    "            g_loss = g_loss_f(gen_out)\n",
    "\n",
    "        d_grads = d_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "        g_grads = g_tape.gradient(g_loss, generator.trainable_variables + noise.trainable_variables)\n",
    "\n",
    "        d_optim.apply_gradients(zip(d_grads, discriminator.trainable_variables))\n",
    "        g_optim.apply_gradients(zip(g_grads, generator.trainable_variables + noise.trainable_variables))\n",
    "\n",
    "    return _train_step_template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "train_data = load_dataset(batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "axR-vkyz6kZa",
    "pycharm": {}
   },
   "source": [
    "Inference step\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r57i63lv6mRT",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def gen_step_template(generator, noise):\n",
    "    @tf.function\n",
    "    def _gen_step_template(data_shape):\n",
    "        return tf.clip_by_value(generator(noise(data_shape), False), -1, 1)\n",
    "\n",
    "    return _gen_step_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8xRLPJoW7IcI",
    "pycharm": {}
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ut1yWYzD7JeR",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def train(train_step, gen_step, epochs, train_data, save_images=True, display_images=True, checkpoint=None):\n",
    "    run_name = 'run_{}'.format(get_time())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for images in train_data:\n",
    "            train_step(images)\n",
    "    \n",
    "        print('Epoch {0}/{1}'.format(epoch, epochs))\n",
    "        if (epoch + 1) % 5 == 0 and checkpoint is not None:\n",
    "            print(\"Saving checkpoint\")\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "        \n",
    "        generated = gen_step(images)\n",
    "        show_images(generated, epoch, save_images=save_images, display_images=display_images)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i1EZ3WMg7ZS0",
    "pycharm": {}
   },
   "source": [
    "Training with Wasserstein loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "cxqxoONqA4ZR",
    "outputId": "c235a412-fe41-40b4-fa73-673d8b55560e",
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_10 : (None, 64, 3) -> (None, 64, 1024)\n",
      "batch_normalization_68 : (None, 64, 1024) -> (None, 64, 1024)\n",
      "re_lu_76 : (None, 64, 1024) -> (None, 64, 1024)\n",
      "reshape_11 : (None, 64, 1024) -> (None, 16, 16, 256)\n",
      "conv2d_47 : (None, 16, 16, 256) -> (None, 16, 16, 256)\n",
      "batch_normalization_69 : (None, 16, 16, 256) -> (None, 16, 16, 256)\n",
      "re_lu_77 : (None, 16, 16, 256) -> (None, 16, 16, 256)\n",
      "conv2d_transpose_22 : (None, 16, 16, 256) -> (None, 32, 32, 128)\n",
      "batch_normalization_70 : (None, 32, 32, 128) -> (None, 32, 32, 128)\n",
      "re_lu_78 : (None, 32, 32, 128) -> (None, 32, 32, 128)\n",
      "conv2d_48 : (None, 32, 32, 128) -> (None, 32, 32, 64)\n",
      "batch_normalization_71 : (None, 32, 32, 64) -> (None, 32, 32, 64)\n",
      "re_lu_79 : (None, 32, 32, 64) -> (None, 32, 32, 64)\n",
      "conv2d_transpose_23 : (None, 32, 32, 64) -> (None, 64, 64, 32)\n",
      "batch_normalization_72 : (None, 64, 64, 32) -> (None, 64, 64, 32)\n",
      "re_lu_80 : (None, 64, 64, 32) -> (None, 64, 64, 32)\n",
      "conv2d_49 : (None, 64, 64, 32) -> (None, 64, 64, 3)\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 64, 1024)          4096      \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 64, 1024)          4096      \n",
      "_________________________________________________________________\n",
      "re_lu_76 (ReLU)              (None, 64, 1024)          0         \n",
      "_________________________________________________________________\n",
      "reshape_11 (Reshape)         (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 16, 16, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "re_lu_77 (ReLU)              (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_22 (Conv2DT (None, 32, 32, 128)       819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_78 (ReLU)              (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 32, 32, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_79 (ReLU)              (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_23 (Conv2DT (None, 64, 64, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu_80 (ReLU)              (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 64, 64, 3)         99        \n",
      "=================================================================\n",
      "Total params: 2,724,291\n",
      "Trainable params: 2,721,283\n",
      "Non-trainable params: 3,008\n",
      "_________________________________________________________________\n",
      "conv2d_50 : (None, 64, 64, 3) -> (None, 32, 32, 64)\n",
      "batch_normalization_73 : (None, 32, 32, 64) -> (None, 32, 32, 64)\n",
      "re_lu_81 : (None, 32, 32, 64) -> (None, 32, 32, 64)\n",
      "dropout_21 : (None, 32, 32, 64) -> (None, 32, 32, 64)\n",
      "conv2d_51 : (None, 32, 32, 64) -> (None, 16, 16, 128)\n",
      "batch_normalization_74 : (None, 16, 16, 128) -> (None, 16, 16, 128)\n",
      "re_lu_82 : (None, 16, 16, 128) -> (None, 16, 16, 128)\n",
      "dropout_22 : (None, 16, 16, 128) -> (None, 16, 16, 128)\n",
      "flatten_7 : (None, 16, 16, 128) -> (None, 32768)\n",
      "dense_11 : (None, 32768) -> (None, 64)\n",
      "batch_normalization_75 : (None, 64) -> (None, 64)\n",
      "re_lu_83 : (None, 64) -> (None, 64)\n",
      "dropout_23 : (None, 64) -> (None, 64)\n",
      "dense_12 : (None, 64) -> (None, 1)\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_50 (Conv2D)           (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_81 (ReLU)              (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_82 (ReLU)              (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                2097216   \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "re_lu_83 (ReLU)              (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,177,025\n",
      "Trainable params: 2,176,513\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_input_shape = (64, 3)\n",
    "generator = Generator(input_shape=generator_input_shape)\n",
    "generator.build((None, *generator_input_shape))\n",
    "generator.summary()\n",
    "\n",
    "discriminator = Discriminator(input_shape=IMAGES_SHAPE)\n",
    "discriminator.build(input_shape=(None, *IMAGES_SHAPE))\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "EHKejxSy7YOx",
    "outputId": "de999bc7-5064-4d75-86e6-487f676dce28",
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'strftime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-775d6b1c983f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Start time\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mget_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-35eba1b27b46>\u001b[0m in \u001b[0;36mget_time\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%d-%m-%Y-_%H-%M-%S\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'strftime'"
     ]
    }
   ],
   "source": [
    "def start_training():\n",
    "    noise = NoiseGenerator(10, 64)\n",
    "    d_optim = tf.optimizers.Adam(1e-4)\n",
    "    g_optim = tf.optimizers.Adam(1e-4)\n",
    "    \n",
    "#     generator.compile(g_optim, g_loss, g_metrics=['accuracy'])\n",
    "    checkpoint = tf.train.Checkpoint(generator_optimizer=g_optim,\n",
    "                                     discriminator_optimizer=d_optim,\n",
    "                                     generator=generator,\n",
    "                                     discriminator=discriminator)\n",
    "\n",
    "    train_step = train_step_template(\n",
    "        generator=generator,\n",
    "        discriminator=discriminator,\n",
    "        noise=noise,\n",
    "        d_optim=d_optim,\n",
    "        g_optim=g_optim,\n",
    "        d_loss_f=w_discriminator_loss,\n",
    "        g_loss_f=w_generator_loss,\n",
    "    )\n",
    "\n",
    "    gen_step = gen_step_template(\n",
    "        generator=generator,\n",
    "        noise=noise\n",
    "    )\n",
    "\n",
    "    train(\n",
    "        train_step=train_step, \n",
    "        gen_step=gen_step, \n",
    "        epochs=30,\n",
    "        train_data=train_data,\n",
    "        checkpoint=checkpoint\n",
    "    )\n",
    "\n",
    "print(\"Start time\")\n",
    "get_time()\n",
    "start = time.time()\n",
    "\n",
    "start_training()\n",
    "\n",
    "end = time.time()\n",
    "print(\"End time\")\n",
    "get_time()\n",
    "print(\"time elapsed\", end-start)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FaceGenerator",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "FaceGenerator",
   "language": "python",
   "name": "facegenerator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
