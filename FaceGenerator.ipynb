{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version is 2.0.0 , device name /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "cmd_line_run = False\n",
    "if not cmd_line_run:\n",
    "    %matplotlib inline\n",
    "collab_mode = False\n",
    "\n",
    "if collab_mode and not cmd_line_run:\n",
    "    # set up tensorflow in collab\n",
    "    %tensorflow_version 2.x\n",
    "# imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import warnings # This ignore all the warning messages\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from os import path\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(\"Tensorflow version is\", tf.__version__, \", device name\", tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def allow_memory_growth():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            # Memory growth must be set before GPUs have been initialized\n",
    "            print(e)\n",
    "\n",
    "# allow_memory_growth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_time():\n",
    "    return time.strftime(\"%d-%m-%Y_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def process_image(img, image_shape):\n",
    "    img = tf.cast(img, tf.float32)/127.5-1 # IMPORTANT, image's pixels are in the range <-1, 1>\n",
    "    img = tf.image.resize(img, (64, 64))\n",
    "    return img\n",
    "\n",
    "def load_image(filename):\n",
    "    img = tf.io.read_file(filename)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    return img\n",
    "\n",
    "def display_image_from_dataset(data):\n",
    "    if cmd_line_run:\n",
    "        return\n",
    "    for batch in data.take(1):\n",
    "        image, attributes = batch\n",
    "        img_ = (image[0]+1)/2\n",
    "        plt.imshow(img_)\n",
    "        print(img_.shape, np.min(img_), np.max(img_))\n",
    "\n",
    "def save_generated_image(settings, epoch):\n",
    "    save_dir = settings.generated_images_path\n",
    "    if not path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    name = path.join(save_dir,\n",
    "                     'img_{}_{}.png'.format(epoch, get_time()))\n",
    "    plt.savefig(name)\n",
    "\n",
    "\n",
    "def show_images(images, epoch, settings, save_images=False, display_images=False):\n",
    "    print(\"image pixels range\", np.min(images), np.max(images), \"std\", np.std(images))\n",
    "    num_of_images = min(10, images.shape[0])\n",
    "    # (x, y=1)\n",
    "    plt.figure(figsize=(num_of_images, 1))\n",
    "    for i in range(num_of_images):\n",
    "        plt.subplot(1, num_of_images, i + 1)\n",
    "        img = images[i, :, :, :].numpy() #\n",
    "        img = (img * 127.5 + 127.5).astype(np.uint8)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    \n",
    "\n",
    "    if save_images:\n",
    "        save_generated_image(settings, epoch)\n",
    "    if display_images and not cmd_line_run:\n",
    "        plt.show()\n",
    "\n",
    "def load_dataset(dataset_path, image_shape, use_manually_downloaded_dataset=True, preprocess_images=True, shuffle_size=500, seed=101):\n",
    "    if use_manually_downloaded_dataset:\n",
    "        img_path = path.join(dataset_path, '*.jpg')\n",
    "        data = tf.data.Dataset.list_files(img_path, seed=seed)\\\n",
    "                              .shuffle(shuffle_size)\\\n",
    "                              .map(load_image)\n",
    "        # for each image return a tuple (image, attributes), in this case we have no attributes\n",
    "        if preprocess_images:\n",
    "            data = data.map(lambda x: (process_image(x, image_shape), dict()))\n",
    "        else:\n",
    "            data = data.map(lambda x: (x, dict()))\n",
    "            \n",
    "    else:\n",
    "        dataset_name = 'celeb_a'\n",
    "        data = tfds.load(dataset_name, split=tfds.Split.TRAIN)\\\n",
    "                   .shuffle(shuffle_size)\n",
    "        # for each image return a tuple (image, attributes), ignore 'landmarks'\n",
    "        if preprocess_images:\n",
    "            data = data\\\n",
    "                .map(lambda x: (process_image(x['image'], image_shape), x['attributes']))\n",
    "        else:\n",
    "            data = data\\\n",
    "                .map(lambda x: (x['image'], x['attributes']))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class Settings:\n",
    "    def __init__(self, collab_mode):\n",
    "        self.root_local_path = os.getcwd()\n",
    "        self.root_gdrive_path = '/content/drive'\n",
    "        self.gdrive_project_path = 'My Drive/pp/GSN/FaceGenerator'\n",
    "        self.dataset_name = \"celeb_a\"\n",
    "        self.subdataset_dir=\"1000\"\n",
    "        self.dataset_image_size = (28, 28)\n",
    "        self.image_size = (64, 64)\n",
    "        self.image_channels = 3\n",
    "        self.generator_input_shape = (self.image_size[0], self.image_channels)\n",
    "        self.gdrive_mounted = False\n",
    "        self.collab_mode = collab_mode\n",
    "        self.batch_size = 10\n",
    "        self.epochs = 100\n",
    "        self.save_models = False # save models at the end?\n",
    "        self.mount_gdrive()\n",
    "        # variables from pytorch\n",
    "        self.init_w = 4 # ?\n",
    "        self.init_h = 4 #?\n",
    "        self.gen_init_filters = 64 # how many filters*2 (channels) should be in the first layer of the generator, n_g number in the paper\n",
    "        self.df_dim = 64\n",
    "        self.gf_dim=self.gen_init_filters # ?\n",
    "        self.z_dim=(100, 100) # size of the vector with normal distribution noise\n",
    "        self.embeddings_shape = (100, 40)\n",
    "        self.n_g = self.gen_init_filters\n",
    "        self.n_d = 64\n",
    "        self.is_conditional=True\n",
    "        self.unconditional_loss_coefficient = 1.0\n",
    "        \n",
    "    @property\n",
    "    def run_name(self):\n",
    "        return 'stack_gan_run_{}'.format(self.subdataset_dir)\n",
    "        # return \"{}_epochs_{}_batch_{}\".format(self.epochs, self.batch_size, self.subdataset_dir)\n",
    "    \n",
    "    @property\n",
    "    def image_shape(self):\n",
    "        return (*self.image_size, self.image_channels)\n",
    "\n",
    "    @property\n",
    "    def download_path(self):\n",
    "        return path.join('.', 'datasets', self.dataset_name)\n",
    "    # def download_path(self):\n",
    "    #     return path.join(self.get_base_path, 'datasets', self.dataset_name)\n",
    "\n",
    "    @property\n",
    "    def dataset_path(self):\n",
    "        return path.join(self.download_path, self.subdataset_dir)\n",
    "\n",
    "    @property\n",
    "    def tensorboard_log_dir(self):\n",
    "        return path.join(self.get_base_path, 'saved_state', self.run_name, 'tensorboard_logs')\n",
    "\n",
    "    @property\n",
    "    def checkpoint_dir(self):\n",
    "        return path.join(self.get_base_path, 'saved_state', self.run_name, \"ckpt\")\n",
    "\n",
    "    @property\n",
    "    def model_save_path(self):\n",
    "        return path.join(self.get_base_path, 'saved_state', self.run_name, 'models')\n",
    "    \n",
    "    @property\n",
    "    def generated_images_path(self):\n",
    "        return path.join(self.get_base_path, 'saved_state', self.run_name, 'generated_images')\n",
    "    \n",
    "    @property\n",
    "    def get_base_path(self):\n",
    "        if self.collab_mode:\n",
    "            return path.join(self.root_gdrive_path, self.gdrive_project_path)\n",
    "        else:\n",
    "            return self.root_local_path\n",
    "\n",
    "    def mount_gdrive(self):\n",
    "        if self.collab_mode:\n",
    "            if cmd_line_run:\n",
    "                print('cmd line run, abort mounting gdrive')\n",
    "                exit(-1)\n",
    "            from google.colab import drive\n",
    "            project_path = path.join(self.root_gdrive_path, self.gdrive_project_path)\n",
    "            self.gdrive_project_path = path.join(self.root_gdrive_path, self.gdrive_project_path)\n",
    "            drive.mount(self.root_gdrive_path)\n",
    "            self.gdrive_mounted = True\n",
    "        \n",
    "            path_with_imports = path.join(self.root_gdrive_path, self.gdrive_project_path)\n",
    "            print(\"Files in path\", path_with_imports)\n",
    "            !ls /content/drive/My\\ Drive/pp/GSN/FaceGenerator\n",
    "            if path_with_imports not in os.sys.path:\n",
    "                os.sys.path.append(path_with_imports)\n",
    "                \n",
    "class DatasetCache:\n",
    "    def __init__(self, use_manually_downloaded_dataset):\n",
    "        self.path = \"\"\n",
    "        self.batch_size = 0\n",
    "        self._data = None\n",
    "        # should it use dataset downloaded manually or the one downloaded by tfds\n",
    "        self.use_manually_downloaded_dataset = use_manually_downloaded_dataset\n",
    "\n",
    "    def load_data(self, settings):\n",
    "        if self._data is not None and self.path == settings.dataset_path:\n",
    "            self.batch_size = settings.batch_size\n",
    "            return self.data\n",
    "        else:\n",
    "            print(\"downloading and loading data\")\n",
    "            if self.use_manually_downloaded_dataset:\n",
    "                self.download_dataset(settings)\n",
    "            self._data = load_dataset(\n",
    "                settings.dataset_path,\n",
    "                settings.image_size,\n",
    "                use_manually_downloaded_dataset=self.use_manually_downloaded_dataset\n",
    "            )\n",
    "            self.data_path = settings.dataset_path\n",
    "            self.batch_size = settings.batch_size\n",
    "            return self.data\n",
    "        \n",
    "    @property\n",
    "    def data(self):\n",
    "        if self._data is None:\n",
    "            return None\n",
    "        else:\n",
    "            return self._data.batch(self.batch_size)\n",
    "\n",
    "    def download_dataset(self, settings):\n",
    "        import dataset_helpers as ds_helpers\n",
    "        '''Downloads data to dataset_path/dataset_name directory'''\n",
    "        print('dataset download path is {}'.format(settings.download_path))\n",
    "        ds_helpers.download_extract('celeba', settings.download_path)\n",
    "        \n",
    "class TensorboardManager():\n",
    "    def __init__(self):\n",
    "        self.log_path = ''\n",
    "        self.train_summary_writer = None\n",
    "        self.test_summary_writer = None\n",
    "        \n",
    "    def initialize(self, settings):\n",
    "        should_be_updated = False\n",
    "        if settings.collab_mode and self.log_path != \"tensorboard_logs\":\n",
    "            should_be_updated = True\n",
    "            self.log_path = \"/content/drive/My Drive/pp/GSN/FaceGenerator/saved_state/run_img_align_celeba/tensorboard_logs\"\n",
    "        elif not settings.collab_mode and self.log_path != settings.tensorboard_log_dir:\n",
    "            should_be_updated = True\n",
    "            self.log_path = settings.tensorboard_log_dir\n",
    "                \n",
    "        if should_be_updated:\n",
    "            self.train_summary_writer = tf.summary.create_file_writer(path.join(self.log_path, 'train'))\n",
    "            self.test_summary_writer = tf.summary.create_file_writer(path.join(self.log_path, 'test'))\n",
    "            print('Initialized tensorboard log dir with path', self.log_path)\n",
    "            self.launch(settings.collab_mode)\n",
    "        \n",
    "    def launch(self, collab_mode):\n",
    "        if collab_mode:\n",
    "            if cmd_line_run:\n",
    "                print('cmd line mode, abort launching tensorboard')\n",
    "                returns\n",
    "            %reload_ext tensorboard\n",
    "            %tensorboard --logdir \"/content/drive/My Drive/pp/GSN/FaceGenerator/saved_state/run_img_align_celeba/tensorboard_logs\"\n",
    "            from tensorboard import notebook\n",
    "            notebook.list() # View open TensorBoard instances\n",
    "        else:\n",
    "            print('open tensorboard with command')\n",
    "            print('tensorboard --logdir {}'.format(self.log_path))\n",
    "            \n",
    "    def save(self, run_type, data, description, timestamp, datatype, step):\n",
    "        '''\n",
    "        run_type: either `train` or `test`\n",
    "        data: represents scalar, images or list of scalars\n",
    "        description: should be of a length of data, i.e. if data is a scalar, description should be a string\n",
    "        datatype: one of 'scalar', 'scalars', 'images'\n",
    "        '''\n",
    "        def _save(writer):\n",
    "            with writer.as_default():\n",
    "                if datatype == 'scalars':\n",
    "                    for value, name in zip(data, description):\n",
    "                        tf.summary.scalar('{}_{}'.format(name, timestamp), value, step=step)\n",
    "                elif datatype == 'scalar':\n",
    "                    tf.summary.scalar('{}_{}'.format(description, timestamp), data, step=step)\n",
    "                elif datatype == 'images':\n",
    "                    tf.summary.image('{}_{}'.format(description, timestamp), data, step=step)\n",
    "                else:\n",
    "                    print('unknown type', datatype)\n",
    "\n",
    "        if run_type == 'train' and self.train_summary_writer:\n",
    "            _save(self.train_summary_writer)\n",
    "        elif run_type == 'test' and self.train_summary_writer:\n",
    "            _save(self.test_summary_writer)\n",
    "        else:\n",
    "            print('unrecognized option `run_type` or selected writer', run_type,'is None')    \n",
    "            \n",
    "class Environment():\n",
    "    def __init__(self, collab_mode):\n",
    "        self.settings = Settings(collab_mode)\n",
    "        self.models = dict()\n",
    "        self.datasetCache = DatasetCache(use_manually_downloaded_dataset=False)\n",
    "        self.checkpointManager = None\n",
    "        self.tensorboard = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading and loading data\n",
      "WARNING:tensorflow:Entity <function load_dataset.<locals>.<lambda> at 0x000001B440D5B438> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: expected exactly one node node, found []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function load_dataset.<locals>.<lambda> at 0x000001B440D5B438> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: expected exactly one node node, found []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function load_dataset.<locals>.<lambda> at 0x000001B440D5B438> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: expected exactly one node node, found []\n",
      "(64, 64, 3) 0.0 0.98545206\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test downloading and loading data\n",
    "\n",
    "dataset = DatasetCache(use_manually_downloaded_dataset=False)\n",
    "settings = Settings(collab_mode)\n",
    "if collab_mode:\n",
    "    settings.subdataset_dir = 'img_align_celeba'\n",
    "dataset.load_data(settings)\n",
    "\n",
    "if not collab_mode:\n",
    "    display_image_from_dataset(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5_o_Clock_Shadow                0.0\n",
      "Arched_Eyebrows                 1.0\n",
      "Attractive                      1.0\n",
      "Bags_Under_Eyes                 1.0\n",
      "Bald                            0.0\n",
      "Bangs                           0.0\n",
      "Big_Lips                        0.0\n",
      "Big_Nose                        1.0\n",
      "Black_Hair                      0.0\n",
      "Blond_Hair                      0.0\n",
      "Blurry                          0.0\n",
      "Brown_Hair                      0.0\n",
      "Bushy_Eyebrows                  0.0\n",
      "Chubby                          0.0\n",
      "Double_Chin                     0.0\n",
      "Eyeglasses                      0.0\n",
      "Goatee                          0.0\n",
      "Gray_Hair                       0.0\n",
      "Heavy_Makeup                    0.0\n",
      "High_Cheekbones                 0.0\n",
      "Male                            0.0\n",
      "Mouth_Slightly_Open             0.0\n",
      "Mustache                        0.0\n",
      "Narrow_Eyes                     0.0\n",
      "No_Beard                        1.0\n",
      "Oval_Face                       0.0\n",
      "Pale_Skin                       0.0\n",
      "Pointy_Nose                     0.0\n",
      "Receding_Hairline               0.0\n",
      "Rosy_Cheeks                     0.0\n",
      "Sideburns                       0.0\n",
      "Smiling                         0.0\n",
      "Straight_Hair                   1.0\n",
      "Wavy_Hair                       0.0\n",
      "Wearing_Earrings                0.0\n",
      "Wearing_Hat                     0.0\n",
      "Wearing_Lipstick                0.0\n",
      "Wearing_Necklace                0.0\n",
      "Wearing_Necktie                 0.0\n",
      "Young                           1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepare_embeddings_from_batch(batch, output_type=tf.float32):\n",
    "    imgs, attributes = batch\n",
    "    embeddings = tf.stack(list(attributes.values()))\n",
    "    embeddings = tf.transpose(embeddings)\n",
    "    embeddings = tf.cast(embeddings, dtype=output_type)\n",
    "    return imgs, embeddings\n",
    "    \n",
    "def describe_embedding(orig_attributes, example):\n",
    "    image, embedding_vector = example\n",
    "    # display image\n",
    "    img_ = (image+1)/2\n",
    "    plt.imshow(img_)\n",
    "    # describe image\n",
    "    for key, value in zip(orig_attributes.keys(), embedding_vector):\n",
    "        print(key, ' '*(30-len(key)), value.numpy())\n",
    "\n",
    "def test_creating_embedding(dataset):\n",
    "    for batch in dataset.data.take(1): # take one batch\n",
    "        # get imgs and embeddings from that batch\n",
    "        imgs, embeddings = prepare_embeddings_from_batch(batch)\n",
    "        # describe first image in the batch and display it\n",
    "        describe_embedding(batch[1], (imgs[0], embeddings[0]) )\n",
    "    \n",
    "# imgs, embeddings = prepare_embeddings_from_batch(batch, settings)\n",
    "test_creating_embedding(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3) 0.0 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_image_from_dataset(dataset.data)\n",
    "if not collab_mode and not cmd_line_run:\n",
    "    !ls \"./datasets/celeb_a/img_align_celeba\" | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noise Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S6YpknpB6a0C",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "class NoiseGenerator(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, distribution_size):\n",
    "        super().__init__()\n",
    "        self.distribution_size = distribution_size\n",
    "        # self.data_distributions = self.add_weight(shape=(num_classes, distribution_size), trainable=True)\n",
    "        # self.data_distributions = tf.tile(tf.range(0, num_classes, dtype=tf.float32)[:, tf.newaxis], [1, distribution_size])\n",
    "        # TODO:\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # dists = tf.nn.embedding_lookup(self.data_distributions, inputs)\n",
    "        # dists += tf.random.uniform(tf.shape(dists), -0.35, 0.35)\n",
    "        # return dists\n",
    "        # TODO\n",
    "        return tf.random.normal([tf.shape(inputs)[0], self.distribution_size, 3])\n",
    "    \n",
    "    def diverse_distributions_loss(self):\n",
    "        # TODO\n",
    "        return None\n",
    "    \n",
    "    \n",
    "class StackGANNoiseGenerator(tf.keras.layers.Layer):\n",
    "    def __init__(self, distribution_size=100):\n",
    "        super().__init__()\n",
    "        self.distribution_size = distribution_size\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # batch_size x distribution_size\n",
    "        return tf.random.normal([tf.shape(inputs)[0], self.distribution_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1xwRLPZYmJtL",
    "pycharm": {}
   },
   "source": [
    "Loss functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TnfRHsNBmLsd",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "kl = tf.keras.losses.KLDivergence()\n",
    "\n",
    "def min_max_discriminator_loss(real_out, gen_out):\n",
    "    real_loss = bce(tf.ones_like(real_out), real_out)\n",
    "    gen_loss = bce(tf.zeros_like(gen_out), gen_out)\n",
    "    return real_loss + gen_loss\n",
    "\n",
    "def min_max_generator_loss(gen_out):\n",
    "    return - min_max_discriminator_loss(tf.ones_like(gen_out), gen_out)\n",
    "\n",
    "def stack_gan_discriminator_loss(real_out, fake_out):\n",
    "    return min_max_discriminator_loss(real_out, fake_out)\n",
    "\n",
    "def stack_gan_generator_loss(gen_out):\n",
    "    return bce(tf.ones_like(gen_out), gen_out)\n",
    "\n",
    "def w_discriminator_loss(real_out, gen_out):\n",
    "    res = - (tf.reduce_mean(real_out) - tf.reduce_mean(gen_out))\n",
    "    return res\n",
    "\n",
    "def w_generator_loss(gen_out):\n",
    "    return - tf.reduce_mean(gen_out)\n",
    "\n",
    "def kl_generator_loss(real, gen):\n",
    "    return kl(real, gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layers for generator and discriminator from StackGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLU(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Multiplies first half of the last dimension\n",
    "    by value of the second half of the last dimension.\n",
    "    Layer introduced in https://github.com/hanzhanggit/StackGAN-v2/blob/master/code/model.py#L47\n",
    "    \n",
    "    Returns the same tensor with its last dimension halved and multiplied by sigmoid function activation.\n",
    "    '''\n",
    "    def __init__(self, **kwargs):\n",
    "        super(GLU, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, data):\n",
    "        rank = data.shape.rank\n",
    "        tensor_shape = data.shape.as_list()\n",
    "        last_dim_half = tensor_shape[-1]//2\n",
    "        # automatic slicing is impossible since the first dimension is None (batch size)\n",
    "        \n",
    "\n",
    "        # begins_1, begins_2 = np.zeros((rank,), dtype=np.int32), np.zeros((rank,), dtype=np.int32)\n",
    "        # begins_2[-1] = last_dim_half # set offset for the last dimension\n",
    "\n",
    "        # sizes = [tensor_shape[i] for i in range(rank)]\n",
    "        # sizes[-1] = last_dim_half # get half of elements from the last dimension\n",
    "\n",
    "        # return tf.slice(data, begins_1, sizes) * tf.math.sigmoid(tf.slice(data, begins_2, sizes))\n",
    "        \n",
    "        \n",
    "        if rank == 2:\n",
    "            return data[:, :last_dim_half] * tf.math.sigmoid(data[:, last_dim_half:])\n",
    "        elif rank == 3:\n",
    "            return data[:, :, :last_dim_half] * tf.math.sigmoid(data[:, :, last_dim_half:])\n",
    "        elif rank == 4:\n",
    "            return data[:, :, :, :last_dim_half] * tf.math.sigmoid(data[:, :, :, last_dim_half:])\n",
    "        elif rank == 5:\n",
    "            return data[:, :, :, :, :last_dim_half] * tf.math.sigmoid(data[:, :, :, :, last_dim_half:])\n",
    "\n",
    "class GeneratorResidualLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, index, **kwargs):\n",
    "        super(GeneratorResidualLayer, self).__init__(**kwargs)\n",
    "        \n",
    "        self.block = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(filters*2, 3, 1, 'same', use_bias=False),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            GLU(),\n",
    "            tf.keras.layers.Conv2D(filters, 3, 1, 'same', use_bias=False),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "        ], name='generator_residual_layer_{}'.format(index))\n",
    "\n",
    "    def call(self, data):\n",
    "        residual = data\n",
    "        out = self.block(data)\n",
    "        return tf.keras.layers.add([out, residual])\n",
    "    \n",
    "class GeneratorUpsampleLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super(GeneratorUpsampleLayer, self).__init__(**kwargs)\n",
    "        self.block = tf.keras.Sequential([\n",
    "            tf.keras.layers.UpSampling2D(),\n",
    "            tf.keras.layers.Conv2D(filters*2, 3, 1, 'same', use_bias=False),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            GLU()\n",
    "        ], name='generator_upsample_layer')\n",
    "\n",
    "    def call(self, data):\n",
    "        return self.block(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwrjmA4t6Oxn",
    "pycharm": {}
   },
   "source": [
    "Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANNetwork(tf.keras.Model):\n",
    "    def __init__(self, model_name=\"Network\", **kwargs):\n",
    "        self.is_conditional = False\n",
    "        if 'is_conditional' in kwargs:\n",
    "            self.is_conditional = kwargs['is_conditional']\n",
    "            # remove that entry from kwargs\n",
    "            # tf raises an exception when a keyword is not from allowed_kwargs set\n",
    "            del kwargs['is_conditional']\n",
    "        super().__init__(name=model_name, **kwargs)\n",
    "        \n",
    "        self.model = None\n",
    "        \n",
    "\n",
    "    def print_layers(self):\n",
    "        print(self.model)\n",
    "        for layer in self.model:\n",
    "            print(layer.name, \":\", layer.input_shape, \"->\", layer.output_shape)\n",
    "\n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "        \n",
    "    @property\n",
    "    def output_layer(self):\n",
    "        return GANNetwork.get_last_layer(self.model)\n",
    "    \n",
    "    @property\n",
    "    def output_shape(self):\n",
    "        return GANNetwork.get_last_layer_output_shape(self.model)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, data, training):\n",
    "        return self.model(data)\n",
    "\n",
    "    def save_model(self, save_path):\n",
    "        if not path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        filename = path.join(save_path, '{}_{}'.format(self.name, get_time()))\n",
    "        print(\"Saving model\", self.name, \"as\", filename)\n",
    "        self.model.save(filename)\n",
    "        \n",
    "    def compile_model(self, optimizer, loss):\n",
    "        self.model.compile(optimizer=optimizer, loss=loss)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_last_layer(model):\n",
    "        return model.get_layer(index=-1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_last_layer_output_shape(model):\n",
    "        layer = GANNetwork.get_last_layer(model)\n",
    "        if layer is not None:\n",
    "            return layer.output_shape[1:] # don't take batch_size into consideration\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class GeneratorInitStage(GANNetwork):\n",
    "    #input_shape = cfg.GAN.Z_DIM + cfg.GAN.EMBEDDING_DIM\n",
    "    # or \n",
    "    # input_shape = cfg.GAN.Z_DIM if without conditioning\n",
    "    def __init__(self, noise_shape, embeddings_shape, filters, settings, model_name=\"GeneratorInitStage\", **kwargs):\n",
    "        # filters should be `gen_init_filters`\n",
    "        super().__init__(model_name, **kwargs)\n",
    "        self.initial_factor = 16\n",
    "        self.filters = self.initial_factor*filters\n",
    "        # if is conditional then the second dimension is has size of concatenated noise and embedding\n",
    "        \n",
    "        self.in_shape = \\\n",
    "            (noise_shape[1] + embeddings_shape[1]) if self.is_conditional else noise_shape[1]\n",
    "#         print('in shape', self.in_shape)\n",
    "        \n",
    "        self.model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(settings.init_w*settings.init_h*self.filters*2, input_shape=(self.in_shape, )),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            GLU(),\n",
    "            tf.keras.layers.Reshape([settings.init_w, settings.init_h, self.filters]),\n",
    "            GeneratorUpsampleLayer(self.filters//2),\n",
    "            GeneratorUpsampleLayer(self.filters//4),\n",
    "            GeneratorUpsampleLayer(self.filters//8),\n",
    "            GeneratorUpsampleLayer(self.filters//16)\n",
    "        ], name='generator_intermediate_init_output')\n",
    "        \n",
    "        self.output_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(3, 3, 1, 'same', input_shape=self.output_shape)\n",
    "        ], name = 'generator_init_stage_output')\n",
    "        \n",
    "    @property\n",
    "    def image_shape(self):\n",
    "        return GANNetwork.get_last_layer_output_shape(self.output_model)\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, data, training):\n",
    "        intermediate_output = self.model(data)\n",
    "        output = self.output_model(intermediate_output)\n",
    "        return intermediate_output, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_embedding_tensor(embedding, output_shape):\n",
    "    '''\n",
    "    Extends embedding tensor to match output shape.\n",
    "    [batch, z] -> [batch, x, y, z], where x, y == output_shape\n",
    "    '''\n",
    "    embedding_shape = embedding.shape.as_list()\n",
    "    # multiply output_shape[0] * output_shape[1]\n",
    "    repeat_factor = tf.math.reduce_prod(output_shape)\n",
    "    res = tf.keras.backend.repeat(embedding, repeat_factor)\n",
    "    reshape_s = [embedding_shape[0], *output_shape, embedding_shape[-1]]\n",
    "    # print(res.shape.as_list(), reshape_s)\n",
    "    # reshape to [batch_size, output_shape[0], output_shape[1], embedding_size]\n",
    "    return tf.reshape(res, reshape_s)\n",
    "\n",
    "class GeneratorNextStage(GANNetwork):    \n",
    "    @staticmethod\n",
    "    def concat_embedding_and_previous_output(embedding, previous_output):\n",
    "        repeat_factor = 1\n",
    "#         print(embedding.shape.as_list(), previous_output.shape.as_list())\n",
    "        if previous_output.shape.rank == 4:\n",
    "            # get second and third dimension\n",
    "            previous_output_shape = tf.slice(previous_output.shape, begin=[1], size=[2]).numpy()\n",
    "        else:\n",
    "            raise(\"Rank of the previous_output is not equal to 4\")\n",
    "        embedding = prepare_embedding_tensor(embedding, previous_output_shape)\n",
    "        print('embedding', embedding.shape.as_list())\n",
    "        return tf.concat([embedding, previous_output], axis=-1)\n",
    "    \n",
    "\n",
    "    def __init__(self, embeddings_shape, number_of_residuals, previous_stage_shape, filters, model_name=\"GeneratorInitStage\", **kwargs):\n",
    "        super().__init__(model_name, **kwargs)\n",
    "        \n",
    "        # size should be equal to\n",
    "        # (init_stage_output_y, init_stage_output_x, init_stage_output_channels\n",
    "        self.in_shape = previous_stage_shape\n",
    "        if self.is_conditional:\n",
    "            # concat embeddings with channel\n",
    "            self.in_shape = (self.in_shape[0], self.in_shape[1], self.in_shape[2] + embeddings_shape[1])\n",
    "        \n",
    "        self.model = tf.keras.Sequential()\n",
    "        \n",
    "        self.model.add(tf.keras.layers.Dense(filters*2, input_shape=self.in_shape))\n",
    "        self.model.add(tf.keras.layers.BatchNormalization())\n",
    "        self.model.add(GLU())\n",
    "        \n",
    "        self.model.add(GeneratorResidualLayer(filters, index=0))\n",
    "        for i in range(number_of_residuals-1):\n",
    "            self.model.add(GeneratorResidualLayer(filters, i+1))\n",
    "        \n",
    "        self.model.add(GeneratorUpsampleLayer(filters//2))\n",
    "        \n",
    "        self.output_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(3, 3, 1, 'same', input_shape=self.output_shape)\n",
    "        ], name = 'generator_next_stage_output')\n",
    "        \n",
    "    @property\n",
    "    def image_shape(self):\n",
    "        return GANNetwork.get_last_layer_output_shape(self.output_model)\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, data, training):\n",
    "        intermediate_output = self.model(data)\n",
    "        output = self.output_model(intermediate_output)\n",
    "        return intermediate_output, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8N1JmZB06SKO",
    "pycharm": {}
   },
   "source": [
    "Discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorEncodeImageLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super(DiscriminatorEncodeImageLayer, self).__init__(**kwargs)\n",
    "        self.block = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(filters, 4, 2, 'same', use_bias=False),\n",
    "            tf.keras.layers.LeakyReLU(alpha=.2),\n",
    "            \n",
    "            tf.keras.layers.Conv2D(filters*2, 4, 2, 'same', use_bias=False),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(alpha=.2),\n",
    "            \n",
    "            tf.keras.layers.Conv2D(filters*4, 4, 2, 'same', use_bias=False),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(alpha=.2),\n",
    "            \n",
    "            \n",
    "            tf.keras.layers.Conv2D(filters*8, 4, 2, 'same', use_bias=False),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(alpha=.2),\n",
    "        ], name='discriminator_encoding_layer')\n",
    "\n",
    "    def call(self, data):\n",
    "        return self.block(data)\n",
    "    \n",
    "class DiscriminatorDownBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.block = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(filters, 4, 2, 'same', use_bias=False),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(alpha=.2)\n",
    "        ])\n",
    "        \n",
    "    def call(self, data):\n",
    "        return self.block(data)\n",
    "    \n",
    "class Dicriminator3x3LeakyReLU(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.block = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(filters, 3, 1, 'same', use_bias=False),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(alpha=.2)\n",
    "        ])\n",
    "        \n",
    "    def call(self, data):\n",
    "        return self.block(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackGANDiscriminator(GANNetwork):\n",
    "    def __init__(self, input_shape, filters, embeddings_shape, output_image_size, model_name=\"StackGANDiscriminator\", **kwargs):\n",
    "        super().__init__(model_name, **kwargs)\n",
    "        \n",
    "        self.filters = filters\n",
    "        \n",
    "        # define intermediate models\n",
    "        self.model = tf.keras.Sequential([\n",
    "            DiscriminatorEncodeImageLayer(filters = self.filters, input_shape=input_shape)\n",
    "        ])\n",
    "        if output_image_size == 128:\n",
    "            self.model.add(DiscriminatorDownBlock(filters=self.filters*16))\n",
    "            self.model.add(Dicriminator3x3LeakyReLU(filters=self.filters*8))\n",
    "\n",
    "        elif output_image_size == 256:\n",
    "            self.model.add(DiscriminatorDownBlock(filters=self.filters*16))\n",
    "            self.model.add(DiscriminatorDownBlock(filters=self.filters*32))\n",
    "            self.model.add(Dicriminator3x3LeakyReLU(filters=self.filters*16))\n",
    "            self.model.add(Dicriminator3x3LeakyReLU(filters=self.filters*8))\n",
    "\n",
    "        self.conditional_model = tf.keras.Sequential()\n",
    "        self.unconditional_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(1, kernel_size=4, strides=4, input_shape=self.output_shape)\n",
    "        ])\n",
    "        \n",
    "        if self.is_conditional:\n",
    "            conditional_input = (self.output_shape[0], self.output_shape[1], self.output_shape[2]+embeddings_shape[1])\n",
    "            self.conditional_model.add(Dicriminator3x3LeakyReLU(filters=self.filters*8, input_shape=conditional_input))\n",
    "            self.conditional_model.add(tf.keras.layers.Conv2D(1, kernel_size=4, strides=4))    \n",
    "            \n",
    "    @tf.function\n",
    "    def call(self, data, training):\n",
    "        if self.is_conditional:\n",
    "            image, embedding = data # if unconditional then embedding == None\n",
    "        else:\n",
    "            image = data\n",
    "            \n",
    "        encoding_output = self.model(image)\n",
    "        \n",
    "        unconditional_output = self.unconditional_model(encoding_output)\n",
    "        unconditional_loss = tf.math.sigmoid(unconditional_output[0,0,0,0])\n",
    "        \n",
    "        if self.is_conditional:\n",
    "            # join embedding and image\n",
    "            encode_layer_shape = self.model.output_shape[1:3] # get y and x of the model output shape\n",
    "            embedding = prepare_embedding_tensor(embedding, encode_layer_shape)\n",
    "            conditional_input = tf.keras.layers.concatenate([embedding, encoding_output], axis=-1)\n",
    "            \n",
    "            conditional_output = self.conditional_model(conditional_input)\n",
    "            conditional_loss = tf.math.sigmoid(conditional_output[0,0,0,0])\n",
    "            \n",
    "            return conditional_loss, unconditional_loss\n",
    "        \n",
    "        return None, unconditional_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models():\n",
    "    is_conditional = False\n",
    "\n",
    "    # test init and next stages\n",
    "    generator_64 = GeneratorInitStage(noise_shape=z_dim,\n",
    "                                    embeddings_shape=embeddings_shape,\n",
    "                                    filters=gen_init_filters,\n",
    "                                    is_conditional=is_conditional)\n",
    "    # generator_64.summary()\n",
    "    # generator_64.output_model.summary()\n",
    "\n",
    "    generator_128 = GeneratorNextStage(\n",
    "        embeddings_shape=embeddings_shape,\n",
    "        number_of_residuals=2,\n",
    "        previous_stage_shape=generator_64.output_shape,\n",
    "        filters=gf_dim,\n",
    "        is_conditional=is_conditional)\n",
    "    # generator_128.summary()\n",
    "    # generator_128.output_model.summary()\n",
    "\n",
    "    generator_256 = GeneratorNextStage(\n",
    "        embeddings_shape=embeddings_shape,\n",
    "        number_of_residuals=2,\n",
    "        previous_stage_shape=generator_128.output_shape,\n",
    "        filters=gf_dim,\n",
    "        is_conditional=is_conditional)\n",
    "\n",
    "    # generator_256.summary()\n",
    "    # generator_256.output_model.summary()\n",
    "\n",
    "    discriminator_64 = StackGANDiscriminator(\n",
    "        input_shape=generator_64.image_shape,\n",
    "        filters=df_dim,\n",
    "        embeddings_shape=embeddings_shape,\n",
    "        output_image_size=64,\n",
    "        is_conditional=is_conditional\n",
    "    )\n",
    "    # discriminator_64.summary()\n",
    "    # discriminator_64.conditional_model.summary()\n",
    "    # discriminator_64.unconditional_model.summary()\n",
    "\n",
    "    discriminator_128 = StackGANDiscriminator(\n",
    "        input_shape=generator_128.image_shape,\n",
    "        filters=df_dim,\n",
    "        embeddings_shape=embeddings_shape,\n",
    "        output_image_size=128,\n",
    "        is_conditional=is_conditional\n",
    "    )\n",
    "    # discriminator_128.summary()\n",
    "    # discriminator_128.conditional_model.summary()\n",
    "    # discriminator_128.unconditional_model.summary()\n",
    "\n",
    "    discriminator_256 = StackGANDiscriminator(\n",
    "        input_shape=generator_256.image_shape,\n",
    "        filters=df_dim,\n",
    "        embeddings_shape=embeddings_shape,\n",
    "        output_image_size=256,\n",
    "        is_conditional=is_conditional\n",
    "    )\n",
    "    # discriminator_256.summary()\n",
    "    # discriminator_256.conditional_model.summary()\n",
    "    # discriminator_256.unconditional_model.summary()\n",
    "\n",
    "    noise_generator = StackGANNoiseGenerator()\n",
    "\n",
    "    for batch in dataset.data.take(1):\n",
    "        imgs, embedding = prepare_embeddings_from_batch(batch)\n",
    "\n",
    "        noise = noise_generator(imgs)\n",
    "\n",
    "        gen_64_input = tf.concat([embedding, noise], axis=1)\\\n",
    "            if is_conditional\\\n",
    "            else noise\n",
    "        gen_64_out, gen_64_image_out = generator_64(gen_64_input, training=False)\n",
    "\n",
    "        gen_128_input = GeneratorNextStage.concat_embedding_and_previous_output(\n",
    "                embedding=embedding,\n",
    "                previous_output=gen_64_out)\\\n",
    "            if is_conditional\\\n",
    "            else gen_64_out\n",
    "        gen_128_out, gen_128_image_out = generator_128(gen_128_input, training=False)\n",
    "\n",
    "        gen_256_input = GeneratorNextStage.concat_embedding_and_previous_output(\n",
    "                embedding=embedding,\n",
    "                previous_output=gen_128_out)\\\n",
    "            if is_conditional\\\n",
    "            else gen_128_out\n",
    "        gen_256_out, gen_256_image_out = generator_256(gen_256_input, training=False)\n",
    "\n",
    "        discr_64_input = [gen_64_image_out, embedding]\\\n",
    "            if is_conditional\\\n",
    "            else gen_64_image_out\n",
    "        discr_64_output = discriminator_64(discr_64_input, training=False)\n",
    "\n",
    "        discr_128_input = [gen_128_image_out, embedding]\\\n",
    "            if is_conditional\\\n",
    "            else gen_128_image_out\n",
    "        discr_64_output = discriminator_128(discr_128_input, training=False)\n",
    "\n",
    "        discr_256_input = [gen_256_image_out, embedding]\\\n",
    "            if is_conditional\\\n",
    "            else gen_256_image_out\n",
    "        discr_256_output = discriminator_256(discr_256_input, training=False)\n",
    "# test_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "enYw9PQ_6h_o",
    "pycharm": {}
   },
   "source": [
    "Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWrapper:\n",
    "    def __init__(self, model_object, model_optimizer_fun, model_loss_fun):\n",
    "        self.model = model_object\n",
    "        self.optimizer_fun = model_optimizer_fun\n",
    "        self.loss_fun = model_loss_fun\n",
    "        self.loss = 0.0\n",
    "\n",
    "\n",
    "def stack_gan_train_step_template(generators, discriminators, noise_generator, is_conditional):\n",
    "    '''\n",
    "    generators: {'name': ModelWrapper}\n",
    "    discriminators: {'name': ModelWrapper}\n",
    "    noise_generator: noise generator model\n",
    "    '''\n",
    "    training = True\n",
    "    @tf.function\n",
    "    def _train_step_template(images, embeddings): # to be executed before\n",
    "        with tf.GradientTape() as d_tape_64,\\\n",
    "                tf.GradientTape() as d_tape_128,\\\n",
    "                tf.GradientTape() as d_tape_256,\\\n",
    "                tf.GradientTape() as g_tape:\n",
    "            noise = noise_generator(images)\n",
    "\n",
    "            ### 64 ###\n",
    "            gen_64_input = tf.concat([embeddings, noise], axis=1)\\\n",
    "                if is_conditional\\\n",
    "                else noise\n",
    "            gen_64_out, gen_64_image_out = generators['64'].model(gen_64_input, training=training)\n",
    "            \n",
    "            # discriminator\n",
    "            discr_64_input = [gen_64_image_out, embeddings]\\\n",
    "                if is_conditional\\\n",
    "                else gen_64_image_out\n",
    "            fake_discr_64_output = discriminators['64'].model([discr_64_input, embeddings], training=training)\n",
    "            real_discr_64_output = discriminators['64'].model([images, embeddings], training=training)\n",
    "            discriminators['64'].loss = discriminators['64']\\\n",
    "                .loss_fun(real_discr_64_output[0], fake_discr_64_output[0])\n",
    "            if is_conditional:\n",
    "                discriminators['64'].loss += discriminators['64']\\\n",
    "                    .loss_fun(real_discr_64_output[0], fake_discr_64_output[0])*unconditional_loss_coefficient\n",
    "            \n",
    "            # calculate generator loss (conditional + unconditional*unconditional_coeff)\n",
    "            generators['64'].loss = generators['64'].loss_fun(\n",
    "                fake_discr_64_output[1] * unconditional_loss_coefficient)\n",
    "            if is_conditional:\n",
    "                generators['64'].loss += generators['64'].loss_fun(fake_discr_64_output[0])\n",
    "\n",
    "\n",
    "            ### 128 ###\n",
    "            gen_128_input = GeneratorNextStage.concat_embedding_and_previous_output(\n",
    "                    embedding=embeddings,\n",
    "                    previous_output=gen_64_out)\\\n",
    "                if is_conditional\\\n",
    "                else gen_64_out\n",
    "            gen_128_out, gen_128_image_out = generators['128'].model(gen_128_input, training=training)\n",
    "            \n",
    "            # discriminator\n",
    "            discr_128_input = [gen_128_image_out, embeddings]\\\n",
    "                if is_conditional\\\n",
    "                else gen_128_image_out\n",
    "            fake_discr_128_output = discriminators['128'].model([discr_128_input, embeddings], training=training)\n",
    "            real_discr_128_output = discriminators['128'].model([images, embeddings], training=training)\n",
    "            discriminators['128'].loss = discriminators['128']\\\n",
    "                .loss_fun(real_discr_128_output[0], fake_discr_128_output[0])\n",
    "            if is_conditional:\n",
    "                discriminators['128'].loss += discriminators['128']\\\n",
    "                    .loss_fun(real_discr_128_output[0], fake_discr_128_output[0])*unconditional_loss_coefficient\n",
    "            \n",
    "            # generator loss\n",
    "            generators['128'].loss = generators['128'].loss_fun(\n",
    "                fake_discr_128_output[1] * unconditional_loss_coefficient)\n",
    "            if is_conditional:\n",
    "                generators['128'].loss += generators['128'].loss_fun(fake_discr_128_output[0])\n",
    "            \n",
    "\n",
    "            ### 256 ###\n",
    "            gen_256_input = GeneratorNextStage.concat_embedding_and_previous_output(\n",
    "                    embedding=embeddings,\n",
    "                    previous_output=gen_128_out)\\\n",
    "                if is_conditional\\\n",
    "                else gen_128_out\n",
    "            gen_256_out, gen_256_image_out = generators['256'].model(gen_256_input, training=training)\n",
    "            \n",
    "            # discriminator\n",
    "            discr_256_input = [gen_256_image_out, embeddings]\\\n",
    "                if is_conditional\\\n",
    "                else gen_256_image_out\n",
    "            fake_discr_256_output = discriminators['256'].model([discr_256_input, embeddings], training=training)\n",
    "            real_discr_256_output = discriminators['256'].model([images, embeddings], training=training)\n",
    "            discriminators['256'].loss = discriminators['256']\\\n",
    "                .loss_fun(real_discr_256_output[0], fake_discr_256_output[0])\n",
    "            if is_conditional:\n",
    "                discriminators['256'].loss += discriminators['256']\\\n",
    "                    .loss_fun(real_discr_256_output[0], fake_discr_256_output[0])*unconditional_loss_coefficient\n",
    "            # generator loss\n",
    "            generators['256'].loss = generators['256'].loss_fun(\n",
    "                fake_discr_256_output[1] * unconditional_loss_coefficient)\n",
    "            if is_conditional:\n",
    "                generators['256'].loss += generators['256'].loss_fun(fake_discr_256_output[0])\n",
    "\n",
    "        \n",
    "        error_g = tf.reduce_sum([x.loss for x in generators.values()])\n",
    "        error_d = tf.reduce_sum([x.loss for x in discriminators.values()])\n",
    "        \n",
    "        g_grads = g_tape.gradient(generators['64'].loss,\n",
    "                                  generators['64'].model.trainable_variables +\n",
    "                                  generators['128'].model.trainable_variables +\n",
    "                                  generators['256'].model.trainable_variables +\n",
    "                                  noise.trainable_variables)\n",
    "        \n",
    "        d_64_grads = d_tape.gradient(discriminators['64'].loss,\n",
    "                                  discriminators['64'].model.trainable_variables)\n",
    "        discriminators['64']\\\n",
    "            .optimizer_fun\\\n",
    "            .apply_gradients(zip(d_64_grads, discriminators['64'].model.trainable_variables))\n",
    "        \n",
    "        d_128_grads = d_tape.gradient(discriminators['128'].loss,\n",
    "                                  discriminators['128'].model.trainable_variables)\n",
    "        discriminators['128']\\\n",
    "            .optimizer_fun\\\n",
    "            .apply_gradients(zip(d_128_grads, discriminators['128'].model.trainable_variables))\n",
    "        \n",
    "        d_256_grads = d_tape.gradient(discriminators['256'].loss,\n",
    "                                  discriminators['256'].model.trainable_variables)\n",
    "        discriminators['256']\\\n",
    "            .optimizer_fun\\\n",
    "            .apply_gradients(zip(d_256_grads, discriminators['256'].model.trainable_variables))\n",
    "        \n",
    "    return _train_step_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "axR-vkyz6kZa",
    "pycharm": {}
   },
   "source": [
    "Inference step\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r57i63lv6mRT",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def stack_gan_gen_step_template(generators, noise_gen, is_conditional):\n",
    "    @tf.function\n",
    "    def _gen_step_template(images, embeddings):\n",
    "        gen_64_input = tf.concat([embeddings, noise_gen(images)], axis=1)\\\n",
    "                if is_conditional\\\n",
    "                else noise\n",
    "        gen_64_out, imgs_64 = generators['64'].model(gen_64_input, training=False)\n",
    "        \n",
    "        gen_128_input = GeneratorNextStage.concat_embedding_and_previous_output(\n",
    "                    embedding=embeddings,\n",
    "                    previous_output=gen_64_out)\\\n",
    "                if is_conditional\\\n",
    "                else gen_128_out\n",
    "        gen_128_out, imgs_128 = generators['128'].model(gen_128_input, training=False)\n",
    "        \n",
    "        gen_256_input = GeneratorNextStage.concat_embedding_and_previous_output(\n",
    "                    embedding=embeddings,\n",
    "                    previous_output=gen_128_out)\\\n",
    "                if is_conditional\\\n",
    "                else gen_128_out\n",
    "        _, imgs_256 = generators['256'].model(gen_256_input, training=False)\n",
    "        return tf.clip_by_value([imgs_64, imgs_128, imgs_256], -1, 1)\n",
    "\n",
    "    return _gen_step_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8xRLPJoW7IcI",
    "pycharm": {}
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ut1yWYzD7JeR",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def train(train_step, gen_step, epochs, data, settings, ckptManager, tensorboard_manager, save_images=True, display_images=True):\n",
    "    loss_descriptions = ['discriminator loss', 'generator loss'] #, 'kl generator loss']\n",
    "    imgs_sizes = ['64', '128', '256']\n",
    "    timestamp = get_time()\n",
    "    max_batch_iter = 0\n",
    "    for epoch in range(epochs):\n",
    "        batch_iter = 0\n",
    "        epoch_start = time.time()\n",
    "        for batch in data:\n",
    "            images, embedding = prepare_embeddings_from_batch(batch)\n",
    "            batch_iter+=1\n",
    "            train_result = train_step(images, embedding)\n",
    "            tensorboard_manager.save('train',\n",
    "                                     [np.average(loss) for loss in train_result],\n",
    "                                     loss_descriptions,\n",
    "                                     timestamp,\n",
    "                                     'scalars',\n",
    "                                     epoch*max_batch_iter+batch_iter\n",
    "                                    )\n",
    "            if (batch_iter+1) % 50 == 0:\n",
    "                print(\"Saving checkpoint, iter\", batch_iter+1)\n",
    "                ckptManager.save()\n",
    "        # save the number of batches in one epoch\n",
    "        if epoch == 0:\n",
    "            max_batch_iter = batch_iter\n",
    "\n",
    "        epoch_end = time.time()\n",
    "        print('-'*30)\n",
    "        print('Epoch {0}/{1}, duration {2}'.format(epoch+1, epochs, epoch_end-epoch_start))\n",
    "        #if (epoch + 1) % 5 == 0 or epoch == epochs-1:\n",
    "        print(\"Saving checkpoint, epoch\", epoch+1)\n",
    "        ckptManager.save()\n",
    "\n",
    "        images_to_generate = [img[0] for img in data.take(1)][0].numpy() # take one batch from train_data\n",
    "        generated_imgs = gen_step(images_to_generate)\n",
    "        \n",
    "        for (generated, size) in zip(generated_imgs, imgs_sizes):\n",
    "            tensorboard_manager.save('train',\n",
    "                                     generated,\n",
    "                                     '{}_{}_{}/{}'.format(settings.run_name, size, epoch+1, epochs),\n",
    "                                     timestamp,\n",
    "                                     'images',\n",
    "                                     epoch\n",
    "                                    )\n",
    "            \n",
    "        \n",
    "            print(size)\n",
    "            show_images(generated, epoch, settings, save_images=save_images, display_images=display_images)\n",
    "        print('+'*30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how images are displayed/saved\n",
    "def test_image_generation(settings):\n",
    "    save_images = True\n",
    "    display_images = True\n",
    "    batch_size = 10\n",
    "    data = load_dataset(batch_size=settings.batch_size)\n",
    "    \n",
    "    generator_input_shape = (64, 3)\n",
    "    generator = Generator(input_shape=generator_input_shape)\n",
    "    noise = NoiseGenerator(64)\n",
    "    \n",
    "    gen_step = gen_step_template(\n",
    "        generator=generator,\n",
    "        noise=noise\n",
    "    )\n",
    "    images_to_generate = [img for img in data.take(1)][0].numpy() # take one batch from train_data\n",
    "    generated = gen_step(images_to_generate)\n",
    "    show_images(generated, -1, settings, save_images=save_images, display_images=display_images)\n",
    "    \n",
    "# test_image_generation(Settings(collab_mode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i1EZ3WMg7ZS0",
    "pycharm": {}
   },
   "source": [
    "Training with Wasserstein loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackGANGeneratorWrapper:\n",
    "    def __init__(self, settings):\n",
    "        self.generators = dict()\n",
    "        self.generators['64'] = ModelWrapper(\n",
    "                        model_object = GeneratorInitStage(noise_shape=settings.z_dim,\n",
    "                            embeddings_shape=settings.embeddings_shape,\n",
    "                            filters=settings.gen_init_filters,\n",
    "                            is_conditional=settings.is_conditional,\n",
    "                            settings=settings),\n",
    "                        model_optimizer_fun = tf.keras.optimizers.Adam(1e-4),\n",
    "                        model_loss_fun = stack_gan_generator_loss\n",
    "                        )\n",
    "                                             \n",
    "        self.generators['128'] = ModelWrapper(\n",
    "                        model_object = GeneratorNextStage(\n",
    "                            embeddings_shape=settings.embeddings_shape,\n",
    "                            number_of_residuals=2,\n",
    "                            previous_stage_shape=self.generators['64'].model.output_shape,\n",
    "                            filters=settings.gf_dim,\n",
    "                            is_conditional=settings.is_conditional),\n",
    "                        model_optimizer_fun = tf.keras.optimizers.Adam(1e-4),\n",
    "                        model_loss_fun = stack_gan_generator_loss\n",
    "                        )\n",
    "                    \n",
    "        self.generators['256'] = ModelWrapper(\n",
    "                        model_object = GeneratorNextStage(\n",
    "                            embeddings_shape=settings.embeddings_shape,\n",
    "                            number_of_residuals=2,\n",
    "                            previous_stage_shape=self.generators['128'].model.output_shape,\n",
    "                            filters=settings.gf_dim,\n",
    "                            is_conditional=settings.is_conditional),\n",
    "                        model_optimizer_fun = tf.keras.optimizers.Adam(1e-4),\n",
    "                        model_loss_fun = stack_gan_generator_loss\n",
    "                        )\n",
    "        self.settings = settings\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        return self.generators[key]\n",
    "        \n",
    "class StackGANDiscriminatorWrapper:\n",
    "    def __init__(self, generators, settings):\n",
    "        self.discriminators = dict()\n",
    "        self.discriminators['64'] = ModelWrapper(\n",
    "            model_object = StackGANDiscriminator(\n",
    "                input_shape=generators['64'].model.image_shape,\n",
    "                filters=settings.df_dim,\n",
    "                embeddings_shape=settings.embeddings_shape,\n",
    "                output_image_size=64,\n",
    "                is_conditional=settings.is_conditional\n",
    "            ),\n",
    "            model_optimizer_fun = tf.keras.optimizers.Adam(1e-4),\n",
    "            model_loss_fun = stack_gan_discriminator_loss\n",
    "        )\n",
    "\n",
    "        self.discriminators['128'] = ModelWrapper(\n",
    "            model_object = StackGANDiscriminator(\n",
    "                input_shape=generators['128'].model.image_shape,\n",
    "                filters=settings.df_dim,\n",
    "                embeddings_shape=settings.embeddings_shape,\n",
    "                output_image_size=128,\n",
    "                is_conditional=settings.is_conditional\n",
    "            ),\n",
    "            model_optimizer_fun = tf.keras.optimizers.Adam(1e-4),\n",
    "            model_loss_fun = stack_gan_discriminator_loss\n",
    "        )\n",
    "        \n",
    "        self.discriminators['256'] = ModelWrapper(\n",
    "            model_object = StackGANDiscriminator(\n",
    "                input_shape=generators['256'].model.image_shape,\n",
    "                filters=settings.df_dim,\n",
    "                embeddings_shape=settings.embeddings_shape,\n",
    "                output_image_size=256,\n",
    "                is_conditional=settings.is_conditional\n",
    "            ),\n",
    "            model_optimizer_fun = tf.keras.optimizers.Adam(1e-4),\n",
    "            model_loss_fun = stack_gan_discriminator_loss\n",
    "        )\n",
    "        self.settings = settings\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "            return self.discriminators[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "EHKejxSy7YOx",
    "outputId": "de999bc7-5064-4d75-86e6-487f676dce28",
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\iswd_2\\gsn\\laby\\FaceGenerator\n",
      "downloading and loading data\n",
      "WARNING:tensorflow:Entity <function load_dataset.<locals>.<lambda> at 0x000001B51C49DD38> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: expected exactly one node node, found []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function load_dataset.<locals>.<lambda> at 0x000001B51C49DD38> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: expected exactly one node node, found []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function load_dataset.<locals>.<lambda> at 0x000001B51C49DD38> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: expected exactly one node node, found []\n",
      "Initialized tensorboard log dir with path D:\\iswd_2\\gsn\\laby\\FaceGenerator\\saved_state\\stack_gan_run_img_align_celeba\\tensorboard_logs\n",
      "open tensorboard with command\n",
      "tensorboard --logdir D:\\iswd_2\\gsn\\laby\\FaceGenerator\\saved_state\\stack_gan_run_img_align_celeba\\tensorboard_logs\n"
     ]
    }
   ],
   "source": [
    "env = Environment(collab_mode)\n",
    "generators = StackGANGeneratorWrapper(env.settings)\n",
    "discriminators = StackGANDiscriminatorWrapper(generators, env.settings)\n",
    "env.settings.epochs = 30\n",
    "env.settings.batch_size = 500\n",
    "env.settings.subdataset_dir='img_align_celeba'\n",
    "env.settings.save_models = True\n",
    "print(env.settings.get_base_path)\n",
    "# load data\n",
    "env.datasetCache.load_data(env.settings)\n",
    "# set models\n",
    "env.models['generators'] = generators\n",
    "env.models['discriminators'] = discriminators\n",
    "# setup tensorboard\n",
    "env.tensorboard = TensorboardManager()\n",
    "env.tensorboard.initialize(env.settings)\n",
    "\n",
    "noise = StackGANNoiseGenerator(100)\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(generator_64_opt=env.models['generators']['64'].optimizer_fun,\n",
    "                                 generator_128_opt=env.models['generators']['128'].optimizer_fun,\n",
    "                                 generator_256_opt=env.models['generators']['256'].optimizer_fun,\n",
    "                                 discriminator_64_opt=env.models['discriminators']['64'].optimizer_fun,\n",
    "                                 discriminator_128_opt=env.models['discriminators']['128'].optimizer_fun,\n",
    "                                 discriminator_256_opt=env.models['discriminators']['256'].optimizer_fun,\n",
    "                                 generator_64=env.models['generators']['64'].model,\n",
    "                                 generator_128=env.models['generators']['128'].model,\n",
    "                                 generator_256=env.models['generators']['256'].model,\n",
    "                                 discriminator_64=env.models['discriminators']['64'].model,\n",
    "                                 discriminator_128=env.models['discriminators']['128'].model,\n",
    "                                 discriminator_256=env.models['discriminators']['256'].model)\n",
    "env.checkpointManager = tf.train.CheckpointManager(checkpoint=checkpoint,\n",
    "                                                   directory=env.settings.checkpoint_dir,\n",
    "                                                   max_to_keep=3\n",
    "                                                  )\n",
    "if env.checkpointManager.latest_checkpoint:\n",
    "    print(\"restoring state from\", env.checkpointManager.latest_checkpoint)\n",
    "    checkpoint\\\n",
    "        .restore(env.checkpointManager.latest_checkpoint)\n",
    "    \n",
    "train_step = stack_gan_train_step_template(\n",
    "    generators=env.models['generators'],\n",
    "    discriminators=env.models['discriminators'],\n",
    "    noise_generator=noise,\n",
    "    is_conditional=env.settings.is_conditional\n",
    ")\n",
    "\n",
    "gen_step = stack_gan_gen_step_template(\n",
    "    generators=env.models['generators'],\n",
    "    noise_gen=noise,\n",
    "    is_conditional=settings.is_conditional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time 13-01-2020_01-20-10\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    <ipython-input-45-45a7e1ebc7bc>:36 _train_step_template  *\n        discriminators['64'].loss = discriminators['64']\\\n    <ipython-input-10-5da2bcd13aa6>:13 stack_gan_discriminator_loss  *\n        return min_max_discriminator_loss(real_out, fake_out)\n    <ipython-input-10-5da2bcd13aa6>:5 min_max_discriminator_loss  *\n        real_loss = bce(tf.ones_like(real_out), real_out)\n    d:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\losses.py:126 __call__\n        losses = self.call(y_true, y_pred)\n    d:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\losses.py:221 call\n        return self.fn(y_true, y_pred, **self._fn_kwargs)\n    d:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\losses.py:994 binary_crossentropy\n        K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\n    d:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py:2117 mean\n        return math_ops.reduce_mean(x, axis, keepdims)\n    d:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py:180 wrapper\n        return target(*args, **kwargs)\n    d:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py:1881 reduce_mean\n        name=name))\n    d:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py:6391 mean\n        name=name)\n    d:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py:793 _apply_op_helper\n        op_def=op_def)\n    d:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py:548 create_op\n        compute_device)\n    d:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:3429 _create_op_internal\n        op_def=op_def)\n    d:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1773 __init__\n        control_input_ops)\n    d:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1613 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Invalid reduction dimension -1 for input with 0 dimensions. for 'binary_crossentropy/Mean' (op: 'Mean') with input shapes: [], [] and with computed input tensors: input[1] = <-1>.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-ef6b2f7eba43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0msettings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mckptManager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpointManager\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mtensorboard_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-5bf4c73a3227>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_step, gen_step, epochs, data, settings, ckptManager, tensorboard_manager, save_images, display_images)\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_embeddings_from_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mbatch_iter\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mtrain_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             tensorboard_manager.save('train',\n\u001b[0;32m     14\u001b[0m                                      \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_result\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    501\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m       \u001b[0minitializer_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    406\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    407\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 408\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2150\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2041\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2043\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    913\u001b[0m                                           converted_func)\n\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    903\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 905\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    906\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in converted code:\n\n    <ipython-input-45-45a7e1ebc7bc>:36 _train_step_template  *\n        discriminators['64'].loss = discriminators['64']\\\n    <ipython-input-10-5da2bcd13aa6>:13 stack_gan_discriminator_loss  *\n        return min_max_discriminator_loss(real_out, fake_out)\n    <ipython-input-10-5da2bcd13aa6>:5 min_max_discriminator_loss  *\n        real_loss = bce(tf.ones_like(real_out), real_out)\n    d:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\losses.py:126 __call__\n        losses = self.call(y_true, y_pred)\n    d:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\losses.py:221 call\n        return self.fn(y_true, y_pred, **self._fn_kwargs)\n    d:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\losses.py:994 binary_crossentropy\n        K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\n    d:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py:2117 mean\n        return math_ops.reduce_mean(x, axis, keepdims)\n    d:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py:180 wrapper\n        return target(*args, **kwargs)\n    d:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py:1881 reduce_mean\n        name=name))\n    d:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py:6391 mean\n        name=name)\n    d:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py:793 _apply_op_helper\n        op_def=op_def)\n    d:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py:548 create_op\n        compute_device)\n    d:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:3429 _create_op_internal\n        op_def=op_def)\n    d:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1773 __init__\n        control_input_ops)\n    d:\\iswd_2\\gsn\\laby\\facegenerator\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1613 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Invalid reduction dimension -1 for input with 0 dimensions. for 'binary_crossentropy/Mean' (op: 'Mean') with input shapes: [], [] and with computed input tensors: input[1] = <-1>.\n"
     ]
    }
   ],
   "source": [
    "print(\"Start time\", get_time())\n",
    "print('%'*30)\n",
    "start = time.time()\n",
    "\n",
    "train(\n",
    "    train_step=train_step,\n",
    "    gen_step=gen_step,\n",
    "    epochs=env.settings.epochs,\n",
    "    data=env.datasetCache.data,\n",
    "    settings=env.settings,\n",
    "    ckptManager=env.checkpointManager,\n",
    "    tensorboard_manager=env.tensorboard\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "print('%'*30)\n",
    "print(\"End time\", get_time())\n",
    "print(\"seconds elapsed\", end - start)\n",
    "\n",
    "if env.settings.save_models:\n",
    "    print('saving models')\n",
    "    for model in env.models:\n",
    "        env.models[model].save_model(env.settings.model_save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uwagi:\n",
    "* na początku generowane obrazki są białe, bardzo małe odchylenie w wartościach pikseli ok 17 dla skali 0-255\n",
    "* generator używa tylko skali np 52-160\n",
    "* później generator uczy się zwiększać odchylenie i wartości pikseli na obrazkach zwiększają się do przedziału 0-255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FaceGenerator",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "FaceGenerator",
   "language": "python",
   "name": "facegenerator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
