{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "collab_mode = False\n",
    "\n",
    "if collab_mode:\n",
    "    # set up tensorflow\n",
    "    %tensorflow_version 2.x\n",
    "# imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import warnings # This ignore all the warning messages\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from os import path\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "root_local_path = os.getcwd()\n",
    "root_gdrive_path = '/content/drive'\n",
    "gdrive_project_path = 'My Drive/pp/GSN/FaceGenerator'\n",
    "checkpoints_path = 'checkpoints'\n",
    "dataset_path = 'datasets'\n",
    "dataset_name = \"celeb_a\"\n",
    "tensorboard_logs_dir='tensorboard'\n",
    "download_path = '' # output path for the dataset\n",
    "generated_images_path = 'generated_images'\n",
    "dataset_image_size = (28, 28)\n",
    "run_name = 'default'\n",
    "gdrive_mounted = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def allow_memory_growth():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            # Memory growth must be set before GPUs have been initialized\n",
    "            print(e)\n",
    "\n",
    "# run the line below if you're using local runtime and have GTX > 1660 (this is known bug with tensorflow memory allocation)\n",
    "# allow_memory_growth()\n",
    "\n",
    "allow_memory_growth()\n",
    "print(\"Getting device name\")\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OitotiNIkMdu",
    "pycharm": {}
   },
   "source": [
    "Misc helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_time():\n",
    "    return time.strftime(\"%d-%m-%Y-_%H-%M-%S\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n9nTYth-ib_Y",
    "pycharm": {}
   },
   "source": [
    "# Mount gdrive disk if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "if collab_mode:\n",
    "    from google.colab import drive\n",
    "    project_path = path.join(root_gdrive_path, gdrive_project_path )\n",
    "    gdrive_project_path = path.join(root_gdrive_path, gdrive_project_path)\n",
    "    drive.mount(root_gdrive_path)\n",
    "    gdrive_mounted = True\n",
    "\n",
    "def get_base_path():\n",
    "    if collab_mode:\n",
    "        return path.join(root_gdrive_path, gdrive_project_path)\n",
    "    else:\n",
    "        return root_local_path "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if collab_mode:\n",
    "    path_with_imports = path.join(root_gdrive_path, gdrive_project_path)\n",
    "    print(\"Files in path\", path_with_imports)\n",
    "    !ls /content/drive/My\\ Drive/pp/GSN/FaceGenerator\n",
    "    if path_with_imports not in os.sys.path:\n",
    "        os.sys.path.append(path_with_imports)\n",
    "\n",
    "import dataset_helpers as ds_helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D5XPXT_060P8",
    "pycharm": {}
   },
   "source": [
    "### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def download_dataset():\n",
    "    '''Downloads data to dataset_path/dataset_name directory'''\n",
    "    if collab_mode:\n",
    "        download_path = path.join(root_gdrive_path, gdrive_project_path, dataset_path, dataset_name)\n",
    "    else:\n",
    "        download_path = path.join(root_local_path, dataset_path, dataset_name)\n",
    "    \n",
    "    print('dataset download path is {}'.format(download_path))\n",
    "    ds_helpers.download_extract('celeba', download_path)\n",
    "\n",
    "download_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "download_path = path.join(root_local_path, dataset_path, 'celeb_a')\n",
    "img_path = path.join(download_path, '50000\\\\*.jpg')\n",
    "IMAGE_SIZES = (64, 64)\n",
    "IMAGE_CHANNELS=3\n",
    "IMAGES_SHAPE = (*IMAGE_SIZES, IMAGE_CHANNELS)\n",
    "print(IMAGES_SHAPE)\n",
    "def process_image(img):\n",
    "    img = tf.cast(img, tf.float32)/127.5-1 # IMPORTANT, image's pixels are in the range <-1, 1>\n",
    "    img = tf.image.resize(img, IMAGE_SIZES)\n",
    "    return img\n",
    "\n",
    "def load_image(filename):\n",
    "    img = tf.io.read_file(filename)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    return img\n",
    "\n",
    "def load_dataset(batch_size, preprocess_images=True, shuffle_size=500, seed=101):\n",
    "    data = tf.data.Dataset.list_files(img_path, seed=seed)\\\n",
    "        .shuffle(shuffle_size)\\\n",
    "        .map(load_image)\n",
    "    if preprocess_images:\n",
    "        data = data.map(process_image)\n",
    "    return data.batch(batch_size)\n",
    "    \n",
    "data = load_dataset(batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_from_dataset():\n",
    "    # Check image\n",
    "    for batch in data.take(1):\n",
    "        for img in iter(batch):\n",
    "            img_ = (img+1)/2\n",
    "            plt.imshow(img_)\n",
    "            print(img_.shape, np.min(img_), np.max(img_))\n",
    "            break\n",
    "            \n",
    "display_image_from_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SKcjsmJF6yxz",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def save_generated_image(epoch):\n",
    "    save_dir = path.join(get_base_path(), generated_images_path, run_name)\n",
    "    if not path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    name = path.join(save_dir,\n",
    "                     'img_{}_{}.png'.format(epoch, get_time()))\n",
    "    plt.savefig(name)\n",
    "\n",
    "\n",
    "def show_images(images, epoch, save_images=False, display_images=False):\n",
    "    print(\"image pixels range\", np.min(images), np.max(images), \"std\", np.std(images))\n",
    "    \n",
    "    num_of_images = min(10, images.shape[0])\n",
    "    plt.figure(figsize=(num_of_images, 1))\n",
    "    # print(\"saving images with shape\", images.shape, \"image size\", num_of_images)\n",
    "    # print(\"showing\", num_of_images, \"images\")\n",
    "    for i in range(num_of_images):\n",
    "        plt.subplot(1, num_of_images, i + 1)\n",
    "        img = images[i, :, :, :].numpy() #\n",
    "        # print(\"values of image\", i, np.min(img), np.max(img))\n",
    "        img = (img * 127.5 + 127.5).astype(np.uint8)\n",
    "        # print(\"values of image\", i, np.min(img), np.max(img), np.std(img))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    \n",
    "\n",
    "    if save_images:\n",
    "        save_generated_image(epoch)\n",
    "    if display_images:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "07vs6jG7ZUqP",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# def save_models(generator, discriminator):\n",
    "#     def save(epoch_number):\n",
    "#         path = get_path()\n",
    "#     return save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "id": "7qc4AKp0RFYv",
    "outputId": "5a3b3ae9-9489-4419-b71a-63810acf2ef8",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "log_dir_path = path.join(get_base_path(), tensorboard_logs_dir, run_name)\n",
    "if collab_mode:\n",
    "    %reload_ext tensorboard\n",
    "\n",
    "    print('tensorboard log dir {}'.format(log_dir_path))\n",
    "    %tensorboard --logdir logs\n",
    "    from tensorboard import notebook\n",
    "    notebook.list() # View open TensorBoard instances\n",
    "else:\n",
    "    print('open tensorboard with command')\n",
    "    print('tensorboard --logdir {}'.format(log_dir_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log_dir = 'logs/gradient_tape/' + run_name + get_time() + '/train'\n",
    "test_log_dir = 'logs/gradient_tape/' + run_name + get_time() + '/test'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "\n",
    "checkpoint_dir = os.path.join('.', 'training_checkpoints', run_name)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "\n",
    "def restore_from_checkpoint():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1xwRLPZYmJtL",
    "pycharm": {}
   },
   "source": [
    "Loss functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TnfRHsNBmLsd",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def min_max_discriminator_loss(real_out, gen_out):\n",
    "    real_loss = bce(tf.ones_like(real_out), real_out)\n",
    "    gen_loss = bce(tf.zeros_like(gen_out), gen_out)\n",
    "    return real_loss + gen_loss\n",
    "\n",
    "\n",
    "def min_max_generator_loss(gen_out):\n",
    "    return - min_max_discriminator_loss(tf.ones_like(gen_out), gen_out)\n",
    "\n",
    "\n",
    "def w_discriminator_loss(real_out, gen_out):\n",
    "    res = - (tf.reduce_mean(real_out) - tf.reduce_mean(gen_out))\n",
    "    return res\n",
    "\n",
    "\n",
    "def w_generator_loss(gen_out):\n",
    "    return - tf.reduce_mean(gen_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_layers(model):\n",
    "    for layer in model.layers:\n",
    "            print(layer.name, \":\", layer.input_shape, \"->\", layer.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwrjmA4t6Oxn",
    "pycharm": {}
   },
   "source": [
    "Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QFu3fHge6K86",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, input_shape, model_name=\"Generator\", **kwargs):\n",
    "        super(Generator, self).__init__(name=model_name, **kwargs)\n",
    "#         print(\"input \", input_shape)\n",
    "        self.noise_decoder = tf.keras.Sequential([\n",
    "            # flat\n",
    "            tf.keras.layers.Dense(1024, input_shape=input_shape),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Reshape([16, 16, 256]),\n",
    "            # conv without stride (16x16)\n",
    "            tf.keras.layers.Conv2D(256, 5, 1, 'same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            # t_conv with stride (32x32)\n",
    "            tf.keras.layers.Conv2DTranspose(128, 5, 2, 'same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            # conv without stride (32x32)\n",
    "            tf.keras.layers.Conv2D(64, 5, 1, 'same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            # t_conv with stride (64x64)\n",
    "            tf.keras.layers.Conv2DTranspose(32, 5, 2, 'same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            # conv without stride\n",
    "            tf.keras.layers.Conv2D(3, (1, 1), 1, 'same')\n",
    "        ])\n",
    "        print_layers(self.noise_decoder)\n",
    "\n",
    "    def call(self, noise, training):\n",
    "        return self.noise_decoder(noise)\n",
    "    \n",
    "    def summary(self):\n",
    "        self.noise_decoder.summary()\n",
    "\n",
    "generator_input_shape = (64, 3)\n",
    "generator = Generator(input_shape=generator_input_shape)\n",
    "# generator.build((None, *generator_input_shape))\n",
    "generator.summary()\n",
    "\n",
    "# generator = Generator(input_shape=IMAGES_SHAPE)\n",
    "# generator.build((None, *IMAGES_SHAPE))\n",
    "# generator.summary()\n",
    "# tf.keras.utils.plot_model(generator, \"gen.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8N1JmZB06SKO",
    "pycharm": {}
   },
   "source": [
    "Discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "16ATdVrY6UId",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, input_shape, model_name=\"Discriminator\", **kwargs):\n",
    "        super(Discriminator, self).__init__(name=model_name, **kwargs)\n",
    "\n",
    "        # since discriminator is for classification it should be robust, thus, add\n",
    "        # additional regularization like dropout to prevent from pixel attacks\n",
    "        self.image_encoder = tf.keras.Sequential([\n",
    "            # conv with stride (32x32)\n",
    "            tf.keras.layers.Conv2D(64, 5, 2, 'same', input_shape=input_shape),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            # conv with stride (16x16x128)\n",
    "            tf.keras.layers.Conv2D(128, 3, 2, 'same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            # flatten + hidden layer\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(64),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            # prediction (LOGITS!)\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        print_layers(self.image_encoder)\n",
    "\n",
    "    def call(self, images, training):\n",
    "        return self.image_encoder(images)\n",
    "    \n",
    "    def summary(self):\n",
    "        self.image_encoder.summary()\n",
    "\n",
    "# discriminator = Discriminator(input_shape=IMAGES_SHAPE)\n",
    "# discriminator.build(input_shape=(None, *IMAGES_SHAPE))\n",
    "# discriminator.summary()\n",
    "# start_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uX4rm1S_6Yfj",
    "pycharm": {}
   },
   "source": [
    "Noise generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S6YpknpB6a0C",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "class NoiseGenerator(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, distribution_size):\n",
    "        super().__init__()\n",
    "        self.distribution_size = distribution_size\n",
    "        # self.data_distributions = self.add_weight(shape=(num_classes, distribution_size), trainable=True)\n",
    "        # self.data_distributions = tf.tile(tf.range(0, num_classes, dtype=tf.float32)[:, tf.newaxis], [1, distribution_size])\n",
    "        # TODO:\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # dists = tf.nn.embedding_lookup(self.data_distributions, inputs)\n",
    "        # dists += tf.random.uniform(tf.shape(dists), -0.35, 0.35)\n",
    "        # return dists\n",
    "        # TODO\n",
    "        return tf.random.normal([tf.shape(inputs)[0], self.distribution_size, 3])\n",
    "        \n",
    "    def diverse_distributions_loss(self):\n",
    "        # TODO\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "enYw9PQ_6h_o",
    "pycharm": {}
   },
   "source": [
    "Training step\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OqIPgp5B6jqe",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def train_step_template(generator, discriminator, noise, d_optim, g_optim, d_loss_f, g_loss_f):\n",
    "\n",
    "    @tf.function\n",
    "    def _train_step_template(images):\n",
    "        with tf.GradientTape() as d_tape, tf.GradientTape() as g_tape:\n",
    "            real_out = discriminator(images, True)\n",
    "            gen_out = discriminator(generator(noise(images), True), True)\n",
    "\n",
    "            d_loss = d_loss_f(real_out, gen_out)\n",
    "            g_loss = g_loss_f(gen_out)\n",
    "\n",
    "        d_grads = d_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "        g_grads = g_tape.gradient(g_loss, generator.trainable_variables + noise.trainable_variables)\n",
    "\n",
    "        d_optim.apply_gradients(zip(d_grads, discriminator.trainable_variables))\n",
    "        g_optim.apply_gradients(zip(g_grads, generator.trainable_variables + noise.trainable_variables))\n",
    "\n",
    "    return _train_step_template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_data = load_dataset(batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "axR-vkyz6kZa",
    "pycharm": {}
   },
   "source": [
    "Inference step\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r57i63lv6mRT",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def gen_step_template(generator, noise):\n",
    "    @tf.function\n",
    "    def _gen_step_template(images):\n",
    "        return tf.clip_by_value(generator(noise(images), False), -1, 1)\n",
    "\n",
    "    return _gen_step_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8xRLPJoW7IcI",
    "pycharm": {}
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ut1yWYzD7JeR",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def train(train_step, gen_step, epochs, data, save_images=True, display_images=True, checkpoint=None):\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        for images in data:\n",
    "            train_step(images)\n",
    "\n",
    "        epoch_end = time.time()\n",
    "        print('$+'*30)\n",
    "        print('Epoch {0}/{1}, duration {2}'.format(epoch, epochs, epoch_end-epoch_start))\n",
    "        if (epoch + 1) % 5 == 0 and checkpoint is not None:\n",
    "            print(\"Saving checkpoint\")\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "        images_to_generate = [img for img in data.take(1)][0].numpy() # take one batch from train_data\n",
    "        generated = gen_step(images_to_generate)\n",
    "        show_images(generated, epoch, save_images=save_images, display_images=display_images)\n",
    "        print('$-'*30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how images are displayed/saved\n",
    "def test_image_generation():\n",
    "    save_images = True\n",
    "    display_images = True\n",
    "    batch_size = 10\n",
    "    data = load_dataset(batch_size=batch_size)\n",
    "    \n",
    "    generator_input_shape = (64, 3)\n",
    "    generator = Generator(input_shape=generator_input_shape)\n",
    "    noise = NoiseGenerator(64)\n",
    "    \n",
    "    gen_step = gen_step_template(\n",
    "        generator=generator,\n",
    "        noise=noise\n",
    "    )\n",
    "    images_to_generate = [img for img in data.take(1)][0].numpy() # take one batch from train_data\n",
    "    generated = gen_step(images_to_generate)\n",
    "    show_images(generated, -1, save_images=save_images, display_images=display_images)\n",
    "    \n",
    "# test_image_generation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i1EZ3WMg7ZS0",
    "pycharm": {}
   },
   "source": [
    "Training with Wasserstein loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "cxqxoONqA4ZR",
    "outputId": "c235a412-fe41-40b4-fa73-673d8b55560e",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "generator_input_shape = (64, 3)\n",
    "generator = Generator(input_shape=generator_input_shape)\n",
    "generator.build((None, *generator_input_shape))\n",
    "generator.summary()\n",
    "\n",
    "discriminator = Discriminator(input_shape=IMAGES_SHAPE)\n",
    "discriminator.build(input_shape=(None, *IMAGES_SHAPE))\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "EHKejxSy7YOx",
    "outputId": "de999bc7-5064-4d75-86e6-487f676dce28",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def start_training():\n",
    "    noise = NoiseGenerator(64)\n",
    "    d_optim = tf.optimizers.Adam(1e-4)\n",
    "    g_optim = tf.optimizers.Adam(1e-4)\n",
    "\n",
    "    checkpoint = tf.train.Checkpoint(generator_optimizer=g_optim,\n",
    "                                     discriminator_optimizer=d_optim,\n",
    "                                     generator=generator,\n",
    "                                     discriminator=discriminator)\n",
    "\n",
    "    train_step = train_step_template(\n",
    "        generator=generator,\n",
    "        discriminator=discriminator,\n",
    "        noise=noise,\n",
    "        d_optim=d_optim,\n",
    "        g_optim=g_optim,\n",
    "        d_loss_f=w_discriminator_loss,\n",
    "        g_loss_f=w_generator_loss,\n",
    "    )\n",
    "\n",
    "    gen_step = gen_step_template(\n",
    "        generator=generator,\n",
    "        noise=noise\n",
    "    )\n",
    "\n",
    "    train(\n",
    "        train_step=train_step,\n",
    "        gen_step=gen_step,\n",
    "        epochs=1,\n",
    "        data=train_data,\n",
    "        checkpoint=checkpoint\n",
    "    )\n",
    "\n",
    "run_name=\"first\"\n",
    "\n",
    "print(\"Start time\", get_time())\n",
    "print('%'*30)\n",
    "start = time.time()\n",
    "\n",
    "start_training()\n",
    "# na początku generowane obrazki są białe, bardzo małe odchylenie w wartościach pikseli ok 17 dla skali 0-255\n",
    "# generator używa tylko skali np 52-160\n",
    "# później generator uczy się zwiększać odchylenie i wartości pikseli na obrazkach zwiększają się do przedziału 0-255\n",
    "\n",
    "end = time.time()\n",
    "print('%'*30)\n",
    "print(\"End time\", get_time())\n",
    "print(\"seconds elapsed\", end - start)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FaceGenerator",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "FaceGenerator",
   "language": "python",
   "name": "facegenerator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
