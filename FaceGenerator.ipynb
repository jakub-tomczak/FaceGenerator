{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "collab_mode = True\n",
    "\n",
    "if collab_mode:\n",
    "    # set up tensorflow in collab\n",
    "    %tensorflow_version 2.x\n",
    "# imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import warnings # This ignore all the warning messages\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from os import path\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(\"Tensorflow version is\", tf.__version__, \", device name\", tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def allow_memory_growth():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            # Memory growth must be set before GPUs have been initialized\n",
    "            print(e)\n",
    "\n",
    "allow_memory_growth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_time():\n",
    "    return time.strftime(\"%d-%m-%Y_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def process_image(img, image_shape):\n",
    "    img = tf.cast(img, tf.float32)/127.5-1 # IMPORTANT, image's pixels are in the range <-1, 1>\n",
    "    img = tf.image.resize(img, (64, 64))\n",
    "    return img\n",
    "\n",
    "def load_image(filename):\n",
    "    img = tf.io.read_file(filename)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    return img\n",
    "\n",
    "def display_image_from_dataset(data):\n",
    "    # Check image\n",
    "    for batch in data.take(1):\n",
    "        for img in iter(batch):\n",
    "            img_ = (img+1)/2\n",
    "            plt.imshow(img_)\n",
    "            print(img_.shape, np.min(img_), np.max(img_))\n",
    "            break\n",
    "\n",
    "def save_generated_image(settings, epoch):\n",
    "    save_dir = settings.generated_images_path\n",
    "    if not path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    name = path.join(save_dir,\n",
    "                     'img_{}_{}.png'.format(epoch, get_time()))\n",
    "    plt.savefig(name)\n",
    "\n",
    "\n",
    "def show_images(images, epoch, settings, save_images=False, display_images=False):\n",
    "    print(\"image pixels range\", np.min(images), np.max(images), \"std\", np.std(images))\n",
    "    num_of_images = min(10, images.shape[0])\n",
    "    # (x, y=1)\n",
    "    plt.figure(figsize=(num_of_images, 1))\n",
    "    for i in range(num_of_images):\n",
    "        plt.subplot(1, num_of_images, i + 1)\n",
    "        img = images[i, :, :, :].numpy() #\n",
    "        img = (img * 127.5 + 127.5).astype(np.uint8)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    \n",
    "\n",
    "    if save_images:\n",
    "        save_generated_image(settings, epoch)\n",
    "    if display_images:\n",
    "        plt.show()\n",
    "\n",
    "def load_dataset(dataset_path, image_shape, use_manually_downloaded_dataset=True, preprocess_images=True, shuffle_size=500, seed=101):\n",
    "    if use_manually_downloaded_dataset:\n",
    "        img_path = path.join(dataset_path, '*.jpg')\n",
    "        data = tf.data.Dataset.list_files(img_path, seed=seed)\\\n",
    "                              .shuffle(shuffle_size)\\\n",
    "                              .map(load_image)\n",
    "    else:\n",
    "        dataset_name = 'celeb_a'\n",
    "        data = tfds.load(dataset_name, split=tfds.Split.TRAIN, seed=seed)\\\n",
    "                   .shuffle(shuffle_size)\n",
    "\n",
    "    if preprocess_images:\n",
    "        data = data.map(lambda x: process_image(x, image_shape))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class Settings:\n",
    "    def __init__(self, collab_mode):\n",
    "        self.root_local_path = os.getcwd()\n",
    "        self.root_gdrive_path = '/content/drive'\n",
    "        self.gdrive_project_path = 'My Drive/pp/GSN/FaceGenerator'\n",
    "        self.dataset_name = \"celeb_a\"\n",
    "        self.subdataset_dir=\"1000\"\n",
    "        self.dataset_image_size = (28, 28)\n",
    "        self.image_size = (64, 64)\n",
    "        self.image_channels = 3\n",
    "        self.generator_input_shape = (self.image_size[0], self.image_channels)\n",
    "        self.gdrive_mounted = False\n",
    "        self.collab_mode = collab_mode\n",
    "        self.batch_size = 100\n",
    "        self.epochs = 100\n",
    "        self.save_models = False # save models at the end?\n",
    "        self.mount_gdrive()\n",
    "        \n",
    "    @property\n",
    "    def run_name(self):\n",
    "        return 'run_{}'.format(self.subdataset_dir)\n",
    "        # return \"{}_epochs_{}_batch_{}\".format(self.epochs, self.batch_size, self.subdataset_dir)\n",
    "    \n",
    "    @property\n",
    "    def image_shape(self):\n",
    "        return (*self.image_size, self.image_channels)\n",
    "\n",
    "    @property\n",
    "    def download_path(self):\n",
    "        return path.join('.', 'datasets', self.dataset_name)\n",
    "    # def download_path(self):\n",
    "    #     return path.join(self.get_base_path, 'datasets', self.dataset_name)\n",
    "\n",
    "    @property\n",
    "    def dataset_path(self):\n",
    "        return path.join(self.download_path, self.subdataset_dir)\n",
    "\n",
    "    @property\n",
    "    def tensorboard_log_dir(self):\n",
    "        return path.join(self.get_base_path, 'saved_state', self.run_name, 'tensorboard_logs')\n",
    "\n",
    "    @property\n",
    "    def checkpoint_dir(self):\n",
    "        return path.join(self.get_base_path, 'saved_state', self.run_name, \"ckpt\")\n",
    "\n",
    "    @property\n",
    "    def model_save_path(self):\n",
    "        return path.join(self.get_base_path, 'saved_state', self.run_name, 'models')\n",
    "    \n",
    "    @property\n",
    "    def generated_images_path(self):\n",
    "        return path.join(self.get_base_path, 'saved_state', self.run_name, 'generated_images')\n",
    "    \n",
    "    @property\n",
    "    def get_base_path(self):\n",
    "        if self.collab_mode:\n",
    "            return path.join(self.root_gdrive_path, self.gdrive_project_path)\n",
    "        else:\n",
    "            return self.root_local_path\n",
    "\n",
    "    def mount_gdrive(self):\n",
    "        if self.collab_mode:\n",
    "            from google.colab import drive\n",
    "            project_path = path.join(self.root_gdrive_path, self.gdrive_project_path)\n",
    "            self.gdrive_project_path = path.join(self.root_gdrive_path, self.gdrive_project_path)\n",
    "            drive.mount(self.root_gdrive_path)\n",
    "            self.gdrive_mounted = True\n",
    "        \n",
    "            path_with_imports = path.join(self.root_gdrive_path, self.gdrive_project_path)\n",
    "            print(\"Files in path\", path_with_imports)\n",
    "            !ls /content/drive/My\\ Drive/pp/GSN/FaceGenerator\n",
    "            if path_with_imports not in os.sys.path:\n",
    "                os.sys.path.append(path_with_imports)\n",
    "                \n",
    "class DatasetCache:\n",
    "    def __init__(self, use_manually_downloaded_dataset):\n",
    "        self.path = \"\"\n",
    "        self.batch_size = 0\n",
    "        self._data = None\n",
    "        # should it use dataset downloaded manually or the one downloaded by tfds\n",
    "        self.use_manually_downloaded_dataset = use_manually_downloaded_dataset\n",
    "\n",
    "    def load_data(self, settings):\n",
    "        if self._data is not None and self.path == settings.dataset_path:\n",
    "            self.batch_size = settings.batch_size\n",
    "            return self.data\n",
    "        else:\n",
    "            print(\"downloading and loading data\")\n",
    "            if self.use_manually_downloaded_dataset:\n",
    "                self.download_dataset(settings)\n",
    "            self._data = load_dataset(\n",
    "                settings.dataset_path,\n",
    "                settings.image_size,\n",
    "                use_manually_downloaded_dataset=self.use_manually_downloaded_dataset\n",
    "            )\n",
    "            self.data_path = settings.dataset_path\n",
    "            self.batch_size = settings.batch_size\n",
    "            return self.data\n",
    "        \n",
    "    @property\n",
    "    def data(self):\n",
    "        if self._data is None:\n",
    "            return None\n",
    "        else:\n",
    "            return self._data.batch(self.batch_size)\n",
    "\n",
    "    def download_dataset(self, settings):\n",
    "        import dataset_helpers as ds_helpers\n",
    "        '''Downloads data to dataset_path/dataset_name directory'''\n",
    "        print('dataset download path is {}'.format(settings.download_path))\n",
    "        ds_helpers.download_extract('celeba', settings.download_path)\n",
    "        \n",
    "class TensorboardManager():\n",
    "    def __init__(self):\n",
    "        self.log_path = ''\n",
    "        self.train_summary_writer = None\n",
    "        self.test_summary_writer = None\n",
    "        \n",
    "    def initialize(self, settings):\n",
    "        should_be_updated = False\n",
    "        if settings.collab_mode and self.log_path != \"tensorboard_logs\":\n",
    "            should_be_updated = True\n",
    "            self.log_path = \"/content/drive/My Drive/pp/GSN/FaceGenerator/saved_state/run_img_align_celeba/tensorboard_logs\"\n",
    "        elif not settings.collab_mode and self.log_path != settings.tensorboard_log_dir:\n",
    "            should_be_updated = True\n",
    "            self.log_path = settings.tensorboard_log_dir\n",
    "                \n",
    "        if should_be_updated:\n",
    "            self.train_summary_writer = tf.summary.create_file_writer(path.join(self.log_path, 'train'))\n",
    "            self.test_summary_writer = tf.summary.create_file_writer(path.join(self.log_path, 'test'))\n",
    "            print('Initialized tensorboard log dir with path', self.log_path)\n",
    "            self.launch(settings.collab_mode)\n",
    "        \n",
    "    def launch(self, collab_mode):\n",
    "        if collab_mode:\n",
    "            %reload_ext tensorboard\n",
    "            %tensorboard --logdir \"/content/drive/My Drive/pp/GSN/FaceGenerator/saved_state/run_img_align_celeba/tensorboard_logs\"\n",
    "            from tensorboard import notebook\n",
    "            notebook.list() # View open TensorBoard instances\n",
    "        else:\n",
    "            print('open tensorboard with command')\n",
    "            print('tensorboard --logdir {}'.format(self.log_path))\n",
    "            \n",
    "    def save(self, run_type, data, description, timestamp, datatype, step):\n",
    "        '''\n",
    "        run_type: either `train` or `test`\n",
    "        data: represents scalar, images or list of scalars\n",
    "        description: should be of a length of data, i.e. if data is a scalar, description should be a string\n",
    "        datatype: one of 'scalar', 'scalars', 'images'\n",
    "        '''\n",
    "        def _save(writer):\n",
    "            with writer.as_default():\n",
    "                if datatype == 'scalars':\n",
    "                    for value, name in zip(data, description):\n",
    "                        tf.summary.scalar('{}_{}'.format(name, timestamp), value, step=step)\n",
    "                elif datatype == 'scalar':\n",
    "                    tf.summary.scalar('{}_{}'.format(description, timestamp), data, step=step)\n",
    "                elif datatype == 'images':\n",
    "                    tf.summary.image('{}_{}'.format(description, timestamp), data, step=step)\n",
    "                else:\n",
    "                    print('unknown type', datatype)\n",
    "\n",
    "        if run_type == 'train' and self.train_summary_writer:\n",
    "            _save(self.train_summary_writer)\n",
    "        elif run_type == 'test' and self.train_summary_writer:\n",
    "            _save(self.test_summary_writer)\n",
    "        else:\n",
    "            print('unrecognized option `run_type` or selected writer', run_type,'is None')    \n",
    "            \n",
    "class Environment():\n",
    "    def __init__(self, collab_mode):\n",
    "        self.settings = Settings(collab_mode)\n",
    "        self.models = dict()\n",
    "        self.datasetCache = DatasetCache(use_manually_downloaded_dataset=True)\n",
    "        self.checkpointManager = None\n",
    "        self.tensorboard = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test downloading and loading data\n",
    "\n",
    "dataset = DatasetCache(use_manually_downloaded_dataset=True)\n",
    "settings = Settings(collab_mode)\n",
    "if collab_mode:\n",
    "    settings.subdataset_dir = 'img_align_celeba'\n",
    "dataset.load_data(settings)\n",
    "\n",
    "\n",
    "if not collab_mode:\n",
    "    data = load_dataset(\"./datasets/celeb_a/1000\", (64, 64))\n",
    "    data = data.batch(100)\n",
    "    display_image_from_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_from_dataset(dataset.data)\n",
    "if not collab_mode:\n",
    "    !ls \"./datasets/celeb_a/img_align_celeba\" | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1xwRLPZYmJtL",
    "pycharm": {}
   },
   "source": [
    "Loss functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TnfRHsNBmLsd",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "kl = tf.keras.losses.KLDivergence()\n",
    "\n",
    "def min_max_discriminator_loss(real_out, gen_out):\n",
    "    real_loss = bce(tf.ones_like(real_out), real_out)\n",
    "    gen_loss = bce(tf.zeros_like(gen_out), gen_out)\n",
    "    return real_loss + gen_loss\n",
    "\n",
    "\n",
    "def min_max_generator_loss(gen_out):\n",
    "    return - min_max_discriminator_loss(tf.ones_like(gen_out), gen_out)\n",
    "\n",
    "\n",
    "def w_discriminator_loss(real_out, gen_out):\n",
    "    res = - (tf.reduce_mean(real_out) - tf.reduce_mean(gen_out))\n",
    "    return res\n",
    "\n",
    "\n",
    "def w_generator_loss(gen_out):\n",
    "    return - tf.reduce_mean(gen_out)\n",
    "\n",
    "def kl_generator_loss(real, gen):\n",
    "    return kl(real, gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorResidualLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super(GeneratorResidualLayer, self).__init__(**kwargs)\n",
    "        self.block = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(filters*2, 3, 1, 'same', use_bias=False),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(filters, 3, 1, 'same', use_bias=False),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "        ])\n",
    "\n",
    "    def call(self, data):\n",
    "        residual = data\n",
    "        out = self.block(data)\n",
    "        return tf.keras.layers.add([out, residual])\n",
    "    \n",
    "class GeneratorUpsampleLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super(GeneratorUpsampleLayer, self).__init__(**kwargs)\n",
    "        self.block = tf.keras.Sequential([\n",
    "            tf.keras.layers.UpSampling2D(),\n",
    "            tf.keras.layers.Conv2D(filters*2, 3, 1, 'same', use_bias=False),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU()\n",
    "        ])\n",
    "\n",
    "    def call(self, data):\n",
    "        return self.block(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwrjmA4t6Oxn",
    "pycharm": {}
   },
   "source": [
    "Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANNetwork(tf.keras.Model):\n",
    "    def __init__(self, model_name=\"Network\", is_conditional=True, **kwargs):\n",
    "        super().__init__(name=model_name, **kwargs)\n",
    "        self.model = None\n",
    "        self.is_conditional = kwargs['is_conditional']\\\n",
    "            if 'is_conditional' in kwargs\\\n",
    "            else False\n",
    "\n",
    "    def print_layers(self):\n",
    "        print(self.model)\n",
    "        for layer in self.model:\n",
    "            print(layer.name, \":\", layer.input_shape, \"->\", layer.output_shape)\n",
    "\n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, data, training):\n",
    "        return self.model(data)\n",
    "\n",
    "    def save_model(self, save_path):\n",
    "        if not path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        filename = path.join(save_path, '{}_{}'.format(self.name, get_time()))\n",
    "        print(\"Saving model\", self.name, \"as\", filename)\n",
    "        self.model.save(filename)\n",
    "        \n",
    "    def compile_model(self, optimizer, loss):\n",
    "        self.model.compile(optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_w = 4\n",
    "init_h = 4\n",
    "gen_init_filters = 64\n",
    "n_g = 2\n",
    "class GeneratorInitStage(GANNetwork):\n",
    "    #input_shape = cfg.GAN.Z_DIM + cfg.GAN.EMBEDDING_DIM\n",
    "    # or \n",
    "    # input_shape = cfg.GAN.Z_DIM if without conditioning\n",
    "    def __init__(self, input_shape, filters, model_name=\"GeneratorInitStage\", **kwargs):\n",
    "        # filters should be `gen_init_filters`\n",
    "        super().__init__(model_name, **kwargs)\n",
    "        self.model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(init_w*init_h*filters*n_g, input_shape=input_shape),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(), # instead of sigmoid\n",
    "            GeneratorUpsampleLayer(filters//2),\n",
    "            GeneratorUpsampleLayer(filters//4),\n",
    "            GeneratorUpsampleLayer(filters//8),\n",
    "            GeneratorUpsampleLayer(filters//16)\n",
    "        ])\n",
    "        \n",
    "class StackGANFirstGenerator(GANNetwork):\n",
    "    #input_shape = cfg.GAN.Z_DIM + cfg.GAN.EMBEDDING_DIM\n",
    "    # or \n",
    "    # input_shape = cfg.GAN.Z_DIM if without conditioning\n",
    "    # last conv2d has 3 channels\n",
    "    def __init__(self, input_shape, filters, model_name=\"GeneratorInitStage\", **kwargs):\n",
    "        # filters should be `gen_init_filters`\n",
    "        super().__init__(model_name, **kwargs)\n",
    "        self.model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(init_w*init_h*filters*n_g, input_shape=input_shape),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(), # instead of sigmoid\n",
    "            GeneratorUpsampleLayer(filters//2),\n",
    "            GeneratorUpsampleLayer(filters//4),\n",
    "            GeneratorUpsampleLayer(filters//8),\n",
    "            GeneratorUpsampleLayer(filters//16),\n",
    "            tf.keras.layers.Conv2D(3, 3, 1, 'same', use_bias=False),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "        ])\n",
    "        \n",
    "        self.output_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(3, 3, 1)\n",
    "        ])\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, data, training):\n",
    "        intermediate_output = self.model(data)\n",
    "        output = tf.\n",
    "init_stage = GeneratorInitStage(input_shape=(16, 16, 3), filters=100)\n",
    "init_stage.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorNextStage(GANNetwork):\n",
    "    def __init__(self, input_shape, number_of_residuals, filters, model_name=\"GeneratorInitStage\", **kwargs):\n",
    "        super().__init__(model_name, **kwargs)\n",
    "        self.model = tf.keras.Sequential()\n",
    "        for i in range(number_of_residuals):\n",
    "            self.model.add(GeneratorResidualLayer(filters))\n",
    "        self.model.add(GeneratorUpsampleLayer(filters//2))\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, data, training):\n",
    "        joined = tf.keras.layers.add(data)\n",
    "        return self.model(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class StackGANGenerator(GANNetwork):\n",
    "#     def __init__(self, input_shape, model_name=\"StackGANGenerator\", **kwargs):\n",
    "#         super().__init__(model_name, **kwargs)\n",
    "#         # takes into account only the initial generator,\n",
    "#         # when adding next generators the whole class should be rewritten\n",
    "#         self.model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(GANNetwork):\n",
    "    def __init__(self, input_shape, model_name=\"Generator\", **kwargs):\n",
    "        super().__init__(model_name, **kwargs)\n",
    "        self.model = tf.keras.Sequential([\n",
    "            # flat\n",
    "            tf.keras.layers.Dense(1024, input_shape=input_shape),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Reshape([16, 16, 256]),\n",
    "            # conv without stride (16x16)\n",
    "            tf.keras.layers.Conv2D(256, 5, 1, 'same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            # t_conv with stride (32x32)\n",
    "            tf.keras.layers.Conv2DTranspose(128, 5, 2, 'same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            # conv without stride (32x32)\n",
    "            tf.keras.layers.Conv2D(64, 5, 1, 'same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            # t_conv with stride (64x64)\n",
    "            tf.keras.layers.Conv2DTranspose(32, 5, 2, 'same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            # conv without stride\n",
    "            tf.keras.layers.Conv2D(3, (1, 1), 1, 'same')\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8N1JmZB06SKO",
    "pycharm": {}
   },
   "source": [
    "Discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackGANDiscriminator(GANNetwork):\n",
    "    def __init__(self, input_shape, filters, model_name=\"StackGANDiscriminator\", **kwargs):\n",
    "        super().__init__(model_name, **kwargs)\n",
    "        self.embedding_dim = kwargs['embedding_dim']\\\n",
    "            if embedding_dim in kwargs\\\n",
    "            else 128\n",
    "        self.filters = filters\n",
    "        self.model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "16ATdVrY6UId",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "class Discriminator(GANNetwork):\n",
    "\n",
    "    def __init__(self, input_shape, model_name=\"Discriminator\", **kwargs):\n",
    "        super().__init__(model_name, **kwargs)\n",
    "\n",
    "        # since discriminator is for classification it should be robust, thus, add\n",
    "        # additional regularization like dropout to prevent from pixel attacks\n",
    "        self.model = tf.keras.Sequential([\n",
    "            # conv with stride (32x32)\n",
    "            tf.keras.layers.Conv2D(64, 5, 2, 'same', input_shape=input_shape),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            # conv with stride (16x16x128)\n",
    "            tf.keras.layers.Conv2D(128, 3, 2, 'same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            # flatten + hidden layer\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(64),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            # prediction (LOGITS!)\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uX4rm1S_6Yfj",
    "pycharm": {}
   },
   "source": [
    "Noise generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S6YpknpB6a0C",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "class NoiseGenerator(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, distribution_size):\n",
    "        super().__init__()\n",
    "        self.distribution_size = distribution_size\n",
    "        # self.data_distributions = self.add_weight(shape=(num_classes, distribution_size), trainable=True)\n",
    "        # self.data_distributions = tf.tile(tf.range(0, num_classes, dtype=tf.float32)[:, tf.newaxis], [1, distribution_size])\n",
    "        # TODO:\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # dists = tf.nn.embedding_lookup(self.data_distributions, inputs)\n",
    "        # dists += tf.random.uniform(tf.shape(dists), -0.35, 0.35)\n",
    "        # return dists\n",
    "        # TODO\n",
    "        return tf.random.normal([tf.shape(inputs)[0], self.distribution_size, 3])\n",
    "        \n",
    "    def diverse_distributions_loss(self):\n",
    "        # TODO\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(input_shape=settings.generator_input_shape)\n",
    "generator.build((None, *settings.generator_input_shape))\n",
    "generator.summary()\n",
    "\n",
    "discriminator = Discriminator(input_shape=settings.image_shape)\n",
    "discriminator.build(input_shape=(None, *settings.image_shape))\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator:\n",
    "\n",
    "   * Total params: 2,724,291\n",
    "   * Trainable params: 2,721,283\n",
    "   * Non-trainable params: 3,008\n",
    "        \n",
    "Dyskryminator:\n",
    "\n",
    "   * Total params: 2,177,025\n",
    "   * Trainable params: 2,176,513\n",
    "   * Non-trainable params: 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "enYw9PQ_6h_o",
    "pycharm": {}
   },
   "source": [
    "Training step\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OqIPgp5B6jqe",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def train_step_template(generator, discriminator, noise, d_optim, g_optim, d_loss_f, g_loss_f, kl_loss_f):\n",
    "\n",
    "    @tf.function\n",
    "    def _train_step_template(images, epoch):\n",
    "        with tf.GradientTape() as d_tape, tf.GradientTape() as g_tape:\n",
    "            real_out = discriminator(images, True)\n",
    "            generated = generator(noise(images), True)\n",
    "            gen_out = discriminator(generated, True)\n",
    "\n",
    "            d_loss = d_loss_f(real_out, gen_out)\n",
    "            g_loss = g_loss_f(gen_out)\n",
    "            g_kl_loss = kl_loss_f(images, generated)\n",
    "\n",
    "        d_grads = d_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "        g_grads = g_tape.gradient(g_loss, generator.trainable_variables + noise.trainable_variables)\n",
    "\n",
    "        d_optim.apply_gradients(zip(d_grads, discriminator.trainable_variables))\n",
    "        g_optim.apply_gradients(zip(g_grads, generator.trainable_variables + noise.trainable_variables))\n",
    "        \n",
    "        return d_loss, g_loss, g_kl_loss\n",
    "\n",
    "    return _train_step_template\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "axR-vkyz6kZa",
    "pycharm": {}
   },
   "source": [
    "Inference step\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r57i63lv6mRT",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def gen_step_template(generator, noise):\n",
    "    @tf.function\n",
    "    def _gen_step_template(images):\n",
    "        return tf.clip_by_value(generator(noise(images), False), -1, 1)\n",
    "\n",
    "    return _gen_step_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8xRLPJoW7IcI",
    "pycharm": {}
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ut1yWYzD7JeR",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def train(train_step, gen_step, epochs, data, settings, ckptManager, tensorboard_manager, save_images=True, display_images=True):\n",
    "    loss_descriptions = ['discriminator loss', 'generator loss', 'kl generator loss']\n",
    "    timestamp = get_time()\n",
    "    max_batch_iter = 0\n",
    "    for epoch in range(epochs):\n",
    "        batch_iter = 0\n",
    "        epoch_start = time.time()\n",
    "        for images in data:\n",
    "            batch_iter+=1\n",
    "            train_result = train_step(images, epoch)\n",
    "            tensorboard_manager.save('train',\n",
    "                                     [np.average(loss) for loss in train_result],\n",
    "                                     loss_descriptions,\n",
    "                                     timestamp,\n",
    "                                     'scalars',\n",
    "                                     epoch*max_batch_iter+batch_iter\n",
    "                                    )\n",
    "            if (batch_iter+1) % 50 == 0:\n",
    "                print(\"Saving checkpoint, iter\", batch_iter+1)\n",
    "                ckptManager.save()\n",
    "        # save the number of batches in one epoch\n",
    "        if epoch == 0:\n",
    "            max_batch_iter = batch_iter\n",
    "\n",
    "        epoch_end = time.time()\n",
    "        print('-'*30)\n",
    "        print('Epoch {0}/{1}, duration {2}'.format(epoch+1, epochs, epoch_end-epoch_start))\n",
    "        #if (epoch + 1) % 5 == 0 or epoch == epochs-1:\n",
    "        print(\"Saving checkpoint, epoch\", epoch+1)\n",
    "        ckptManager.save()\n",
    "\n",
    "        images_to_generate = [img for img in data.take(1)][0].numpy() # take one batch from train_data\n",
    "        generated = gen_step(images_to_generate)\n",
    "        \n",
    "        tensorboard_manager.save('train',\n",
    "                                 generated,\n",
    "                                 '{}_{}/{}'.format(settings.run_name, epoch+1, epochs),\n",
    "                                 timestamp,\n",
    "                                 'images',\n",
    "                                 epoch\n",
    "                                )\n",
    "            \n",
    "        show_images(generated, epoch, settings, save_images=save_images, display_images=display_images)\n",
    "        print('+'*30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how images are displayed/saved\n",
    "def test_image_generation(settings):\n",
    "    save_images = True\n",
    "    display_images = True\n",
    "    batch_size = 10\n",
    "    data = load_dataset(batch_size=settings.batch_size)\n",
    "    \n",
    "    generator_input_shape = (64, 3)\n",
    "    generator = Generator(input_shape=generator_input_shape)\n",
    "    noise = NoiseGenerator(64)\n",
    "    \n",
    "    gen_step = gen_step_template(\n",
    "        generator=generator,\n",
    "        noise=noise\n",
    "    )\n",
    "    images_to_generate = [img for img in data.take(1)][0].numpy() # take one batch from train_data\n",
    "    generated = gen_step(images_to_generate)\n",
    "    show_images(generated, -1, settings, save_images=save_images, display_images=display_images)\n",
    "    \n",
    "# test_image_generation(Settings(collab_mode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i1EZ3WMg7ZS0",
    "pycharm": {}
   },
   "source": [
    "Training with Wasserstein loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "cxqxoONqA4ZR",
    "outputId": "c235a412-fe41-40b4-fa73-673d8b55560e",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def get_models(settings):\n",
    "    generator = Generator(input_shape=settings.generator_input_shape)\n",
    "    generator.build((None, *settings.generator_input_shape))\n",
    "#     generator.summary()\n",
    "\n",
    "    discriminator = Discriminator(input_shape=settings.image_shape)\n",
    "    discriminator.build(input_shape=(None, *settings.image_shape))\n",
    "#     discriminator.summary()\n",
    "    \n",
    "    return generator, discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "EHKejxSy7YOx",
    "outputId": "de999bc7-5064-4d75-86e6-487f676dce28",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "env = Environment(collab_mode)\n",
    "env.settings.epochs = 30\n",
    "env.settings.batch_size = 500\n",
    "env.settings.subdataset_dir='img_align_celeba'\n",
    "env.settings.save_models = True\n",
    "print(env.settings.get_base_path)\n",
    "# load data\n",
    "env.datasetCache.load_data(env.settings)\n",
    "# set models\n",
    "env.models['generator'], env.models['discriminator'] = get_models(env.settings)\n",
    "# setup tensorboard\n",
    "env.tensorboard = TensorboardManager()\n",
    "env.tensorboard.initialize(env.settings)\n",
    "\n",
    "noise = NoiseGenerator(64)\n",
    "d_optim = tf.keras.optimizers.Adam(1e-4)\n",
    "g_optim = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=g_optim,\n",
    "                                 discriminator_optimizer=d_optim,\n",
    "                                 generator=env.models['generator'],\n",
    "                                 discriminator=env.models['discriminator'])\n",
    "env.checkpointManager = tf.train.CheckpointManager(checkpoint=checkpoint,\n",
    "                                                   directory=env.settings.checkpoint_dir,\n",
    "                                                   max_to_keep=3\n",
    "                                                  )\n",
    "if env.checkpointManager.latest_checkpoint:\n",
    "    print(\"restoring state from\", env.checkpointManager.latest_checkpoint)\n",
    "    checkpoint\\\n",
    "        .restore(env.checkpointManager.latest_checkpoint)\n",
    "    \n",
    "train_step = train_step_template(\n",
    "    generator=env.models['generator'],\n",
    "    discriminator=env.models['discriminator'],\n",
    "    noise=noise,\n",
    "    d_optim=d_optim,\n",
    "    g_optim=g_optim,\n",
    "    d_loss_f=w_discriminator_loss,\n",
    "    g_loss_f=w_generator_loss,\n",
    "    kl_loss_f=kl_generator_loss\n",
    ")\n",
    "\n",
    "gen_step = gen_step_template(\n",
    "    generator=env.models['generator'],\n",
    "    noise=noise\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start time\", get_time())\n",
    "print('%'*30)\n",
    "start = time.time()\n",
    "\n",
    "train(\n",
    "    train_step=train_step,\n",
    "    gen_step=gen_step,\n",
    "    epochs=env.settings.epochs,\n",
    "    data=env.datasetCache.data,\n",
    "    settings=env.settings,\n",
    "    ckptManager=env.checkpointManager,\n",
    "    tensorboard_manager=env.tensorboard\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "print('%'*30)\n",
    "print(\"End time\", get_time())\n",
    "print(\"seconds elapsed\", end - start)\n",
    "\n",
    "if env.settings.save_models:\n",
    "    print('saving models')\n",
    "    for model in env.models:\n",
    "        env.models[model].save_model(env.settings.model_save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uwagi:\n",
    "* na początku generowane obrazki są białe, bardzo małe odchylenie w wartościach pikseli ok 17 dla skali 0-255\n",
    "* generator używa tylko skali np 52-160\n",
    "* później generator uczy się zwiększać odchylenie i wartości pikseli na obrazkach zwiększają się do przedziału 0-255\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FaceGenerator",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "FaceGenerator",
   "language": "python",
   "name": "facegenerator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
